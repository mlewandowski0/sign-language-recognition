{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.14.0)\n",
      "Collecting opencv-python\n",
      "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/d9/64/7fdfb9386511cd6805451e012c537073a79a958a58795c4e602e538c388c/opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting mediapipe\n",
      "  Obtaining dependency information for mediapipe from https://files.pythonhosted.org/packages/c9/e4/3e645a8f87577553194a2a15383a60d61b8381cf864e903e43e4c6eb58e0/mediapipe-0.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading mediapipe-0.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/4e/53/14405a47292b59235d811a2af8634aba188ccfd1a38ef4b8042f3447d79a/scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/fc/a5/4d82be566f069d7a9a702dcdf6f9106df0e0b042e738043c0cc7ddd7e3f6/pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pyarrow\n",
      "  Obtaining dependency information for pyarrow from https://files.pythonhosted.org/packages/d5/73/d5588e2bd671aabe02e1e11b12966fa1a066767b20340885964f5d4e1862/pyarrow-16.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading pyarrow-16.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting wandb\n",
      "  Obtaining dependency information for wandb from https://files.pythonhosted.org/packages/8b/8d/bb05a4ecdeac6b2256d98ac10bae8723af5d7a8c1a4c2384b3ae0f80370e/wandb-0.16.6-py3-none-any.whl.metadata\n",
      "  Downloading wandb-0.16.6-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting plotly\n",
      "  Obtaining dependency information for plotly from https://files.pythonhosted.org/packages/04/e5/04cf049c08975e016da446356a47566889be8b6cf88ed45045774f5bf112/plotly-5.21.0-py3-none-any.whl.metadata\n",
      "  Downloading plotly-5.21.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (23.1.0)\n",
      "Collecting jax (from mediapipe)\n",
      "  Obtaining dependency information for jax from https://files.pythonhosted.org/packages/dc/d9/f387d9dfb2cf00f814b24e0f8bf6f4c68ae01870994dc436993fadd73563/jax-0.4.26-py3-none-any.whl.metadata\n",
      "  Downloading jax-0.4.26-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Obtaining dependency information for jaxlib from https://files.pythonhosted.org/packages/a9/41/6bbe0a55e4df1c5d30da02dc3d26be2aea6333af9c35c6d846d431b86c74/jaxlib-0.4.26-cp311-cp311-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading jaxlib-0.4.26-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting torch (from mediapipe)\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/c3/33/d7a6123231bd4d04c7005dde8507235772f3bc4622a25f3a88c016415d49/torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata\n",
      "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Obtaining dependency information for opencv-contrib-python from https://files.pythonhosted.org/packages/8a/ea/aea6289058480b93157ad698ecd7f13cae4892ae0a4750abf33b3ac12f91/opencv_contrib_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading opencv_contrib_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/8d/14/619e24a4c70df2901e1f4dbc50a6291eb63a759172558df326347dce1f0d/protobuf-3.20.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Obtaining dependency information for sounddevice>=0.4.4 from https://files.pythonhosted.org/packages/d7/d5/f0a0aba169f23657c7af3f0c878db7413a9a3b113026fc759862a697c611/sounddevice-0.4.6-py3-none-any.whl.metadata\n",
      "  Downloading sounddevice-0.4.6-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Obtaining dependency information for scipy>=1.6.0 from https://files.pythonhosted.org/packages/e8/fb/e5955e2ddbdf2baee461eb53ec8d0adedd20a6dfc5510ef8d5e7e44ba461/scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/ae/e2/4dea6313ef2b38442fccbbaf4017e50a6c3c8a50e8ee9b512783e5c90409/joblib-1.4.0-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/1e/84/ccd9b08653022b7785b6e3ee070ffb2825841e0dc119be22f0840b2b35cb/threadpoolctl-3.4.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting Click!=8.0.0,>=7.1 (from wandb)\n",
      "  Obtaining dependency information for Click!=8.0.0,>=7.1 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for GitPython!=3.1.29,>=1.0.0 from https://files.pythonhosted.org/packages/e9/bd/cc3a402a6439c15c3d4294333e13042b915bbeab54edc457c723931fed3f/GitPython-3.1.43-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for sentry-sdk>=1.0.0 from https://files.pythonhosted.org/packages/b7/26/cf87e98fb7fa5781c40474970a76d40b04289b949c0a327b719336aa5bca/sentry_sdk-1.45.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sentry_sdk-1.45.0-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Obtaining dependency information for docker-pycreds>=0.4.0 from https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Obtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/fd/df/44b267cb8f073a4ae77e120f0705ab3a07165ad90cecd4881b34c7e1e37b/setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Obtaining dependency information for appdirs>=1.4.3 from https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tenacity>=6.2.0 (from plotly)\n",
      "  Obtaining dependency information for tenacity>=6.2.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.23.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (3.13.4)\n",
      "Collecting sympy (from torch->mediapipe)\n",
      "  Obtaining dependency information for sympy from https://files.pythonhosted.org/packages/d2/05/e6600db80270777c4a64238a98d442f0fd07cc8915be2a1c16da7f2b9e74/sympy-1.12-py3-none-any.whl.metadata\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch->mediapipe)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/38/e9/5f72929373e1a0e8d142a130f3f97e6ff920070f87f91c4e13e40e0fba5a/networkx-3.3-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (3.1.2)\n",
      "Collecting fsspec (from torch->mediapipe)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/93/6d/66d48b03460768f523da62a57a7e14e5e95fdf339d79e996ce3cecda2cdb/fsspec-2024.3.1-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-cuda-nvrtc-cu12==12.1.105 from https://files.pythonhosted.org/packages/b6/9f/c64c03f49d6fbc56196664d05dba14e3a561038a81a638eeb47f4d4cfd48/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-cuda-runtime-cu12==12.1.105 from https://files.pythonhosted.org/packages/eb/d5/c68b1d2cdfcc59e72e8a5949a37ddb22ae6cade80cd4a57a84d4c8b55472/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-cuda-cupti-cu12==12.1.105 from https://files.pythonhosted.org/packages/7e/00/6b218edd739ecfc60524e585ba8e6b00554dd908de2c9c66c1af3e44e18d/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==8.9.2.26 from https://files.pythonhosted.org/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-cublas-cu12==12.1.3.1 from https://files.pythonhosted.org/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-cufft-cu12==11.0.2.54 from https://files.pythonhosted.org/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-curand-cu12==10.3.2.106 from https://files.pythonhosted.org/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-cusolver-cu12==11.4.5.107 from https://files.pythonhosted.org/packages/bc/1d/8de1e5c67099015c834315e333911273a8c6aaba78923dd1d1e25fc5f217/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-cusparse-cu12==12.1.0.106 from https://files.pythonhosted.org/packages/65/5b/cfaeebf25cd9fdec14338ccb16f6b2c4c7fa9163aefcf057d86b9cc248bb/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-nccl-cu12==2.19.3 from https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-nvtx-cu12==12.1.105 from https://files.pythonhosted.org/packages/da/d3/8057f0587683ed2fcd4dbfbdfdfa807b9160b809976099d36b8f60d08f03/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch->mediapipe)\n",
      "  Obtaining dependency information for triton==2.2.0 from https://files.pythonhosted.org/packages/bd/ac/3974caaa459bf2c3a244a84be8d17561f631f7d42af370fc311defeca2fb/triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe)\n",
      "  Obtaining dependency information for nvidia-nvjitlink-cu12 from https://files.pythonhosted.org/packages/ff/ff/847841bacfbefc97a00036e0fce5a0f086b640756dc38caea5e1bb002655/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch->mediapipe)\n",
      "  Obtaining dependency information for mpmath>=0.19 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.0)\n",
      "Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mediapipe-0.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.21.0-py3-none-any.whl (15.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.45.0-py2.py3-none-any.whl (267 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jax-0.4.26-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.4.26-cp311-cp311-manylinux2014_x86_64.whl (78.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_contrib_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, mpmath, appdirs, tzdata, triton, threadpoolctl, tenacity, sympy, smmap, setproctitle, sentry-sdk, scipy, pyarrow, protobuf, opencv-python, opencv-contrib-python, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, joblib, fsspec, docker-pycreds, Click, sounddevice, scikit-learn, plotly, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxlib, jax, gitdb, nvidia-cusolver-cu12, GitPython, wandb, torch, mediapipe\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.24.3\n",
      "    Uninstalling protobuf-4.24.3:\n",
      "      Successfully uninstalled protobuf-4.24.3\n",
      "Successfully installed Click-8.1.7 GitPython-3.1.43 appdirs-1.4.4 docker-pycreds-0.4.0 fsspec-2024.3.1 gitdb-4.0.11 jax-0.4.26 jaxlib-0.4.26 joblib-1.4.0 mediapipe-0.10.11 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 opencv-contrib-python-4.9.0.80 opencv-python-4.9.0.80 pandas-2.2.2 plotly-5.21.0 protobuf-3.20.3 pyarrow-16.0.0 pytz-2024.1 scikit-learn-1.4.2 scipy-1.13.0 sentry-sdk-1.45.0 setproctitle-1.3.3 smmap-5.0.1 sounddevice-0.4.6 sympy-1.12 tenacity-8.2.3 threadpoolctl-3.4.0 torch-2.2.2 triton-2.2.0 tzdata-2024.1 wandb-0.16.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow opencv-python mediapipe scikit-learn matplotlib pandas pyarrow wandb plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 12:00:35.877024: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-24 12:00:36.091584: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-24 12:00:36.091640: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-24 12:00:36.092821: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-24 12:00:36.187428: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Load parquet data into dataset_parquet for training.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.regularizers import l2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import time\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    # root = os.path.join(\"/\", \"kaggle\", \"input\", \"asl-signs\") \n",
    "    #root = os.path.join(\"..\",\"data\", \"ASL-ds\")\n",
    "    root = os.path.join(\".\")\n",
    "    DATA_LIMIT = 2000\n",
    "    BATCH_SIZE = 16\n",
    "    VIDEO_LENGTH = 36\n",
    "    TRAIN_VAL_SPLIT = 0.80\n",
    "    WANDB_RUN = \"mediapipe-asl-dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIPS :  40\n",
      "EYE_LEFT :  20\n",
      "EYE_RIGHT :  20\n",
      "LEFT_HAND :  21\n",
      "RIGHT_HAND :  21\n",
      "LEFT_POSE :  5\n",
      "RIGHT_POSE :  5\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "LIPS_IDXS0 = np.array([\n",
    "        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "    ])\n",
    "\n",
    "EYE_LEFT = np.array([33, 7, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 471, 470, 469, 472])\n",
    "EYE_RIGHT = np.array([362, 398, 384, 385, 386, 387, 388, 466, 263, 249, 390, 373, 374, 380, 381, 382, 476, 475, 474, 477])\n",
    "# Landmark indices in original data\n",
    "LEFT_HAND_IDXS0 = np.arange(468,489)\n",
    "RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
    "LEFT_POSE_IDXS0 = np.array([502, 504, 506, 508, 510])\n",
    "RIGHT_POSE_IDXS0 = np.array([503, 505, 507, 509, 511])\n",
    "\n",
    "print(\"LIPS : \",len(LIPS_IDXS0))\n",
    "print(\"EYE_LEFT : \",len(EYE_LEFT))\n",
    "print(\"EYE_RIGHT : \",len(EYE_RIGHT))\n",
    "print(\"LEFT_HAND : \",len(LEFT_HAND_IDXS0))\n",
    "print(\"RIGHT_HAND : \",len(RIGHT_HAND_IDXS0))\n",
    "print(\"LEFT_POSE : \",len(LEFT_POSE_IDXS0))\n",
    "print(\"RIGHT_POSE : \",len(RIGHT_POSE_IDXS0))\n",
    "\n",
    "all_selection = np.concatenate([LIPS_IDXS0, EYE_LEFT, EYE_RIGHT, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, LEFT_POSE_IDXS0, RIGHT_POSE_IDXS0])\n",
    "print(len(all_selection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code sorts out a parquet files and rearrange the order to pose,face, left-hand, right-hand\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "ids = None\n",
    "\n",
    "order_global = {\"pose\" : 10000, \"face\" : 1000, \"left_hand\" : 100, \"right_hand\" : 10}\n",
    "\n",
    "def visualize_keypoints(frames : np.ndarray, point_size : int):\n",
    "    if len(frames.shape) == 1:\n",
    "        frames = np.array([frames])\n",
    "    \n",
    "    for frame in frames:\n",
    "        frame = frame.reshape(-1, 3)\n",
    "        sizes = point_size * np.ones(frame.shape[0])\n",
    "\n",
    "        fig = go.Figure(data=go.Scatter(x=frame[:,0], y=2.5 - frame[:,1], mode='markers',\n",
    "                                        marker=dict(\n",
    "                                            size=sizes\n",
    "                                            )))\n",
    "\n",
    "    # Customize the layout\n",
    "    fig.update_layout(title='visualization of human keypoints',\n",
    "                        xaxis_title='',\n",
    "                        yaxis_title='',\n",
    "                        width=1000,\n",
    "                        height=1600)\n",
    "\n",
    "    fig.update_xaxes(range=[-0.2, 1.4])  # Set x-axis range from 0 to 6\n",
    "    fig.update_yaxes(range=[0, 2.5])  # Set y-axis range from 10 to 20\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def process_parquet(ds, idxes = None):\n",
    "    ret = []\n",
    "    frames_unique = sorted(np.unique(ds[\"frame\"]))\n",
    "    for i,frame in enumerate(frames_unique):\n",
    "        frame_ds = ds[ds['frame'] == frame]\n",
    "        \n",
    "        order = []\n",
    "        for el in frame_ds[\"row_id\"]:\n",
    "            _frame, part, keypoint = el.split(\"-\")\n",
    "            order.append(order_global[part] - int(keypoint))\n",
    "\n",
    "        order = np.array(order)\n",
    "        frame_ds.iloc[:, 1] = order\n",
    "        frame_ds = frame_ds.sort_values(by=\"row_id\", ascending=False)\n",
    "    \n",
    "        vals = np.array(frame_ds[[\"x\", \"y\", \"z\"]])\n",
    "        if idxes is not None:\n",
    "            vals = vals[idxes]\n",
    "    \n",
    "        vals = vals.flatten()\n",
    "\n",
    "        ret.append(vals)\n",
    "        \n",
    "    return np.array(ret)\n",
    "\n",
    "\n",
    "def process_parquet2(ds, idxes = None):\n",
    "    ret = []    \n",
    "    frame_size = 543\n",
    "    it = len(ds) // frame_size\n",
    "    assert it == len(ds) / frame_size\n",
    "    \n",
    "    for i in range(it):\n",
    "        vals = ds.iloc[ i * frame_size : (i + 1 ) * frame_size ]        \n",
    "        \n",
    "        if idxes is not None:          \n",
    "            vals = ds.iloc[idxes]\n",
    "                        \n",
    "        ret.append(np.array(vals[[\"x\",\"y\", \"z\"]]).flatten())\n",
    "        \n",
    "    return np.array(np.array(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94477/94477 [00:00<00:00, 462968.35it/s]\n",
      "Cacheing: 100%|██████████| 1600/1600 [00:20<00:00, 77.31it/s]\n",
      "100%|██████████| 94477/94477 [00:00<00:00, 468543.20it/s]\n",
      "Cacheing: 100%|██████████| 400/400 [00:05<00:00, 74.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardinality of train : 1600, cardinality of validation : 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#custom class to load data from Parquet files for training ML models.\n",
    "class ParquetDatasetCached(keras.utils.Sequence):\n",
    "    def __init__(self, dataset_folder, csv_file : str, batch_size=CONFIG.BATCH_SIZE, \n",
    "                 data_limit :int= CONFIG.DATA_LIMIT, check_if_file_exists = True, \n",
    "                 preprocessing_func=None, frame_length :int = CONFIG.VIDEO_LENGTH,\n",
    "                 split : str = \"train\", train_val_split : float = CONFIG.TRAIN_VAL_SPLIT,\n",
    "                 sort_by_counts : bool = True, **kwargs\n",
    "                ):\n",
    "        super().__init__(**kwargs)\n",
    "        #taking keras sequence for .fit(), .evaluate(), .predict() methods\n",
    "        #load csv - it has the path to parquet file, and another to store label\n",
    "        self.csv_path = csv_file\n",
    "        self.root_folder = dataset_folder\n",
    "        self.batch_size = batch_size\n",
    "        #optional pre-processing function to the parquet files.\n",
    "        self.preprocessing_func = preprocessing_func\n",
    "        \n",
    "        self.csv_data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        self.all_files = []\n",
    "        self.not_exists = []\n",
    "        self.frame_length = frame_length\n",
    "\n",
    "        \n",
    "        for path, label in tqdm(list(zip(self.csv_data[\"path\"], self.csv_data[\"sign\"]))):\n",
    "            prop_path = os.path.join(self.root_folder, path)\n",
    "            \n",
    "            if check_if_file_exists:\n",
    "                if os.path.exists(prop_path):\n",
    "                    self.all_files.append((prop_path, label))\n",
    "                else:\n",
    "                    self.not_exists.append(prop_path)\n",
    "            else:\n",
    "                self.all_files.append((prop_path, label))\n",
    "                \n",
    "                    \n",
    "        self.all_files = np.array(self.all_files)\n",
    "        self.unique_labels = np.unique(self.all_files[:, 1])\n",
    "        self.label_2_id = { key : i for i, key in enumerate(self.unique_labels)}\n",
    "    \n",
    "        # sort the values by popularity\n",
    "        if sort_by_counts:\n",
    "            cnt = Counter(self.all_files[:, 1])\n",
    "            vals = []\n",
    "            \n",
    "            for i,row in enumerate(self.all_files):\n",
    "                vals.append((int(1e6 * cnt[row[1]] + self.label_2_id [row[1]]),i))\n",
    "            \n",
    "            vals = np.array(sorted(vals)[::-1])\n",
    "            self.all_files = self.all_files[vals[:,1]]\n",
    "\n",
    "        \n",
    "        if data_limit < 0:\n",
    "            train_ds, val_ds = train_test_split(self.all_files, train_size=train_val_split, random_state=42)\n",
    "        else:\n",
    "            train_ds, val_ds = train_test_split(self.all_files[:data_limit], train_size=train_val_split, random_state=42)\n",
    "            self.unique_labels = np.unique(self.all_files[:data_limit, 1])\n",
    "            self.label_2_id = { key : i for i, key in enumerate(self.unique_labels)}\n",
    "            \n",
    "        if split.lower() == \"train\":\n",
    "            self.dataset = train_ds\n",
    "            \n",
    "        elif split.lower() == \"val\":\n",
    "            self.dataset = val_ds \n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"please specify split to be either train or val\")\n",
    "            \n",
    "        self.cache_data()\n",
    "                   \n",
    "\n",
    "    def cache_data(self):\n",
    "        self.cached_X, self.cached_Y = [], []\n",
    "        \n",
    "        pb = tqdm(range(len(self.dataset)), desc=\"Cacheing\")\n",
    "\n",
    "        for i in pb:\n",
    "            \n",
    "            path, label = self.dataset[i]\n",
    "            df = pd.read_parquet(path)\n",
    "                        \n",
    "            one_hot_encoded_label = np.zeros(len(self.unique_labels))\n",
    "            one_hot_encoded_label[self.label_2_id[label]] = 1\n",
    "\n",
    "            self.cached_X.append(process_parquet2(df)) \n",
    "            self.cached_Y.append(one_hot_encoded_label)        \n",
    "\n",
    "    def __len__(self):\n",
    "        # Assuming each Parquet file should be one batch; adjust if necessary\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.preprocessing_func(self.cached_X[idx]), self.cached_Y[idx]                \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle files for the next epoch\n",
    "        np.random.shuffle(self.dataset)\n",
    "\n",
    "\n",
    "def preprocess(frames):\n",
    "    current_length, num_features = frames.shape\n",
    "\n",
    "    if current_length >= CONFIG.VIDEO_LENGTH:\n",
    "            # TODO: a better than uniform value ? Could place gaussian in the middle\n",
    "            random_start = random.randint(0, current_length - CONFIG.VIDEO_LENGTH)\n",
    "            return np.nan_to_num(frames[random_start : (random_start + CONFIG.VIDEO_LENGTH)])\n",
    "        \n",
    "    # padd the video to contain zeros \n",
    "    return np.concatenate([np.nan_to_num(frames), np.zeros((CONFIG.VIDEO_LENGTH - current_length, num_features))], axis=0)\n",
    "\n",
    "    \n",
    "# Usage example\n",
    "parquet_folder_path = CONFIG.root\n",
    "train_dataset_parquet = ParquetDatasetCached(parquet_folder_path, csv_file = os.path.join(CONFIG.root, \"train.csv\"), \n",
    "                                 batch_size=CONFIG.BATCH_SIZE, data_limit=CONFIG.DATA_LIMIT,\n",
    "                                 preprocessing_func=preprocess,\n",
    "                                check_if_file_exists = True,\n",
    "                                split=\"train\")\n",
    "\n",
    "val_dataset_parquet = ParquetDatasetCached(parquet_folder_path, csv_file = os.path.join(CONFIG.root, \"train.csv\"), \n",
    "                                 batch_size=CONFIG.BATCH_SIZE, data_limit=CONFIG.DATA_LIMIT,\n",
    "                                 preprocessing_func=preprocess,\n",
    "                                 check_if_file_exists= True,\n",
    "                                 split=\"val\")\n",
    "\n",
    "print(f\"cardinality of train : {len(train_dataset_parquet)}, cardinality of validation : {len(val_dataset_parquet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape = (36, 1629), Y_shape = (5,)\n"
     ]
    }
   ],
   "source": [
    "X_shape = train_dataset_parquet[0][0].shape\n",
    "Y_shape = train_dataset_parquet[0][1].shape\n",
    "print(f\"X_shape = {X_shape}, Y_shape = {Y_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'donkey': 0, 'listen': 1, 'look': 2, 'mouse': 3, 'shhh': 4}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_parquet.label_2_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 12:01:06.608179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22462 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def dataset_train_generator():\n",
    "    # Instantiate your existing dataset loader\n",
    "\n",
    "    for i in range(len(train_dataset_parquet)):\n",
    "        X_batch, Y_batch = train_dataset_parquet[i]\n",
    "        yield X_batch, Y_batch\n",
    "        \n",
    "def dataset_val_generator():\n",
    "    # Instantiate your existing dataset loader\n",
    "\n",
    "    for i in range(len(val_dataset_parquet)):\n",
    "        X_batch, Y_batch = val_dataset_parquet[i]\n",
    "        yield X_batch, Y_batch        \n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: dataset_train_generator(),\n",
    "    output_types=(tf.float32, tf.float32),  # Adjust types based on your actual data\n",
    "    output_shapes=(X_shape, Y_shape)\n",
    ").prefetch(tf.data.AUTOTUNE).batch(CONFIG.BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: dataset_val_generator(),\n",
    "    output_types=(tf.float32, tf.float32),  # Adjust types based on your actual data\n",
    "    output_shapes=(X_shape, Y_shape)\n",
    ").prefetch(tf.data.AUTOTUNE).batch(CONFIG.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [00:00, 158.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 36, 1629) (16, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 201.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating through dataset took : 0.5044s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "isnans =False\n",
    "\n",
    "f = True\n",
    "labels_batches = []\n",
    "for el in tqdm(train_dataset):\n",
    "    if f:\n",
    "        print(el[0].shape, el[1].shape)\n",
    "        f = False\n",
    "    labels_batches.append(el[1])\n",
    "        \n",
    "    isnans |= np.any(np.isnan(el[0]))\n",
    "    if isnans:\n",
    "        print(\"FOUND NAN!\")\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Iterating through dataset took : {round( time.time() - start , 4)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "from keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "\n",
    "\n",
    "class CosineAnnealingLearningRateScheduler(Callback):\n",
    "    def __init__(self, max_lr, min_lr, T_max):\n",
    "        super(CosineAnnealingLearningRateScheduler, self).__init__()\n",
    "        self.max_lr = max_lr  # Maximum learning rate (i.e., start learning rate)\n",
    "        self.min_lr = min_lr  # Minimum learning rate\n",
    "        self.T_max = T_max    # Specifies the number of epochs per cycle\n",
    "        self.t = 0            # Current epoch\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.t += 1\n",
    "        cos = np.cos(np.pi * (self.t % self.T_max) / self.T_max)\n",
    "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + cos)\n",
    "\n",
    "        keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "def keras_train(model, filepath : str, X_shape, max_lr = 1e-4, min_lr = 2.5e-5, T_max=101, epochs=200, run_name=\"\",\n",
    "                mediapipe_features = \"all\", USE_WANDB=True,\n",
    "               verbose=\"auto\"): \n",
    "    \n",
    "    \n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                                 monitor=\"val_categorical_accuracy\",\n",
    "                                                 verbose=0,\n",
    "                                                 save_best_only=True,\n",
    "                                                 mode=\"max\",\n",
    "                                                 save_freq=\"epoch\")\n",
    "    \n",
    "    cosine_annealer = CosineAnnealingLearningRateScheduler(max_lr=max_lr,\n",
    "                                                           min_lr=min_lr,\n",
    "                                                           T_max=T_max)\n",
    "    \n",
    "    #Adam Optimizer - fixed learning rate.\n",
    "    adam_optimizer = tf.keras.optimizers.Adam(learning_rate=max_lr, clipnorm=1.)\n",
    "\n",
    "    model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    model.build(X_shape)\n",
    "    \n",
    "    \n",
    "    callbacks  = [checkpoint, cosine_annealer]\n",
    "    \n",
    "    if USE_WANDB:\n",
    "        wandb.init(project=CONFIG.WANDB_RUN,\n",
    "                        name=run_name,\n",
    "                        notes=\"Model summary : \\n\" + str(model.summary()),\n",
    "                        config={\"max_lr\" : max_lr, \n",
    "                                \"min_lr\" : 5e-5, \n",
    "                                \"scheduler\" : \"cosineAnnealer\", \n",
    "                                \"epochs\" : epochs, \n",
    "                                \"T_max\" : T_max, \n",
    "                                \"train_size\" : len(train_dataset_parquet.dataset),\n",
    "                                \"val_size\" : len(val_dataset_parquet.dataset),\n",
    "                                \"unique_classes\" : len(train_dataset_parquet.unique_labels), \n",
    "                                \"video_length\" : CONFIG.VIDEO_LENGTH,\n",
    "                                \"features\" : mediapipe_features\n",
    "                                })\n",
    "        callbacks.append(WandbMetricsLogger())\n",
    "\n",
    "\n",
    "    \n",
    "    history = model.fit(train_dataset, epochs=epochs, validation_data = val_dataset, callbacks=callbacks, verbose=verbose)\n",
    "    \n",
    "    if USE_WANDB:      \n",
    "        wandb.finish()\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 1629)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 16)                105344    \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 16)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 256)               4352      \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110981 (433.52 KB)\n",
      "Trainable params: 110981 (433.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(16, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-LSTM16-LR-Dense256-fs=15-cls=3.tf\"),\n",
    "#            run_name=\"AK-LSTM16-LR-Dense256-fs=15-cls=3\", X_shape=X_shape,\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 32)                212736    \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 256)               8448      \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 222469 (869.02 KB)\n",
      "Trainable params: 222469 (869.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nkeras_train(model, filepath=os.path.join(\"models\", \"AK-LSTM32-LR-Dense256-fs=15-cls=3.tf\"),\\n            run_name=\"AK-LSTM32-LR-Dense256-fs=15-cls=3\",\\n            USE_WANDB=True)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(32, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\"\"\"\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"AK-LSTM32-LR-Dense256-fs=15-cls=3.tf\"),\n",
    "            run_name=\"AK-LSTM32-LR-Dense256-fs=15-cls=3\",\n",
    "            USE_WANDB=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_13 (LSTM)              (None, 64)                433664    \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 451589 (1.72 MB)\n",
      "Trainable params: 451589 (1.72 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nkeras_train(model, filepath=os.path.join(\"models\", \"AK-LSTM64-LR-Dense256-fs=15-cls=3.tf\"),\\n            run_name=\"AK-LSTM64-LR-Dense256-fs=15-cls=3\",\\n            USE_WANDB=True)\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\"\"\"\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"AK-LSTM64-LR-Dense256-fs=15-cls=3.tf\"),\n",
    "            run_name=\"AK-LSTM64-LR-Dense256-fs=15-cls=3\",\n",
    "            USE_WANDB=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_28 (LSTM)              (None, 128)               900096    \n",
      "                                                                 \n",
      " leaky_re_lu_39 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 934405 (3.56 MB)\n",
      "Trainable params: 934405 (3.56 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nkeras_train(model, filepath=os.path.join(\"models\", \"AK-LSTM128-LR-Dense256-fs=15-cls=3.tf\"),\\n            run_name=\"AK-LSTM128-LR-Dense256-fs=15-cls=3\",\\n            USE_WANDB=True)\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\"\"\"\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"AK-LSTM128-LR-Dense256-fs=15-cls=3.tf\"),\n",
    "            run_name=\"AK-LSTM128-LR-Dense256-fs=15-cls=3\",\n",
    "            USE_WANDB=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_30 (LSTM)              (None, 512)               4386816   \n",
      "                                                                 \n",
      " leaky_re_lu_41 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4519429 (17.24 MB)\n",
      "Trainable params: 4519429 (17.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nkeras_train(model, filepath=os.path.join(\"models\", \"AK-LSTM128-LR-Dense256-fs=15-cls=3.tf\"),\\n            run_name=\"AK-LSTM128-LR-Dense256-fs=15-cls=3\",\\n            USE_WANDB=True)\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(512, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\"\"\"\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"AK-LSTM128-LR-Dense256-fs=15-cls=3.tf\"),\n",
    "            run_name=\"AK-LSTM128-LR-Dense256-fs=15-cls=3\",\n",
    "            USE_WANDB=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 36, 512)           4386816   \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 18432)             0         \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 256)               4718848   \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9106949 (34.74 MB)\n",
      "Trainable params: 9106949 (34.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-LSTM512-LR-Dense128-gelu-fs=15-cls=3.tf\"),\n",
    "#            run_name=\"AK-LSTM256-LR-Dense128-gelu-fs=15-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 16)                79056     \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 16)                0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 256)               4352      \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84693 (330.83 KB)\n",
      "Trainable params: 84693 (330.83 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.GRU(16, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-GRU16-LR-Dense256-gelu-fs=15-cls=3.tf\"),\n",
    "#            run_name=\"AK-GRU16-LR-Dense256-gelu-fs=15-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 32)                159648    \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 256)               8448      \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169381 (661.64 KB)\n",
      "Trainable params: 169381 (661.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.GRU(32, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-GRU32-LR-Dense256-gelu-fs=15-cls=3.tf\"),\n",
    "#            run_name=\"AK-GRU32-LR-Dense256-gelu-fs=15-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, 64)                325440    \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 343365 (1.31 MB)\n",
      "Trainable params: 343365 (1.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.GRU(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-GRU64-LR-Dense256-gelu-cls=3.tf\"),\n",
    "#            run_name=\"AK-GRU64-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, 128)               675456    \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709765 (2.71 MB)\n",
      "Trainable params: 709765 (2.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.GRU(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-GRU128-LR-Dense256-gelu-cls=3.tf\"),\n",
    "#            run_name=\"AK-GRU128-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, 256)               1449216   \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1516293 (5.78 MB)\n",
      "Trainable params: 1516293 (5.78 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.GRU(256, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-GRU256-LR-Dense256-gelu-cls=3.tf\"),\n",
    "#            run_name=\"AK-GRU256-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_5 (GRU)                 (None, 512)               3291648   \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3424261 (13.06 MB)\n",
      "Trainable params: 3424261 (13.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.GRU(512, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-GRU512-LR-Dense256-gelu-cls=3.tf\"),\n",
    "#            run_name=\"AK-GRU512-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_14 (Bidirect  (None, 36, 32)            210688    \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 1152)              0         \n",
      "                                                                 \n",
      " leaky_re_lu_27 (LeakyReLU)  (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 256)               295168    \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 507141 (1.93 MB)\n",
      "Trainable params: 507141 (1.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.Bidirectional(LSTM(16, return_sequences=True, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001))))\n",
    "model.add(layers.Flatten())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.build((None, X_shape[0], X_shape[1]))\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, X_shape=(None, X_shape[0], X_shape[1]), filepath=os.path.join(\"models\", \"AK-BLSTM16-LR-Dense256-gelu-cls=3\"),\n",
    "#            run_name=\"AK-BLSTM16-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_15 (Bidirect  (None, 36, 64)            425472    \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 2304)              0         \n",
      "                                                                 \n",
      " leaky_re_lu_28 (LeakyReLU)  (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 256)               590080    \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1016837 (3.88 MB)\n",
      "Trainable params: 1016837 (3.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.Bidirectional(LSTM(32, return_sequences=True, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001))))\n",
    "model.add(layers.Flatten())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.build((None, X_shape[0], X_shape[1]))\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, X_shape=(None, X_shape[0], X_shape[1]), filepath=os.path.join(\"models\", \"AK-BLSTM32-LR-Dense256-gelu-cls=3\"),\n",
    "#            run_name=\"AK-BLSTM32-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_16 (Bidirect  (None, 36, 128)           867328    \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 4608)              0         \n",
      "                                                                 \n",
      " leaky_re_lu_29 (LeakyReLU)  (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 256)               1179904   \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2048517 (7.81 MB)\n",
      "Trainable params: 2048517 (7.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.Bidirectional(LSTM(64, return_sequences=True, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001))))\n",
    "model.add(layers.Flatten())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.build((None, X_shape[0], X_shape[1]))\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model,X_shape=(None, X_shape[0], X_shape[1]), filepath=os.path.join(\"models\", \"AK-BLSTM64-LR-Dense256-gelu-cls=3.tf\"),\n",
    "#            run_name=\"AK-BLSTM64-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_17 (Bidirect  (None, 36, 256)           1800192   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 9216)              0         \n",
      "                                                                 \n",
      " leaky_re_lu_30 (LeakyReLU)  (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 256)               2359552   \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4161029 (15.87 MB)\n",
      "Trainable params: 4161029 (15.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.Bidirectional(LSTM(128, return_sequences=True, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001))))\n",
    "model.add(layers.Flatten())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.build((None, X_shape[0], X_shape[1]))\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model,X_shape=(None, X_shape[0], X_shape[1]), filepath=os.path.join(\"models\", \"AK-BLSTM128-LR-Dense256-gelu-cls=3\"),\n",
    "#            run_name=\"AK-BLSTM128-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_18 (Bidirect  (None, 36, 512)           3862528   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 18432)             0         \n",
      "                                                                 \n",
      " leaky_re_lu_31 (LeakyReLU)  (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 256)               4718848   \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8582661 (32.74 MB)\n",
      "Trainable params: 8582661 (32.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.Bidirectional(LSTM(256, return_sequences=True, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001))))\n",
    "model.add(layers.Flatten())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.build((None, X_shape[0], X_shape[1]))\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model,X_shape=(None, X_shape[0], X_shape[1]), filepath=os.path.join(\"models\", \"AK-BLSTM256-LR-Dense256-gelu-cls=3\"),\n",
    "#            run_name=\"AK-BLSTM256-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_19 (Bidirect  (None, 36, 32)            158112    \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 1152)              0         \n",
      "                                                                 \n",
      " leaky_re_lu_32 (LeakyReLU)  (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 256)               295168    \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 454565 (1.73 MB)\n",
      "Trainable params: 454565 (1.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.Bidirectional(layers.GRU(16, return_sequences=True, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001))))\n",
    "model.add(layers.Flatten())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.build((None, X_shape[0], X_shape[1]))\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-BGRU16-LR-Dense256-gelu-cls=3\"),\n",
    "#            run_name=\"AK-BGRU16-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_20 (Bidirect  (None, 36, 64)            319296    \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 2304)              0         \n",
      "                                                                 \n",
      " leaky_re_lu_33 (LeakyReLU)  (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 256)               590080    \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 910661 (3.47 MB)\n",
      "Trainable params: 910661 (3.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.Bidirectional(layers.GRU(32, return_sequences=True, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001))))\n",
    "model.add(layers.Flatten())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.build((None, X_shape[0], X_shape[1]))\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-BGRU32-LR-Dense256-gelu-cls=3\"),\n",
    "#            run_name=\"AK-BGRU32-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_21 (Bidirect  (None, 36, 128)           650880    \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 4608)              0         \n",
      "                                                                 \n",
      " leaky_re_lu_34 (LeakyReLU)  (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 256)               1179904   \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1832069 (6.99 MB)\n",
      "Trainable params: 1832069 (6.99 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.Bidirectional(layers.GRU(64, return_sequences=True, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001))))\n",
    "model.add(layers.Flatten())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.build((None, X_shape[0], X_shape[1]))\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-BGRU64-LR-Dense256-gelu-cls=3\"),\n",
    "#            run_name=\"AK-BGRU64-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_22 (Bidirect  (None, 36, 256)           1350912   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 9216)              0         \n",
      "                                                                 \n",
      " leaky_re_lu_35 (LeakyReLU)  (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 256)               2359552   \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3711749 (14.16 MB)\n",
      "Trainable params: 3711749 (14.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.Bidirectional(layers.GRU(128, return_sequences=True, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001))))\n",
    "model.add(layers.Flatten())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.build((None, X_shape[0], X_shape[1]))\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-BGRU128-LR-Dense256-gelu-cls=3\"),\n",
    "#            run_name=\"AK-BGRU128-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_23 (Bidirect  (None, 36, 512)           2898432   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 18432)             0         \n",
      "                                                                 \n",
      " leaky_re_lu_36 (LeakyReLU)  (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 256)               4718848   \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7618565 (29.06 MB)\n",
      "Trainable params: 7618565 (29.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(layers.Bidirectional(layers.GRU(256, return_sequences=True, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001))))\n",
    "model.add(layers.Flatten())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(256, activation='gelu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "model.build((None, X_shape[0], X_shape[1]))\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, filepath=os.path.join(\"models\", \"AK-BGRU256-LR-Dense256-gelu-cls=3\"),\n",
    "#            run_name=\"AK-BGRU256-LR-Dense256-gelu-cls=3\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 36, 1629)]        0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, 36, 1629)          58644     \n",
      " ng_7 (TokenAndPositionEmbe                                      \n",
      " dding)                                                          \n",
      "                                                                 \n",
      " transformer_block_7 (Trans  (None, 36, 1629)          21665828  \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " global_average_pooling1d_7  (None, 1629)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 1629)              0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 128)               208640    \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21933757 (83.67 MB)\n",
      "Trainable params: 21933757 (83.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 64  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(CONFIG.VIDEO_LENGTH, 1629))\n",
    "embedding_layer = TokenAndPositionEmbedding(X_shape[0], X_shape[1])\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(X_shape[1], num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = Dense(len(train_dataset_parquet.unique_labels), activation='softmax')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#keras_train(model, filepath=os.path.join(\"models\", f\"AK-Transformer-e={embed_dim}-h={num_heads}-ff={ff_dim}-D=0.1-Dense=128.tf\"),\n",
    "#            run_name=f\"AK-Transformer-e={embed_dim}-h={num_heads}-ff={ff_dim}-D=0.1-Dense=128\",\n",
    "#                max_lr=1e-4,\n",
    "#            min_lr=2.5e-5,\n",
    "#            X_shape=(None, X_shape[0], X_shape[1]),\n",
    "#            T_max=101,\n",
    "#            epochs=200,\n",
    "#            mediapipe_features=\"reduced-LipsEyesHandsPose-scaled\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 36, 1629)]        0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, 36, 1629)          58644     \n",
      " ng_8 (TokenAndPositionEmbe                                      \n",
      " dding)                                                          \n",
      "                                                                 \n",
      " transformer_block_8 (Trans  (None, 36, 1629)          21457252  \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " global_average_pooling1d_8  (None, 1629)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 1629)              0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 128)               208640    \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21725181 (82.87 MB)\n",
      "Trainable params: 21725181 (82.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 64  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 64  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(CONFIG.VIDEO_LENGTH, 1629))\n",
    "embedding_layer = TokenAndPositionEmbedding(X_shape[0], X_shape[1])\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(X_shape[1], num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = Dense(len(train_dataset_parquet.unique_labels), activation='softmax')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "#keras_train(model, filepath=os.path.join(\"models\", f\"AK-Transformer-e={embed_dim}-h={num_heads}-ff={ff_dim}-D=0.1-Dense=128.tf\"),\n",
    "#            run_name=f\"AK-Transformer-e={embed_dim}-h={num_heads}-ff={ff_dim}-D=0.1-Dense=128\",\n",
    "#                max_lr=1e-4,\n",
    "#            min_lr=2.5e-5,\n",
    "#            X_shape=(None, X_shape[0], X_shape[1]),\n",
    "#            T_max=101,\n",
    "#            epochs=200,\n",
    "#            mediapipe_features=\"reduced-LipsEyesHandsPose-scaled\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 36, 1629)]        0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, 36, 1629)          58644     \n",
      " ng_9 (TokenAndPositionEmbe                                      \n",
      " dding)                                                          \n",
      "                                                                 \n",
      " transformer_block_9 (Trans  (None, 36, 1629)          21665828  \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " global_average_pooling1d_9  (None, 1629)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 1629)              0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 128)               208640    \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21933757 (83.67 MB)\n",
      "Trainable params: 21933757 (83.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(CONFIG.VIDEO_LENGTH, 1629))\n",
    "embedding_layer = TokenAndPositionEmbedding(X_shape[0], X_shape[1])\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(X_shape[1], num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = Dense(len(train_dataset_parquet.unique_labels), activation='softmax')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "#keras_train(model, filepath=os.path.join(\"models\", f\"AK-Transformer-e={embed_dim}-h={num_heads}-ff={ff_dim}-D=0.1-Dense=128.tf\"),\n",
    "#            run_name=f\"AK-Transformer-e={embed_dim}-h={num_heads}-ff={ff_dim}-D=0.1-Dense=128\",\n",
    "#                max_lr=1e-4,\n",
    "#            min_lr=2.5e-5,\n",
    "#            X_shape=(None, X_shape[0], X_shape[1]),\n",
    "#            T_max=101,\n",
    "#            epochs=200,\n",
    "#            mediapipe_features=\"all\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 36, 1629)]        0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, 36, 1629)          58644     \n",
      " ng_10 (TokenAndPositionEmb                                      \n",
      " edding)                                                         \n",
      "                                                                 \n",
      " transformer_block_10 (Tran  (None, 36, 1629)          21457252  \n",
      " sformerBlock)                                                   \n",
      "                                                                 \n",
      " global_average_pooling1d_1  (None, 1629)              0         \n",
      " 0 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 1629)              0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 128)               208640    \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21725181 (82.87 MB)\n",
      "Trainable params: 21725181 (82.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 64  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(CONFIG.VIDEO_LENGTH, 1629))\n",
    "embedding_layer = TokenAndPositionEmbedding(X_shape[0], X_shape[1])\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(X_shape[1], num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = Dense(len(train_dataset_parquet.unique_labels), activation='softmax')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "#keras_train(model, filepath=os.path.join(\"models\", f\"AK-Transformer-e={embed_dim}-h={num_heads}-ff={ff_dim}-D=0.1-Dense=128.tf\"),\n",
    "#            run_name=f\"AK-Transformer-e={embed_dim}-h={num_heads}-ff={ff_dim}-D=0.1-Dense=128\",\n",
    "#                max_lr=1e-4,\n",
    "#            min_lr=2.5e-5,\n",
    "#            X_shape=(None, X_shape[0], X_shape[1]),\n",
    "#            T_max=101,\n",
    "#            epochs=200,\n",
    "#            mediapipe_features=\"all\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 36, 1629)]        0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, 36, 1629)          58644     \n",
      " ng_11 (TokenAndPositionEmb                                      \n",
      " edding)                                                         \n",
      "                                                                 \n",
      " transformer_block_11 (Tran  (None, 36, 1629)          42800442  \n",
      " sformerBlock)                                                   \n",
      "                                                                 \n",
      " global_average_pooling1d_1  (None, 1629)              0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 1629)              0         \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 128)               208640    \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43068371 (164.29 MB)\n",
      "Trainable params: 43068371 (164.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 96  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(CONFIG.VIDEO_LENGTH, 1629))\n",
    "embedding_layer = TokenAndPositionEmbedding(X_shape[0], X_shape[1])\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(X_shape[1], num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = Dense(len(train_dataset_parquet.unique_labels), activation='softmax')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "#keras_train(model, filepath=os.path.join(\"models\", f\"AK-Transformer-e={embed_dim}-h={num_heads}-ff={ff_dim}-D=0.1-Dense=128.tf\"),\n",
    "#            run_name=f\"AK-Transformer-e={embed_dim}-h={num_heads}-ff={ff_dim}-D=0.1-Dense=128\",\n",
    "#                max_lr=1e-4,\n",
    "#            min_lr=2.5e-5,\n",
    "#            X_shape=(None, X_shape[0], X_shape[1]),\n",
    "#            T_max=101,\n",
    "#            epochs=200,\n",
    "#            mediapipe_features=\"all\",\n",
    "#            USE_WANDB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 5087314,
     "sourceId": 46105,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
