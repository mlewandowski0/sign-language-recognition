{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ebbacf",
   "metadata": {},
   "source": [
    "# This project\n",
    "Clean up the project such that only the MHI with VGG version exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a35f45",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e8cae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/nhatminh2h/.local/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy in /home/nhatminh2h/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Collecting fastdtw\n",
      "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/nhatminh2h/.local/lib/python3.10/site-packages (3.8.3)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 KB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/nhatminh2h/.local/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting keras>=3.0.0\n",
      "  Downloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes~=0.3.1\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from tensorflow) (1.62.0)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.10.0\n",
      "  Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from tensorflow) (4.25.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rich in /home/nhatminh2h/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/nhatminh2h/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Building wheels for collected packages: fastdtw\n",
      "  Building wheel for fastdtw (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp310-cp310-linux_x86_64.whl size=471419 sha256=5d9b63b286c21ea6b6ace472cf84c0b045a12cc75c1fc3ffce187d7da1d0286e\n",
      "  Stored in directory: /home/nhatminh2h/.cache/pip/wheels/73/c8/f7/c25448dab74c3acf4848bc25d513c736bb93910277e1528ef4\n",
      "Successfully built fastdtw\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, scipy, optree, opt-einsum, ml-dtypes, joblib, h5py, google-pasta, gast, fastdtw, astunparse, scikit-learn, keras, tensorflow\n",
      "Successfully installed astunparse-1.6.3 fastdtw-0.3.4 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 h5py-3.10.0 joblib-1.3.2 keras-3.1.1 libclang-18.1.1 ml-dtypes-0.3.2 namex-0.0.7 opt-einsum-3.3.0 optree-0.11.0 scikit-learn-1.4.1.post1 scipy-1.13.0 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0 threadpoolctl-3.4.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy fastdtw tensorflow scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ade0ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the required dependencies of the project\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f116ced",
   "metadata": {},
   "source": [
    "# Motion History Image Method - CNN Shape\n",
    "Motion History Image (MHI) represent motion in sequence frames as a single image. The intensity of each pixel in the MHI corresponds to the recency of motion at that location - brighter the pixel, more recent the location.\n",
    "\n",
    "Algorithm generates MHI that captures the temporal aspects of motion by decaying older movements and highlight new ones - using further analysis like action recognition on 2DCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781b6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mhi(prev_frame, current_frame, mhi, decay=0.7):\n",
    "    \"\"\"\n",
    "    Update the motion history image based on the current frame and the previous frame.\n",
    "    \"\"\"\n",
    "    # Compute the absolute difference between the current and the previous frame\n",
    "    frame_diff = cv2.absdiff(current_frame, prev_frame)\n",
    "    gray_diff = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_diff = cv2.threshold(gray_diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Convert binary_diff to float32 to match mhi's type\n",
    "    binary_diff = np.float32(binary_diff / 255)  # Normalize to [0, 1] to maintain consistency\n",
    "\n",
    "    # Update MHI: decay existing MHI values and increase values where motion is detected\n",
    "    mhi = cv2.add(mhi * decay, binary_diff)\n",
    "    return mhi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e05949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update MHI, adapted to handle color (BGR) frames directly\n",
    "def update_mhi(prev_frame, current_frame, mhi, decay=0.02):\n",
    "    frame_diff = cv2.absdiff(current_frame, prev_frame)\n",
    "    # Applying threshold to get binary motion detection, works on grayscale\n",
    "    gray_diff = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_diff = cv2.threshold(gray_diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    binary_diff = np.repeat(binary_diff[:, :, np.newaxis], 3, axis=2)  # Make it 3-channel\n",
    "    binary_diff = np.float32(binary_diff / 255)  # Normalize to [0, 1]\n",
    "\n",
    "    # Update the MHI\n",
    "    mhi = cv2.add(mhi * decay, binary_diff)\n",
    "    return mhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f355af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THIS - decay rate of 0.09\n",
    "def update_mhi(prev_frame, current_frame, mhi, decay=0.09):\n",
    "    \"\"\"\n",
    "    Update the motion history image (MHI) to retain motion across the entire video,\n",
    "    adapted for a 3-channel (color) MHI.\n",
    "    \n",
    "    - prev_frame: The previous frame in the video (BGR).\n",
    "    - current_frame: The current frame in the video (BGR).\n",
    "    - mhi: The current state of the MHI, a 3-channel image.\n",
    "    - decay: The rate at which previous motion history fades.\n",
    "    \"\"\"\n",
    "    # Compute the absolute difference between the current and the previous frame\n",
    "    frame_diff = cv2.absdiff(current_frame, prev_frame)\n",
    "    \n",
    "    # Convert the frame difference to grayscale and threshold it\n",
    "    gray_diff = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, motion_mask = cv2.threshold(gray_diff, 25, 1, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Convert the single-channel motion mask to a 3-channel mask\n",
    "    motion_mask_3ch = cv2.merge([motion_mask, motion_mask, motion_mask])\n",
    "    \n",
    "    # Update the MHI: New motion is added with a value of 1, and existing motion history decays\n",
    "    # Ensure that both mhi and motion_mask_3ch are floats for correct operation\n",
    "    mhi = (mhi * (1 - decay)) + np.float32(motion_mask_3ch)\n",
    "    \n",
    "    # Ensure MHI values are capped at 1\n",
    "    mhi = np.clip(mhi, 0, 1)\n",
    "    \n",
    "    return mhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5692dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture video from input video\n",
    "cap = cv2.VideoCapture('bsl_dataset/manual-script/sorry/sorry_28.mp4')\n",
    "\n",
    "# Read the first frame\n",
    "ret, prev_frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    exit()\n",
    "\n",
    "# Initialize MHI with 3 channels to keep color information\n",
    "mhi = np.zeros((*prev_frame.shape[:2], 3), dtype=np.float32)\n",
    "\n",
    "# List to store MHIs\n",
    "mhis = []\n",
    "\n",
    "# Process video to generate MHI\n",
    "while True:\n",
    "    ret, current_frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # End of video\n",
    "    \n",
    "    # Update MHI\n",
    "    mhi = update_mhi(prev_frame, current_frame, mhi)\n",
    "    \n",
    "    # Prepare for next iteration\n",
    "    prev_frame = current_frame.copy()\n",
    "\n",
    "    # Optionally, visualize the MHI\n",
    "    normalized_mhi = np.uint8(np.clip((mhi / mhi.max()) * 255, 0, 255))\n",
    "    cv2.imshow(\"MHI\", normalized_mhi)\n",
    "    \n",
    "    resized_mhi = cv2.resize(normalized_mhi, (224, 224))\n",
    "\n",
    "    # Store the MHI for this frame\n",
    "    mhis.append(resized_mhi.copy())\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Save the last MHI image to a file\n",
    "output_path = 'mhi_image28_alt_0.09.png'  # Adjust the output path as needed\n",
    "cv2.imwrite(output_path, resized_mhi)\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# NOTE: Further processing to fit MHIs into MobileNetV2 would follow here,\n",
    "# including resizing and normalization as needed for your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "346c02ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the mhi_array: (720, 1280, 3)\n",
      "Shape of normalized: (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "output_path\n",
    "mhi_array = np.array(mhi)\n",
    "normalized_mhi_array = np.array(resized_mhi)\n",
    "print(\"Shape of the mhi_array:\", mhi_array.shape)\n",
    "#print(\"Shape of stacked_mhi:\", stacked_mhis.shape)\n",
    "print(\"Shape of normalized:\", resized_mhi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b67a3",
   "metadata": {},
   "source": [
    "## Motion History Image - 3 channel decay method\n",
    "Idea: Instead of duplicating the MHI into 3 channel for RBG into mobile net, set different decay rate and log it into the shape.\n",
    "Then the input should be fed into MobileNetv2.\n",
    "\n",
    "This is still in progress - might need to expand this experiment later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mhi(prev_frame, current_frame, mhi, decay_rate):\n",
    "    \"\"\"\n",
    "    Update the motion history image (MHI) to retain motion across the entire video,\n",
    "    adapted for a 3-channel (color) MHI.\n",
    "    \n",
    "    - prev_frame: The previous frame in the video (BGR).\n",
    "    - current_frame: The current frame in the video (BGR).\n",
    "    - mhi: The current state of the MHI, a 3-channel image.\n",
    "    - decay: The rate at which previous motion history fades.\n",
    "    \"\"\"\n",
    "    # Compute the absolute difference between the current and the previous frame\n",
    "    frame_diff = cv2.absdiff(current_frame, prev_frame)\n",
    "    \n",
    "    # Convert the frame difference to grayscale and threshold it\n",
    "    gray_diff = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, motion_mask = cv2.threshold(gray_diff, 25, 1, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Convert the single-channel motion mask to a 3-channel mask\n",
    "    #motion_mask_3ch = cv2.merge([motion_mask, motion_mask, motion_mask])\n",
    "    \n",
    "    # Update the MHI: New motion is added with a value of 1, and existing motion history decays\n",
    "    # Ensure that both mhi and motion_mask_3ch are floats for correct operation\n",
    "    mhi_1 = (mhi_1 * (1 - decay_rate)) + np.float32(motion_mask)\n",
    "    \n",
    "    mhi_2 = (mhi_2 * (1 - decay_rate)) + np.float32(motion_mask)\n",
    "    \n",
    "    mhi_3 = (mhi_3 * (1 - decay_rate)) + np.float32(motion_mask)\n",
    "    \n",
    "    mhi_combined = cv2.merge([mhi_1, mhi_2, mhi_3])\n",
    "    \n",
    "    # Ensure MHI values are capped at 1\n",
    "    mhi_combined = np.clip(mhi_combined, 0, 1)\n",
    "    \n",
    "    return mhi_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45178dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c99086b9",
   "metadata": {},
   "source": [
    "# Setup Folders for Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14d26e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Data\n",
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MHI_Data') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['thanks', 'sorry'])\n",
    "#no_sequences = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec71ac2f",
   "metadata": {},
   "source": [
    "# Collect Extracted Matrix Values for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68168c28",
   "metadata": {},
   "source": [
    "Loop through the videos in the video folder, they are labelled with ids that separate them.\n",
    "Then for each subfolder get the actions and loop through it, collecting their frame difference matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a875dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder of dataset\n",
    "dataset_folder = \"bsl_dataset/manual-script\"\n",
    "#D:\\BSL_project\\bsl_dataset\\manual-script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa522981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: thanks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]C:\\Users\\mered\\AppData\\Local\\Temp\\ipykernel_19684\\379117340.py:31: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_mhi = np.uint8(np.clip((mhi / mhi.max()) * 255, 0, 255))\n",
      "C:\\Users\\mered\\AppData\\Local\\Temp\\ipykernel_19684\\379117340.py:31: RuntimeWarning: invalid value encountered in cast\n",
      "  normalized_mhi = np.uint8(np.clip((mhi / mhi.max()) * 255, 0, 255))\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:03<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: thanks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:57<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "#data from BSL code version\n",
    "from tqdm import tqdm\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "for action_folder in os.listdir(dataset_folder):\n",
    "    action_path = os.path.join(dataset_folder, action_folder)\n",
    "    if os.path.isdir(action_path) and (actions is None or action in actions):\n",
    "        print(f\"Processing action: {action}\")\n",
    "        for video_file in tqdm(os.listdir(action_path)):\n",
    "            if video_file.endswith(\".mp4\"):\n",
    "                video_path = os.path.join(action_path, video_file)\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "                ret, prev_frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Failed to read video\", video_path)\n",
    "                    cap.release()\n",
    "                    continue\n",
    "\n",
    "                mhi = np.zeros((*prev_frame.shape[:2], 3), dtype=np.float32)\n",
    "                mhis = []\n",
    "\n",
    "                while True:\n",
    "                    ret, current_frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "\n",
    "                    mhi = update_mhi(prev_frame, current_frame, mhi)\n",
    "                    prev_frame = current_frame.copy()\n",
    "                    \n",
    "                    normalized_mhi = np.uint8(np.clip((mhi / mhi.max()) * 255, 0, 255))\n",
    "                    \n",
    "\n",
    "                    #Resize MHI here - for MobileNetV2\n",
    "                    resized_mhi = cv2.resize(normalized_mhi, (200, 200))\n",
    "                    \n",
    "                    #store MHI for this frame\n",
    "                    mhis.append(resized_mhi.copy())\n",
    "\n",
    "                \n",
    "\n",
    "                # Generate an output path for the MHI npy file\n",
    "                output_npy_path = os.path.join(DATA_PATH, action_folder,  f\"{video_file.split('.')[0]}.npy\")\n",
    "                # Save the MHI list as a .npy file\n",
    "                np.save(output_npy_path, np.array(resized_mhi))\n",
    "                #output_path = os.path.join(DATA_PATH, action_folder,  f\"{video_file.split('.')[0]}.png\")\n",
    "                #cv2.imwrite(output_path, resized_mhi)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()  # Make sure to destroy all cv2 windows outside the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f017417",
   "metadata": {},
   "source": [
    "test the shape of the npy file saved fits MobileNetv2 expected shape of (200, 200, 3) shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6cb185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "npy_file_path = 'MHI_Data/thanks/thanks_02.npy'  # Adjust the path as needed\n",
    "\n",
    "# Load the npy file\n",
    "test_array = np.load(npy_file_path)\n",
    "\n",
    "# Output the shape of the array\n",
    "print(test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5eb342e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('MHI_ASL_DATA') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2befe5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected actions: ['book' 'drink' 'computer' ... 'weigh' 'wheelchair' 'whistle']\n",
      "Processing action: book\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [00:06<00:02,  1.30s/it]C:\\Users\\mered\\AppData\\Local\\Temp\\ipykernel_1964\\1114566068.py:60: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_mhi = np.uint8(np.clip((mhi / mhi.max()) * 255, 0, 255))\n",
      "C:\\Users\\mered\\AppData\\Local\\Temp\\ipykernel_1964\\1114566068.py:60: RuntimeWarning: invalid value encountered in cast\n",
      "  normalized_mhi = np.uint8(np.clip((mhi / mhi.max()) * 255, 0, 255))\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:07<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: drink\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:18<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: computer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:35<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: before\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:23<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:09<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: go\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:11<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: clothes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: who\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:22<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: candy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: cousin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:15<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: deaf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:16<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: fine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:08<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: help\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:19<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: thin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: walk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:14<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:15<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: black\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: cool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:23<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:08<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: hot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: like\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: many\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: mother\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:14<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: orange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: thanksgiving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:14<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: what\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:14<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: woman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: bed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:16<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: blue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:08<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: bowling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:19<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: can\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:09<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: family\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: fish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: graduate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: hat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: hearing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:08<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: kiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:12<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: later\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:18<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: man\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:16<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: shirt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:10<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: study\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: tall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:18<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:12<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:12<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: accident\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:25<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:13<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: bird\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:14<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: color\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: corn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:17<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: cow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:12<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: dance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:11<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: dark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:20<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: doctor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: eat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: enjoy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:15<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: forget\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:14<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: give\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:10<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: meet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:16<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: pink\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:12<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: pizza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:21<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: play\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: school\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:13<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: secretary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: short\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:15<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:05<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: want\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:14<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: africa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:20<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: basketball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:20<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: birthday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: brown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:09<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: but\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:05<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: cheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: city\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:16<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: cook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:09<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: decide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:08<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: how\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:16<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: jacket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:13<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: letter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: medicine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:09<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: need\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:10<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: paint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:11<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: paper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:09<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: pull\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:19<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: purple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:08<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: same\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:12<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: son\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: tell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: thursday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:13<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: visit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:14<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: water\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:06<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: wife\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:10<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: yellow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: backpack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:18<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: bar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:13<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: brother\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:21<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:08<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: cry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: different\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: door\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:11<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: hair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:12<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: have\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:09<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: headache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:09<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: inform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:07<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: knife\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:04<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: laugh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:18<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: learn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: movie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: rabbit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:08<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:07<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: room\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:15<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:07<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: show\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:14<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: sick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: snow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: take\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:10<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: tea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:17<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:09<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: week\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:07<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: why\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:14<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: with\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:11<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: write\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: yesterday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:09<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: ball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:12<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: bathroom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: blanket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: buy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:20<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: call\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:13<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: coffee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:09<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: cold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:15<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: college\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:09<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: copy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: cute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:07<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: daughter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:16<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:24<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: friend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: home\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: know\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:09<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: late\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: leave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:17<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: lose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:09<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: old\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:09<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: police\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:08<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: remember\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:09<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: share\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: soon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: stay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:14<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: sunday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:17<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:08<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: tired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:15<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: trade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:25<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: travel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:12<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: window\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:05<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: about\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:08<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: approve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: arrive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:12<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: balance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: banana\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:17<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: beard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: because\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: boy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:12<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: business\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing action: careful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████▎                                              | 4/9 [00:01<00:02,  2.10it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# dataset from asl:\n",
    "dataset_folder = \"asl_dataset_word/archive (1)/extracted_videos_asl\"  # Updated to point to your dataset directory\n",
    "\n",
    "# Defining Data\n",
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MHI_ASL_DATA') \n",
    "\n",
    "# Actions will be dynamically populated based on folder names\n",
    "actions = []\n",
    "\n",
    "# Check and create DATA_PATH if not exists\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "# Populate actions based on folder names in dataset_folder\n",
    "for entry in os.listdir(dataset_folder):\n",
    "    if os.path.isdir(os.path.join(dataset_folder, entry)):\n",
    "        actions.append(entry)\n",
    "\n",
    "actions = np.array(actions)  # Convert list of actions to numpy array\n",
    "\n",
    "print(f\"Detected actions: {actions}\")\n",
    "\n",
    "for action in actions:\n",
    "    action_folder = os.path.join(dataset_folder, action)\n",
    "    action_data_path = os.path.join(DATA_PATH, action)\n",
    "    if not os.path.exists(action_data_path):\n",
    "        os.makedirs(action_data_path)\n",
    "    \n",
    "    print(f\"Processing action: {action}\")\n",
    "    for video_file in tqdm(os.listdir(action_folder)):\n",
    "        if video_file.endswith(\".mp4\"):\n",
    "            # Generate an output path for the MHI npy file\n",
    "            output_npy_path = os.path.join(action_data_path, f\"{video_file.split('.')[0]}.npy\")\n",
    "            \n",
    "            \n",
    "\n",
    "            video_path = os.path.join(action_folder, video_file)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "            ret, prev_frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to read video\", video_path)\n",
    "                cap.release()\n",
    "                continue\n",
    "\n",
    "            mhi = np.zeros((*prev_frame.shape[:2], 3), dtype=np.float32)\n",
    "            mhis = []\n",
    "\n",
    "            while True:\n",
    "                ret, current_frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                mhi = update_mhi(prev_frame, current_frame, mhi)\n",
    "                prev_frame = current_frame.copy()\n",
    "                #normalized_mhi = np.uint8(np.clip((mhi / mhi.max()) * 255, 0, 255))\n",
    "                normalized_mhi = np.uint8(np.clip((mhi / mhi.max()) * 255, 0, 255))\n",
    "                resized_mhi = cv2.resize(normalized_mhi, (224, 224))\n",
    "                mhis.append(resized_mhi.copy())\n",
    "\n",
    "            # Save the MHI list as a .npy file\n",
    "            np.save(output_npy_path, np.array(resized_mhi.copy()))\n",
    "            #output_path_img = os.path.join(action_data_path, f\"{video_file.split('.')[0]}.png\")\n",
    "            #cv2.imwrite(output_path_img, resized_mhi)\n",
    "            cap.release()\n",
    "\n",
    "            \n",
    "\n",
    "cv2.destroyAllWindows()  # Make sure to destroy all cv2 windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a82a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected actions: ['book' 'drink' 'computer' 'before' 'chair' 'go' 'clothes' 'who' 'candy'\n",
      " 'cousin' 'deaf' 'fine' 'help' 'no' 'thin' 'walk' 'year' 'yes' 'all'\n",
      " 'black' 'cool' 'finish' 'hot' 'like' 'many' 'mother' 'now' 'orange'\n",
      " 'table' 'thanksgiving' 'what' 'woman' 'bed' 'blue' 'bowling' 'can' 'dog'\n",
      " 'family' 'fish' 'graduate' 'hat' 'hearing' 'kiss' 'language' 'later'\n",
      " 'man' 'shirt' 'study' 'tall' 'white' 'wrong' 'accident' 'apple' 'bird'\n",
      " 'change' 'color' 'corn' 'cow' 'dance' 'dark' 'doctor' 'eat' 'enjoy'\n",
      " 'forget' 'give' 'last' 'meet' 'pink' 'pizza' 'play' 'school' 'secretary'\n",
      " 'short' 'time' 'want' 'work' 'africa' 'basketball' 'birthday' 'brown'\n",
      " 'but' 'cheat' 'city' 'cook' 'decide' 'full' 'how' 'jacket' 'letter'\n",
      " 'medicine' 'need' 'paint' 'paper' 'pull' 'purple' 'right' 'same' 'son'\n",
      " 'tell' 'thursday']\n",
      "Prepared directory for action: book\n",
      "Prepared directory for action: drink\n",
      "Prepared directory for action: computer\n",
      "Prepared directory for action: before\n",
      "Prepared directory for action: chair\n",
      "Prepared directory for action: go\n",
      "Prepared directory for action: clothes\n",
      "Prepared directory for action: who\n",
      "Prepared directory for action: candy\n",
      "Prepared directory for action: cousin\n",
      "Prepared directory for action: deaf\n",
      "Prepared directory for action: fine\n",
      "Prepared directory for action: help\n",
      "Prepared directory for action: no\n",
      "Prepared directory for action: thin\n",
      "Prepared directory for action: walk\n",
      "Prepared directory for action: year\n",
      "Prepared directory for action: yes\n",
      "Prepared directory for action: all\n",
      "Prepared directory for action: black\n",
      "Prepared directory for action: cool\n",
      "Prepared directory for action: finish\n",
      "Prepared directory for action: hot\n",
      "Prepared directory for action: like\n",
      "Prepared directory for action: many\n",
      "Prepared directory for action: mother\n",
      "Prepared directory for action: now\n",
      "Prepared directory for action: orange\n",
      "Prepared directory for action: table\n",
      "Prepared directory for action: thanksgiving\n",
      "Prepared directory for action: what\n",
      "Prepared directory for action: woman\n",
      "Prepared directory for action: bed\n",
      "Prepared directory for action: blue\n",
      "Prepared directory for action: bowling\n",
      "Prepared directory for action: can\n",
      "Prepared directory for action: dog\n",
      "Prepared directory for action: family\n",
      "Prepared directory for action: fish\n",
      "Prepared directory for action: graduate\n",
      "Prepared directory for action: hat\n",
      "Prepared directory for action: hearing\n",
      "Prepared directory for action: kiss\n",
      "Prepared directory for action: language\n",
      "Prepared directory for action: later\n",
      "Prepared directory for action: man\n",
      "Prepared directory for action: shirt\n",
      "Prepared directory for action: study\n",
      "Prepared directory for action: tall\n",
      "Prepared directory for action: white\n",
      "Prepared directory for action: wrong\n",
      "Prepared directory for action: accident\n",
      "Prepared directory for action: apple\n",
      "Prepared directory for action: bird\n",
      "Prepared directory for action: change\n",
      "Prepared directory for action: color\n",
      "Prepared directory for action: corn\n",
      "Prepared directory for action: cow\n",
      "Prepared directory for action: dance\n",
      "Prepared directory for action: dark\n",
      "Prepared directory for action: doctor\n",
      "Prepared directory for action: eat\n",
      "Prepared directory for action: enjoy\n",
      "Prepared directory for action: forget\n",
      "Prepared directory for action: give\n",
      "Prepared directory for action: last\n",
      "Prepared directory for action: meet\n",
      "Prepared directory for action: pink\n",
      "Prepared directory for action: pizza\n",
      "Prepared directory for action: play\n",
      "Prepared directory for action: school\n",
      "Prepared directory for action: secretary\n",
      "Prepared directory for action: short\n",
      "Prepared directory for action: time\n",
      "Prepared directory for action: want\n",
      "Prepared directory for action: work\n",
      "Prepared directory for action: africa\n",
      "Prepared directory for action: basketball\n",
      "Prepared directory for action: birthday\n",
      "Prepared directory for action: brown\n",
      "Prepared directory for action: but\n",
      "Prepared directory for action: cheat\n",
      "Prepared directory for action: city\n",
      "Prepared directory for action: cook\n",
      "Prepared directory for action: decide\n",
      "Prepared directory for action: full\n",
      "Prepared directory for action: how\n",
      "Prepared directory for action: jacket\n",
      "Prepared directory for action: letter\n",
      "Prepared directory for action: medicine\n",
      "Prepared directory for action: need\n",
      "Prepared directory for action: paint\n",
      "Prepared directory for action: paper\n",
      "Prepared directory for action: pull\n",
      "Prepared directory for action: purple\n",
      "Prepared directory for action: right\n",
      "Prepared directory for action: same\n",
      "Prepared directory for action: son\n",
      "Prepared directory for action: tell\n",
      "Prepared directory for action: thursday\n"
     ]
    }
   ],
   "source": [
    "#code that loops through folders to get actions\n",
    "dataset_folder = \"asl_dataset_word/archive (1)/extracted_videos_asl\"  # Update this to your dataset directory\n",
    "\n",
    "# Path for exported data (not used for video processing here, but kept for structure)\n",
    "DATA_PATH = os.path.join('MHI_ASL_DATA') \n",
    "\n",
    "# Ensure DATA_PATH exists\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "# List to hold the names of actions based on folder names in the dataset_folder\n",
    "actions = []\n",
    "action_count = 100\n",
    "counter = 0;\n",
    "#action count - limit the amount of labels.\n",
    "\n",
    "# Populate actions list with the names of directories in dataset_folder\n",
    "for entry in os.listdir(dataset_folder):\n",
    "    if counter >= action_count:\n",
    "        break\n",
    "    if os.path.isdir(os.path.join(dataset_folder, entry)):\n",
    "        actions.append(entry)\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "# Convert the list of actions to a numpy array (optional, depending on further use)\n",
    "actions = np.array(actions)\n",
    "\n",
    "# Print detected actions\n",
    "print(f\"Detected actions: {actions}\")\n",
    "\n",
    "# Optionally, prepare folders for each action in a separate data path\n",
    "for action in actions:\n",
    "    action_data_path = os.path.join(DATA_PATH, action)\n",
    "    if not os.path.exists(action_data_path):\n",
    "        os.makedirs(action_data_path)\n",
    "    print(f\"Prepared directory for action: {action}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e2b8161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "#test the size of the npy file has the same image size frame\n",
    "npy_file_path = 'MHI_ASL_Data/drink/17709.npy'  # Adjust the path as needed\n",
    "\n",
    "# Load the npy file\n",
    "test_array = np.load(npy_file_path)\n",
    "\n",
    "# Output the shape of the array\n",
    "print(test_array.shape)\n",
    "\n",
    "#list out all the action labels we have\n",
    "print(actions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b7cc3",
   "metadata": {},
   "source": [
    "# Preprocess Data, Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630d3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test is a function to split dataset into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Converts class vectors to binary class matrix for categorial crossentropy\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d4d39a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Label Map\n",
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2999436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book': 0,\n",
       " 'drink': 1,\n",
       " 'computer': 2,\n",
       " 'before': 3,\n",
       " 'chair': 4,\n",
       " 'go': 5,\n",
       " 'clothes': 6,\n",
       " 'who': 7,\n",
       " 'candy': 8,\n",
       " 'cousin': 9,\n",
       " 'deaf': 10,\n",
       " 'fine': 11,\n",
       " 'help': 12,\n",
       " 'no': 13,\n",
       " 'thin': 14,\n",
       " 'walk': 15,\n",
       " 'year': 16,\n",
       " 'yes': 17,\n",
       " 'all': 18,\n",
       " 'black': 19,\n",
       " 'cool': 20,\n",
       " 'finish': 21,\n",
       " 'hot': 22,\n",
       " 'like': 23,\n",
       " 'many': 24,\n",
       " 'mother': 25,\n",
       " 'now': 26,\n",
       " 'orange': 27,\n",
       " 'table': 28,\n",
       " 'thanksgiving': 29,\n",
       " 'what': 30,\n",
       " 'woman': 31,\n",
       " 'bed': 32,\n",
       " 'blue': 33,\n",
       " 'bowling': 34,\n",
       " 'can': 35,\n",
       " 'dog': 36,\n",
       " 'family': 37,\n",
       " 'fish': 38,\n",
       " 'graduate': 39,\n",
       " 'hat': 40,\n",
       " 'hearing': 41,\n",
       " 'kiss': 42,\n",
       " 'language': 43,\n",
       " 'later': 44,\n",
       " 'man': 45,\n",
       " 'shirt': 46,\n",
       " 'study': 47,\n",
       " 'tall': 48,\n",
       " 'white': 49,\n",
       " 'wrong': 50,\n",
       " 'accident': 51,\n",
       " 'apple': 52,\n",
       " 'bird': 53,\n",
       " 'change': 54,\n",
       " 'color': 55,\n",
       " 'corn': 56,\n",
       " 'cow': 57,\n",
       " 'dance': 58,\n",
       " 'dark': 59,\n",
       " 'doctor': 60,\n",
       " 'eat': 61,\n",
       " 'enjoy': 62,\n",
       " 'forget': 63,\n",
       " 'give': 64,\n",
       " 'last': 65,\n",
       " 'meet': 66,\n",
       " 'pink': 67,\n",
       " 'pizza': 68,\n",
       " 'play': 69,\n",
       " 'school': 70,\n",
       " 'secretary': 71,\n",
       " 'short': 72,\n",
       " 'time': 73,\n",
       " 'want': 74,\n",
       " 'work': 75,\n",
       " 'africa': 76,\n",
       " 'basketball': 77,\n",
       " 'birthday': 78,\n",
       " 'brown': 79,\n",
       " 'but': 80,\n",
       " 'cheat': 81,\n",
       " 'city': 82,\n",
       " 'cook': 83,\n",
       " 'decide': 84,\n",
       " 'full': 85,\n",
       " 'how': 86,\n",
       " 'jacket': 87,\n",
       " 'letter': 88,\n",
       " 'medicine': 89,\n",
       " 'need': 90,\n",
       " 'paint': 91,\n",
       " 'paper': 92,\n",
       " 'pull': 93,\n",
       " 'purple': 94,\n",
       " 'right': 95,\n",
       " 'same': 96,\n",
       " 'son': 97,\n",
       " 'tell': 98,\n",
       " 'thursday': 99}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a4ed8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'deaf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m sequences\u001b[38;5;241m.\u001b[39mappend(mhi_data)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Use the label_map to convert action names to integers\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m labels\u001b[38;5;241m.\u001b[39mappend(label_map[action_folder])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'deaf'"
     ]
    }
   ],
   "source": [
    "#For MHI - use this.\n",
    "sequences, labels = [], []\n",
    "for action_folder in os.listdir(DATA_PATH):\n",
    "    action_path = os.path.join(DATA_PATH, action_folder)\n",
    "    if os.path.isdir(action_path):\n",
    "        for file_name in os.listdir(action_path):\n",
    "            if file_name.endswith('.npy'):\n",
    "                # Load MHI data\n",
    "                mhi_path = os.path.join(action_path, file_name)\n",
    "                mhi_data = np.load(mhi_path)\n",
    "                \n",
    "                sequences.append(mhi_data)\n",
    "                \n",
    "                # Use the label_map to convert action names to integers\n",
    "                labels.append(label_map[action_folder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c900e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify code such that it only takes the actions - and preprocess it.\n",
    "# Initialize lists to store sequences and labels\n",
    "sequences, labels = [], []\n",
    "\n",
    "# Process each folder in DATA_PATH\n",
    "for action_folder in os.listdir(DATA_PATH):\n",
    "    if action_folder in actions:\n",
    "        action_path = os.path.join(DATA_PATH, action_folder)\n",
    "        if os.path.isdir(action_path):\n",
    "            for file_name in os.listdir(action_path):\n",
    "                if file_name.endswith('.npy'):\n",
    "                    # Load MHI data\n",
    "                    mhi_path = os.path.join(action_path, file_name)\n",
    "                    mhi_data = np.load(mhi_path)\n",
    "                    \n",
    "                    sequences.append(mhi_data)\n",
    "                    \n",
    "                    # Use the label_map to convert action names to integers\n",
    "                    labels.append(label_map[action_folder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01dbe42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1007, 200, 200, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "665baaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1007,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "468d624f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1007, 200, 200, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(sequences)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8538826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#label_encoder = LabelEncoder()\n",
    "#integer_encoded = label_encoder.fit_transform(labels)\n",
    "y = to_categorical(labels).astype(int)\n",
    "#y = to_categorical(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48ab0a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09f49dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, split into train, test, and dev (validate) dataset\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)\n",
    "\n",
    "# First, split into temp training and test sets\n",
    "X_temp, X_dev, y_temp, y_dev = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "# Then, split the temp training set into final training and dev (validation) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2b243f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((908, 200, 200, 3), (48, 200, 200, 3), (51, 200, 200, 3))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "155e9b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b7d75a",
   "metadata": {},
   "source": [
    "# Build and Train CNN Neural Network\n",
    "Taking from pre-trained image CNN\n",
    "Create base model from pre-trained model: MobileNet V3Small\n",
    "Step 1: Create Base Model from MobileNet V2 model developed at Google.\n",
    "Step 2: Freeze layers\n",
    "Step 3: Train new layers on dataset\n",
    "Step 4: Improve model via fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67657ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D , Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b5f6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create logs to view learning in real time\n",
    "log_dir = os.path.join('Logs_MHI_ASL_MobileNetV2')\n",
    "#tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "tb_callback = [TensorBoard(log_dir=log_dir,\n",
    "                         histogram_freq=1,\n",
    "                         write_graph=True,\n",
    "                         write_images=True,\n",
    "                         update_freq='epoch',\n",
    "                         profile_batch=2,\n",
    "                         embeddings_freq=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "877ad2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FD_SHAPE = (444, 444, 3)\n",
    "#MobileNetV3 uses input shape of (224, 224, 3)\n",
    "MHI_SHAPE = (224,224,3)\n",
    "#reshaped_data = data.reshape(-1, 480, 640, 1)\n",
    "# get the base model, exclude final dense layers - we will modify/output this\n",
    "base_model = tf.keras.applications.MobileNetV3Small(input_shape = MHI_SHAPE,\n",
    "                                               include_top = False,\n",
    "                                               weights = 'imagenet',\n",
    "                                               pooling='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f7061cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the convolutional base\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8bceba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobilenetV3small\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 200, 200, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)       (None, 200, 200, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " Conv (Conv2D)               (None, 100, 100, 16)         432       ['rescaling[0][0]']           \n",
      "                                                                                                  \n",
      " Conv/BatchNorm (BatchNorma  (None, 100, 100, 16)         64        ['Conv[0][0]']                \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.add (TFOpLambda)    (None, 100, 100, 16)         0         ['Conv/BatchNorm[0][0]']      \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (None, 100, 100, 16)         0         ['tf.math.add[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 100, 100, 16)         0         ['re_lu[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 100, 100, 16)         0         ['Conv/BatchNorm[0][0]',      \n",
      "                                                                     'tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/pa  (None, 101, 101, 16)         0         ['multiply[0][0]']            \n",
      " d (ZeroPadding2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise (D  (None, 50, 50, 16)           144       ['expanded_conv/depthwise/pad[\n",
      " epthwiseConv2D)                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/Ba  (None, 50, 50, 16)           64        ['expanded_conv/depthwise[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (None, 50, 50, 16)           0         ['expanded_conv/depthwise/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_exci  (None, 1, 1, 16)             0         ['re_lu_1[0][0]']             \n",
      " te/AvgPool (GlobalAverageP                                                                       \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_exci  (None, 1, 1, 8)              136       ['expanded_conv/squeeze_excite\n",
      " te/Conv (Conv2D)                                                   /AvgPool[0][0]']              \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_exci  (None, 1, 1, 8)              0         ['expanded_conv/squeeze_excite\n",
      " te/Relu (ReLU)                                                     /Conv[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_exci  (None, 1, 1, 16)             144       ['expanded_conv/squeeze_excite\n",
      " te/Conv_1 (Conv2D)                                                 /Relu[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.math.add_1 (TFOpLambda)  (None, 1, 1, 16)             0         ['expanded_conv/squeeze_excite\n",
      "                                                                    /Conv_1[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              (None, 1, 1, 16)             0         ['tf.math.add_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (None, 1, 1, 16)             0         ['re_lu_2[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_exci  (None, 50, 50, 16)           0         ['re_lu_1[0][0]',             \n",
      " te/Mul (Multiply)                                                   'tf.math.multiply_1[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv/project (Con  (None, 50, 50, 16)           256       ['expanded_conv/squeeze_excite\n",
      " v2D)                                                               /Mul[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv/project/Batc  (None, 50, 50, 16)           64        ['expanded_conv/project[0][0]'\n",
      " hNorm (BatchNormalization)                                         ]                             \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand (Co  (None, 50, 50, 72)           1152      ['expanded_conv/project/BatchN\n",
      " nv2D)                                                              orm[0][0]']                   \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand/Bat  (None, 50, 50, 72)           288       ['expanded_conv_1/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              (None, 50, 50, 72)           0         ['expanded_conv_1/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/  (None, 51, 51, 72)           0         ['re_lu_3[0][0]']             \n",
      " pad (ZeroPadding2D)                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise   (None, 25, 25, 72)           648       ['expanded_conv_1/depthwise/pa\n",
      " (DepthwiseConv2D)                                                  d[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/  (None, 25, 25, 72)           288       ['expanded_conv_1/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              (None, 25, 25, 72)           0         ['expanded_conv_1/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_1/project (C  (None, 25, 25, 24)           1728      ['re_lu_4[0][0]']             \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/project/Ba  (None, 25, 25, 24)           96        ['expanded_conv_1/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand (Co  (None, 25, 25, 88)           2112      ['expanded_conv_1/project/Batc\n",
      " nv2D)                                                              hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand/Bat  (None, 25, 25, 88)           352       ['expanded_conv_2/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              (None, 25, 25, 88)           0         ['expanded_conv_2/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise   (None, 25, 25, 88)           792       ['re_lu_5[0][0]']             \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise/  (None, 25, 25, 88)           352       ['expanded_conv_2/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)              (None, 25, 25, 88)           0         ['expanded_conv_2/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_2/project (C  (None, 25, 25, 24)           2112      ['re_lu_6[0][0]']             \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_2/project/Ba  (None, 25, 25, 24)           96        ['expanded_conv_2/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_2/Add (Add)   (None, 25, 25, 24)           0         ['expanded_conv_1/project/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'expanded_conv_2/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand (Co  (None, 25, 25, 96)           2304      ['expanded_conv_2/Add[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand/Bat  (None, 25, 25, 96)           384       ['expanded_conv_3/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.add_2 (TFOpLambda)  (None, 25, 25, 96)           0         ['expanded_conv_3/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)              (None, 25, 25, 96)           0         ['tf.math.add_2[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLa  (None, 25, 25, 96)           0         ['re_lu_7[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)       (None, 25, 25, 96)           0         ['expanded_conv_3/expand/Batch\n",
      "                                                                    Norm[0][0]',                  \n",
      "                                                                     'tf.math.multiply_2[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/  (None, 29, 29, 96)           0         ['multiply_1[0][0]']          \n",
      " pad (ZeroPadding2D)                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise   (None, 13, 13, 96)           2400      ['expanded_conv_3/depthwise/pa\n",
      " (DepthwiseConv2D)                                                  d[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/  (None, 13, 13, 96)           384       ['expanded_conv_3/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.add_3 (TFOpLambda)  (None, 13, 13, 96)           0         ['expanded_conv_3/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)              (None, 13, 13, 96)           0         ['tf.math.add_3[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLa  (None, 13, 13, 96)           0         ['re_lu_8[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)       (None, 13, 13, 96)           0         ['expanded_conv_3/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]',               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     'tf.math.multiply_3[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_ex  (None, 1, 1, 96)             0         ['multiply_2[0][0]']          \n",
      " cite/AvgPool (GlobalAverag                                                                       \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_ex  (None, 1, 1, 24)             2328      ['expanded_conv_3/squeeze_exci\n",
      " cite/Conv (Conv2D)                                                 te/AvgPool[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_ex  (None, 1, 1, 24)             0         ['expanded_conv_3/squeeze_exci\n",
      " cite/Relu (ReLU)                                                   te/Conv[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_ex  (None, 1, 1, 96)             2400      ['expanded_conv_3/squeeze_exci\n",
      " cite/Conv_1 (Conv2D)                                               te/Relu[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.add_4 (TFOpLambda)  (None, 1, 1, 96)             0         ['expanded_conv_3/squeeze_exci\n",
      "                                                                    te/Conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)              (None, 1, 1, 96)             0         ['tf.math.add_4[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLa  (None, 1, 1, 96)             0         ['re_lu_9[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_ex  (None, 13, 13, 96)           0         ['multiply_2[0][0]',          \n",
      " cite/Mul (Multiply)                                                 'tf.math.multiply_4[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_3/project (C  (None, 13, 13, 40)           3840      ['expanded_conv_3/squeeze_exci\n",
      " onv2D)                                                             te/Mul[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_3/project/Ba  (None, 13, 13, 40)           160       ['expanded_conv_3/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand (Co  (None, 13, 13, 240)          9600      ['expanded_conv_3/project/Batc\n",
      " nv2D)                                                              hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand/Bat  (None, 13, 13, 240)          960       ['expanded_conv_4/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.add_5 (TFOpLambda)  (None, 13, 13, 240)          0         ['expanded_conv_4/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             (None, 13, 13, 240)          0         ['tf.math.add_5[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLa  (None, 13, 13, 240)          0         ['re_lu_10[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)       (None, 13, 13, 240)          0         ['expanded_conv_4/expand/Batch\n",
      "                                                                    Norm[0][0]',                  \n",
      "                                                                     'tf.math.multiply_5[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise   (None, 13, 13, 240)          6000      ['multiply_3[0][0]']          \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise/  (None, 13, 13, 240)          960       ['expanded_conv_4/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.add_6 (TFOpLambda)  (None, 13, 13, 240)          0         ['expanded_conv_4/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)             (None, 13, 13, 240)          0         ['tf.math.add_6[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLa  (None, 13, 13, 240)          0         ['re_lu_11[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)       (None, 13, 13, 240)          0         ['expanded_conv_4/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]',               \n",
      "                                                                     'tf.math.multiply_6[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_ex  (None, 1, 1, 240)            0         ['multiply_4[0][0]']          \n",
      " cite/AvgPool (GlobalAverag                                                                       \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_ex  (None, 1, 1, 64)             15424     ['expanded_conv_4/squeeze_exci\n",
      " cite/Conv (Conv2D)                                                 te/AvgPool[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_ex  (None, 1, 1, 64)             0         ['expanded_conv_4/squeeze_exci\n",
      " cite/Relu (ReLU)                                                   te/Conv[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_ex  (None, 1, 1, 240)            15600     ['expanded_conv_4/squeeze_exci\n",
      " cite/Conv_1 (Conv2D)                                               te/Relu[0][0]']               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.math.add_7 (TFOpLambda)  (None, 1, 1, 240)            0         ['expanded_conv_4/squeeze_exci\n",
      "                                                                    te/Conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)             (None, 1, 1, 240)            0         ['tf.math.add_7[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLa  (None, 1, 1, 240)            0         ['re_lu_12[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_ex  (None, 13, 13, 240)          0         ['multiply_4[0][0]',          \n",
      " cite/Mul (Multiply)                                                 'tf.math.multiply_7[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_4/project (C  (None, 13, 13, 40)           9600      ['expanded_conv_4/squeeze_exci\n",
      " onv2D)                                                             te/Mul[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_4/project/Ba  (None, 13, 13, 40)           160       ['expanded_conv_4/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_4/Add (Add)   (None, 13, 13, 40)           0         ['expanded_conv_3/project/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'expanded_conv_4/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand (Co  (None, 13, 13, 240)          9600      ['expanded_conv_4/Add[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand/Bat  (None, 13, 13, 240)          960       ['expanded_conv_5/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.add_8 (TFOpLambda)  (None, 13, 13, 240)          0         ['expanded_conv_5/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)             (None, 13, 13, 240)          0         ['tf.math.add_8[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLa  (None, 13, 13, 240)          0         ['re_lu_13[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)       (None, 13, 13, 240)          0         ['expanded_conv_5/expand/Batch\n",
      "                                                                    Norm[0][0]',                  \n",
      "                                                                     'tf.math.multiply_8[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise   (None, 13, 13, 240)          6000      ['multiply_5[0][0]']          \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise/  (None, 13, 13, 240)          960       ['expanded_conv_5/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.add_9 (TFOpLambda)  (None, 13, 13, 240)          0         ['expanded_conv_5/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)             (None, 13, 13, 240)          0         ['tf.math.add_9[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLa  (None, 13, 13, 240)          0         ['re_lu_14[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)       (None, 13, 13, 240)          0         ['expanded_conv_5/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]',               \n",
      "                                                                     'tf.math.multiply_9[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_ex  (None, 1, 1, 240)            0         ['multiply_6[0][0]']          \n",
      " cite/AvgPool (GlobalAverag                                                                       \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_ex  (None, 1, 1, 64)             15424     ['expanded_conv_5/squeeze_exci\n",
      " cite/Conv (Conv2D)                                                 te/AvgPool[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_ex  (None, 1, 1, 64)             0         ['expanded_conv_5/squeeze_exci\n",
      " cite/Relu (ReLU)                                                   te/Conv[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_ex  (None, 1, 1, 240)            15600     ['expanded_conv_5/squeeze_exci\n",
      " cite/Conv_1 (Conv2D)                                               te/Relu[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.add_10 (TFOpLambda  (None, 1, 1, 240)            0         ['expanded_conv_5/squeeze_exci\n",
      " )                                                                  te/Conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)             (None, 1, 1, 240)            0         ['tf.math.add_10[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpL  (None, 1, 1, 240)            0         ['re_lu_15[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " expanded_conv_5/squeeze_ex  (None, 13, 13, 240)          0         ['multiply_6[0][0]',          \n",
      " cite/Mul (Multiply)                                                 'tf.math.multiply_10[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_5/project (C  (None, 13, 13, 40)           9600      ['expanded_conv_5/squeeze_exci\n",
      " onv2D)                                                             te/Mul[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_5/project/Ba  (None, 13, 13, 40)           160       ['expanded_conv_5/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_5/Add (Add)   (None, 13, 13, 40)           0         ['expanded_conv_4/Add[0][0]', \n",
      "                                                                     'expanded_conv_5/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand (Co  (None, 13, 13, 120)          4800      ['expanded_conv_5/Add[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand/Bat  (None, 13, 13, 120)          480       ['expanded_conv_6/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.add_11 (TFOpLambda  (None, 13, 13, 120)          0         ['expanded_conv_6/expand/Batch\n",
      " )                                                                  Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)             (None, 13, 13, 120)          0         ['tf.math.add_11[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpL  (None, 13, 13, 120)          0         ['re_lu_16[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)       (None, 13, 13, 120)          0         ['expanded_conv_6/expand/Batch\n",
      "                                                                    Norm[0][0]',                  \n",
      "                                                                     'tf.math.multiply_11[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise   (None, 13, 13, 120)          3000      ['multiply_7[0][0]']          \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise/  (None, 13, 13, 120)          480       ['expanded_conv_6/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.add_12 (TFOpLambda  (None, 13, 13, 120)          0         ['expanded_conv_6/depthwise/Ba\n",
      " )                                                                  tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)             (None, 13, 13, 120)          0         ['tf.math.add_12[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpL  (None, 13, 13, 120)          0         ['re_lu_17[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)       (None, 13, 13, 120)          0         ['expanded_conv_6/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]',               \n",
      "                                                                     'tf.math.multiply_12[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_ex  (None, 1, 1, 120)            0         ['multiply_8[0][0]']          \n",
      " cite/AvgPool (GlobalAverag                                                                       \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_ex  (None, 1, 1, 32)             3872      ['expanded_conv_6/squeeze_exci\n",
      " cite/Conv (Conv2D)                                                 te/AvgPool[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_ex  (None, 1, 1, 32)             0         ['expanded_conv_6/squeeze_exci\n",
      " cite/Relu (ReLU)                                                   te/Conv[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_ex  (None, 1, 1, 120)            3960      ['expanded_conv_6/squeeze_exci\n",
      " cite/Conv_1 (Conv2D)                                               te/Relu[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.add_13 (TFOpLambda  (None, 1, 1, 120)            0         ['expanded_conv_6/squeeze_exci\n",
      " )                                                                  te/Conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)             (None, 1, 1, 120)            0         ['tf.math.add_13[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpL  (None, 1, 1, 120)            0         ['re_lu_18[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_ex  (None, 13, 13, 120)          0         ['multiply_8[0][0]',          \n",
      " cite/Mul (Multiply)                                                 'tf.math.multiply_13[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_6/project (C  (None, 13, 13, 48)           5760      ['expanded_conv_6/squeeze_exci\n",
      " onv2D)                                                             te/Mul[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_6/project/Ba  (None, 13, 13, 48)           192       ['expanded_conv_6/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " expanded_conv_7/expand (Co  (None, 13, 13, 144)          6912      ['expanded_conv_6/project/Batc\n",
      " nv2D)                                                              hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand/Bat  (None, 13, 13, 144)          576       ['expanded_conv_7/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.add_14 (TFOpLambda  (None, 13, 13, 144)          0         ['expanded_conv_7/expand/Batch\n",
      " )                                                                  Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)             (None, 13, 13, 144)          0         ['tf.math.add_14[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpL  (None, 13, 13, 144)          0         ['re_lu_19[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)       (None, 13, 13, 144)          0         ['expanded_conv_7/expand/Batch\n",
      "                                                                    Norm[0][0]',                  \n",
      "                                                                     'tf.math.multiply_14[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise   (None, 13, 13, 144)          3600      ['multiply_9[0][0]']          \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise/  (None, 13, 13, 144)          576       ['expanded_conv_7/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.add_15 (TFOpLambda  (None, 13, 13, 144)          0         ['expanded_conv_7/depthwise/Ba\n",
      " )                                                                  tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)             (None, 13, 13, 144)          0         ['tf.math.add_15[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpL  (None, 13, 13, 144)          0         ['re_lu_20[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_10 (Multiply)      (None, 13, 13, 144)          0         ['expanded_conv_7/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]',               \n",
      "                                                                     'tf.math.multiply_15[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_ex  (None, 1, 1, 144)            0         ['multiply_10[0][0]']         \n",
      " cite/AvgPool (GlobalAverag                                                                       \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_ex  (None, 1, 1, 40)             5800      ['expanded_conv_7/squeeze_exci\n",
      " cite/Conv (Conv2D)                                                 te/AvgPool[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_ex  (None, 1, 1, 40)             0         ['expanded_conv_7/squeeze_exci\n",
      " cite/Relu (ReLU)                                                   te/Conv[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_ex  (None, 1, 1, 144)            5904      ['expanded_conv_7/squeeze_exci\n",
      " cite/Conv_1 (Conv2D)                                               te/Relu[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.add_16 (TFOpLambda  (None, 1, 1, 144)            0         ['expanded_conv_7/squeeze_exci\n",
      " )                                                                  te/Conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)             (None, 1, 1, 144)            0         ['tf.math.add_16[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpL  (None, 1, 1, 144)            0         ['re_lu_21[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_ex  (None, 13, 13, 144)          0         ['multiply_10[0][0]',         \n",
      " cite/Mul (Multiply)                                                 'tf.math.multiply_16[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_7/project (C  (None, 13, 13, 48)           6912      ['expanded_conv_7/squeeze_exci\n",
      " onv2D)                                                             te/Mul[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_7/project/Ba  (None, 13, 13, 48)           192       ['expanded_conv_7/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_7/Add (Add)   (None, 13, 13, 48)           0         ['expanded_conv_6/project/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'expanded_conv_7/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand (Co  (None, 13, 13, 288)          13824     ['expanded_conv_7/Add[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand/Bat  (None, 13, 13, 288)          1152      ['expanded_conv_8/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.add_17 (TFOpLambda  (None, 13, 13, 288)          0         ['expanded_conv_8/expand/Batch\n",
      " )                                                                  Norm[0][0]']                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " re_lu_22 (ReLU)             (None, 13, 13, 288)          0         ['tf.math.add_17[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpL  (None, 13, 13, 288)          0         ['re_lu_22[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_11 (Multiply)      (None, 13, 13, 288)          0         ['expanded_conv_8/expand/Batch\n",
      "                                                                    Norm[0][0]',                  \n",
      "                                                                     'tf.math.multiply_17[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/  (None, 17, 17, 288)          0         ['multiply_11[0][0]']         \n",
      " pad (ZeroPadding2D)                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise   (None, 7, 7, 288)            7200      ['expanded_conv_8/depthwise/pa\n",
      " (DepthwiseConv2D)                                                  d[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/  (None, 7, 7, 288)            1152      ['expanded_conv_8/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.add_18 (TFOpLambda  (None, 7, 7, 288)            0         ['expanded_conv_8/depthwise/Ba\n",
      " )                                                                  tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)             (None, 7, 7, 288)            0         ['tf.math.add_18[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpL  (None, 7, 7, 288)            0         ['re_lu_23[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_12 (Multiply)      (None, 7, 7, 288)            0         ['expanded_conv_8/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]',               \n",
      "                                                                     'tf.math.multiply_18[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_ex  (None, 1, 1, 288)            0         ['multiply_12[0][0]']         \n",
      " cite/AvgPool (GlobalAverag                                                                       \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_ex  (None, 1, 1, 72)             20808     ['expanded_conv_8/squeeze_exci\n",
      " cite/Conv (Conv2D)                                                 te/AvgPool[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_ex  (None, 1, 1, 72)             0         ['expanded_conv_8/squeeze_exci\n",
      " cite/Relu (ReLU)                                                   te/Conv[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_ex  (None, 1, 1, 288)            21024     ['expanded_conv_8/squeeze_exci\n",
      " cite/Conv_1 (Conv2D)                                               te/Relu[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.add_19 (TFOpLambda  (None, 1, 1, 288)            0         ['expanded_conv_8/squeeze_exci\n",
      " )                                                                  te/Conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)             (None, 1, 1, 288)            0         ['tf.math.add_19[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpL  (None, 1, 1, 288)            0         ['re_lu_24[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_ex  (None, 7, 7, 288)            0         ['multiply_12[0][0]',         \n",
      " cite/Mul (Multiply)                                                 'tf.math.multiply_19[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_8/project (C  (None, 7, 7, 96)             27648     ['expanded_conv_8/squeeze_exci\n",
      " onv2D)                                                             te/Mul[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_8/project/Ba  (None, 7, 7, 96)             384       ['expanded_conv_8/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand (Co  (None, 7, 7, 576)            55296     ['expanded_conv_8/project/Batc\n",
      " nv2D)                                                              hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand/Bat  (None, 7, 7, 576)            2304      ['expanded_conv_9/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.add_20 (TFOpLambda  (None, 7, 7, 576)            0         ['expanded_conv_9/expand/Batch\n",
      " )                                                                  Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)             (None, 7, 7, 576)            0         ['tf.math.add_20[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_20 (TFOpL  (None, 7, 7, 576)            0         ['re_lu_25[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_13 (Multiply)      (None, 7, 7, 576)            0         ['expanded_conv_9/expand/Batch\n",
      "                                                                    Norm[0][0]',                  \n",
      "                                                                     'tf.math.multiply_20[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise   (None, 7, 7, 576)            14400     ['multiply_13[0][0]']         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise/  (None, 7, 7, 576)            2304      ['expanded_conv_9/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.add_21 (TFOpLambda  (None, 7, 7, 576)            0         ['expanded_conv_9/depthwise/Ba\n",
      " )                                                                  tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)             (None, 7, 7, 576)            0         ['tf.math.add_21[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_21 (TFOpL  (None, 7, 7, 576)            0         ['re_lu_26[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_14 (Multiply)      (None, 7, 7, 576)            0         ['expanded_conv_9/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]',               \n",
      "                                                                     'tf.math.multiply_21[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_ex  (None, 1, 1, 576)            0         ['multiply_14[0][0]']         \n",
      " cite/AvgPool (GlobalAverag                                                                       \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_ex  (None, 1, 1, 144)            83088     ['expanded_conv_9/squeeze_exci\n",
      " cite/Conv (Conv2D)                                                 te/AvgPool[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_ex  (None, 1, 1, 144)            0         ['expanded_conv_9/squeeze_exci\n",
      " cite/Relu (ReLU)                                                   te/Conv[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_ex  (None, 1, 1, 576)            83520     ['expanded_conv_9/squeeze_exci\n",
      " cite/Conv_1 (Conv2D)                                               te/Relu[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.add_22 (TFOpLambda  (None, 1, 1, 576)            0         ['expanded_conv_9/squeeze_exci\n",
      " )                                                                  te/Conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)             (None, 1, 1, 576)            0         ['tf.math.add_22[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_22 (TFOpL  (None, 1, 1, 576)            0         ['re_lu_27[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_ex  (None, 7, 7, 576)            0         ['multiply_14[0][0]',         \n",
      " cite/Mul (Multiply)                                                 'tf.math.multiply_22[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_9/project (C  (None, 7, 7, 96)             55296     ['expanded_conv_9/squeeze_exci\n",
      " onv2D)                                                             te/Mul[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_9/project/Ba  (None, 7, 7, 96)             384       ['expanded_conv_9/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_9/Add (Add)   (None, 7, 7, 96)             0         ['expanded_conv_8/project/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'expanded_conv_9/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand (C  (None, 7, 7, 576)            55296     ['expanded_conv_9/Add[0][0]'] \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand/Ba  (None, 7, 7, 576)            2304      ['expanded_conv_10/expand[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.add_23 (TFOpLambda  (None, 7, 7, 576)            0         ['expanded_conv_10/expand/Batc\n",
      " )                                                                  hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)             (None, 7, 7, 576)            0         ['tf.math.add_23[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_23 (TFOpL  (None, 7, 7, 576)            0         ['re_lu_28[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_15 (Multiply)      (None, 7, 7, 576)            0         ['expanded_conv_10/expand/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'tf.math.multiply_23[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise  (None, 7, 7, 576)            14400     ['multiply_15[0][0]']         \n",
      "  (DepthwiseConv2D)                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise  (None, 7, 7, 576)            2304      ['expanded_conv_10/depthwise[0\n",
      " /BatchNorm (BatchNormaliza                                         ][0]']                        \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.add_24 (TFOpLambda  (None, 7, 7, 576)            0         ['expanded_conv_10/depthwise/B\n",
      " )                                                                  atchNorm[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " re_lu_29 (ReLU)             (None, 7, 7, 576)            0         ['tf.math.add_24[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_24 (TFOpL  (None, 7, 7, 576)            0         ['re_lu_29[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_16 (Multiply)      (None, 7, 7, 576)            0         ['expanded_conv_10/depthwise/B\n",
      "                                                                    atchNorm[0][0]',              \n",
      "                                                                     'tf.math.multiply_24[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_e  (None, 1, 1, 576)            0         ['multiply_16[0][0]']         \n",
      " xcite/AvgPool (GlobalAvera                                                                       \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_e  (None, 1, 1, 144)            83088     ['expanded_conv_10/squeeze_exc\n",
      " xcite/Conv (Conv2D)                                                ite/AvgPool[0][0]']           \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_e  (None, 1, 1, 144)            0         ['expanded_conv_10/squeeze_exc\n",
      " xcite/Relu (ReLU)                                                  ite/Conv[0][0]']              \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_e  (None, 1, 1, 576)            83520     ['expanded_conv_10/squeeze_exc\n",
      " xcite/Conv_1 (Conv2D)                                              ite/Relu[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.add_25 (TFOpLambda  (None, 1, 1, 576)            0         ['expanded_conv_10/squeeze_exc\n",
      " )                                                                  ite/Conv_1[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)             (None, 1, 1, 576)            0         ['tf.math.add_25[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_25 (TFOpL  (None, 1, 1, 576)            0         ['re_lu_30[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_e  (None, 7, 7, 576)            0         ['multiply_16[0][0]',         \n",
      " xcite/Mul (Multiply)                                                'tf.math.multiply_25[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_10/project (  (None, 7, 7, 96)             55296     ['expanded_conv_10/squeeze_exc\n",
      " Conv2D)                                                            ite/Mul[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_10/project/B  (None, 7, 7, 96)             384       ['expanded_conv_10/project[0][\n",
      " atchNorm (BatchNormalizati                                         0]']                          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_10/Add (Add)  (None, 7, 7, 96)             0         ['expanded_conv_9/Add[0][0]', \n",
      "                                                                     'expanded_conv_10/project/Bat\n",
      "                                                                    chNorm[0][0]']                \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 7, 7, 576)            55296     ['expanded_conv_10/Add[0][0]']\n",
      "                                                                                                  \n",
      " Conv_1/BatchNorm (BatchNor  (None, 7, 7, 576)            2304      ['Conv_1[0][0]']              \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " tf.math.add_26 (TFOpLambda  (None, 7, 7, 576)            0         ['Conv_1/BatchNorm[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)             (None, 7, 7, 576)            0         ['tf.math.add_26[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_26 (TFOpL  (None, 7, 7, 576)            0         ['re_lu_31[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_17 (Multiply)      (None, 7, 7, 576)            0         ['Conv_1/BatchNorm[0][0]',    \n",
      "                                                                     'tf.math.multiply_26[0][0]'] \n",
      "                                                                                                  \n",
      " max_pool (GlobalMaxPooling  (None, 576)                  0         ['multiply_17[0][0]']         \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 939120 (3.58 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 939120 (3.58 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#get the base model summary\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3da256c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MobileNetV3 without additional dense layer - add softmax classification layer\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b30483e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Add classification head/own layers\n",
    "z = base_model.output\n",
    "# If you want to include GlobalAveragePooling2D, you can directly use 'pooling=max' in the base model as done above\n",
    "z = Dense(1024, activation='relu')(z)  # Dense layer 1\n",
    "z = Dense(1024, activation='relu')(z)  # Dense layer 2\n",
    "z = Dense(512, activation='relu')(z)   # Dense layer 3\n",
    "preds = Dense(actions.shape[0], activation='softmax')(z)  # Final layer with softmax activation\n",
    "\n",
    "# Create the full model\n",
    "model = Model(inputs=base_model.input, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ecd25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixed learning rate: adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003) #0.001 can be changed.\n",
    "\n",
    "#learning rate decay for Adam\n",
    "initial_learning_rate = 0.0003  # Starting learning rate\n",
    "decay_steps = 100000           # After how many steps to apply decay\n",
    "decay_rate = 0.96              # Decay rate\n",
    "staircase = True               # Apply decay in a staircase fashion\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps,\n",
    "    decay_rate,\n",
    "    staircase=staircase\n",
    ")\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)  # Use the learning rate schedule here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b399c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efd02f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "29/29 [==============================] - 6s 152ms/step - loss: 0.4262 - categorical_accuracy: 0.9394\n",
      "Epoch 2/2000\n",
      "29/29 [==============================] - 4s 147ms/step - loss: 0.4050 - categorical_accuracy: 0.9471\n",
      "Epoch 3/2000\n",
      "29/29 [==============================] - 4s 150ms/step - loss: 0.3757 - categorical_accuracy: 0.9548\n",
      "Epoch 4/2000\n",
      "29/29 [==============================] - 4s 130ms/step - loss: 0.3447 - categorical_accuracy: 0.9548\n",
      "Epoch 5/2000\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.3280 - categorical_accuracy: 0.9559\n",
      "Epoch 6/2000\n",
      "29/29 [==============================] - 4s 140ms/step - loss: 0.3059 - categorical_accuracy: 0.9615\n",
      "Epoch 7/2000\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 0.2864 - categorical_accuracy: 0.9681\n",
      "Epoch 8/2000\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 0.2724 - categorical_accuracy: 0.9692\n",
      "Epoch 9/2000\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.2592 - categorical_accuracy: 0.9725\n",
      "Epoch 10/2000\n",
      "29/29 [==============================] - 4s 139ms/step - loss: 0.2490 - categorical_accuracy: 0.9736\n",
      "Epoch 11/2000\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 0.2341 - categorical_accuracy: 0.9747\n",
      "Epoch 12/2000\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.2275 - categorical_accuracy: 0.9758\n",
      "Epoch 13/2000\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.2061 - categorical_accuracy: 0.9769\n",
      "Epoch 14/2000\n",
      "29/29 [==============================] - 4s 148ms/step - loss: 0.1921 - categorical_accuracy: 0.9802\n",
      "Epoch 15/2000\n",
      "29/29 [==============================] - 4s 152ms/step - loss: 0.1894 - categorical_accuracy: 0.9802\n",
      "Epoch 16/2000\n",
      "29/29 [==============================] - 4s 129ms/step - loss: 0.1748 - categorical_accuracy: 0.9802\n",
      "Epoch 17/2000\n",
      "29/29 [==============================] - 4s 130ms/step - loss: 0.1689 - categorical_accuracy: 0.9835\n",
      "Epoch 18/2000\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 0.1620 - categorical_accuracy: 0.9868\n",
      "Epoch 19/2000\n",
      "29/29 [==============================] - 4s 140ms/step - loss: 0.1485 - categorical_accuracy: 0.9890\n",
      "Epoch 20/2000\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.1472 - categorical_accuracy: 0.9879\n",
      "Epoch 21/2000\n",
      "29/29 [==============================] - 4s 143ms/step - loss: 0.1401 - categorical_accuracy: 0.9912\n",
      "Epoch 22/2000\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.1340 - categorical_accuracy: 0.9879\n",
      "Epoch 23/2000\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 0.1257 - categorical_accuracy: 0.9901\n",
      "Epoch 24/2000\n",
      "29/29 [==============================] - 4s 144ms/step - loss: 0.1187 - categorical_accuracy: 0.9923\n",
      "Epoch 25/2000\n",
      "29/29 [==============================] - 4s 142ms/step - loss: 0.1215 - categorical_accuracy: 0.9901\n",
      "Epoch 26/2000\n",
      "29/29 [==============================] - 5s 156ms/step - loss: 0.1132 - categorical_accuracy: 0.9901\n",
      "Epoch 27/2000\n",
      "29/29 [==============================] - 4s 148ms/step - loss: 0.1063 - categorical_accuracy: 0.9901\n",
      "Epoch 28/2000\n",
      "29/29 [==============================] - 4s 148ms/step - loss: 0.1040 - categorical_accuracy: 0.9901\n",
      "Epoch 29/2000\n",
      "29/29 [==============================] - 4s 148ms/step - loss: 0.0998 - categorical_accuracy: 0.9923\n",
      "Epoch 30/2000\n",
      "11/29 [==========>...................] - ETA: 2s - loss: 0.0900 - categorical_accuracy: 0.9915"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Train the model - MobileNetV3Small as pretrained model. Tensorboard callback.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, validation_data \u001b[38;5;241m=\u001b[39m (X_dev, y_dev), batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[tb_callback])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train the model - MobileNetV3Small as pretrained model. Tensorboard callback.\n",
    "model.fit(X_train, y_train, epochs=1000, validation_data = (X_dev, y_dev), batch_size = 8, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84279e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model (for future load and training purposes)\n",
    "model.save('MobileNetV3Small_first.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf9e74",
   "metadata": {},
   "source": [
    "## Try out ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b8e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224fd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f696789",
   "metadata": {},
   "source": [
    "## VGG From Scratch\n",
    "VGG16 is a CNN architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85e3c25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhatminh2h/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "2024-04-07 03:32:12.055439: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-07 03:32:12.057118: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-04-07 03:32:12.234082: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 301989888 exceeds 10% of free system memory.\n",
      "2024-04-07 03:32:12.310465: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 301989888 exceeds 10% of free system memory.\n",
      "2024-04-07 03:32:12.355317: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 301989888 exceeds 10% of free system memory.\n",
      "2024-04-07 03:32:12.456235: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2024-04-07 03:32:12.469475: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 67108864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18432</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">75,501,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,194,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18432\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m75,501,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │     \u001b[38;5;34m8,194,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115,191,568</span> (439.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m115,191,568\u001b[0m (439.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115,191,568</span> (439.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m115,191,568\u001b[0m (439.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MHI_SHAPE = (200,200,3)\n",
    "\n",
    "model_VGG = Sequential()\n",
    "#Block 1\n",
    "model_VGG.add(Conv2D(input_shape=MHI_SHAPE,filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "#Block 2\n",
    "model_VGG.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "#Block 3\n",
    "model_VGG.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "#Block 4\n",
    "model_VGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "#Block 5\n",
    "model_VGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model_VGG.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "#Fully Connected Layers\n",
    "model_VGG.add(Flatten())\n",
    "model_VGG.add(Dense(units=4096,activation=\"relu\"))\n",
    "model_VGG.add(Dense(units=4096,activation=\"relu\"))\n",
    "#softmax units is dependent on the labels we want to extract out.\n",
    "model_VGG.add(Dense(units=actions.shape[0], activation=\"softmax\"))\n",
    "\n",
    "#then, generate model summary\n",
    "model_VGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07ef3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom learning rate for Adam\n",
    "\n",
    "initial_learning_rate = 0.0003  # Starting learning rate\n",
    "decay_steps = 100000           # After how many steps to apply decay\n",
    "decay_rate = 0.96              # Decay rate\n",
    "staircase = True               # Apply decay in a staircase fashion\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps,\n",
    "    decay_rate,\n",
    "    staircase=staircase\n",
    ")\n",
    "\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)  # Use the learning rate schedule here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fbe2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_VGG.compile(optimizer=adam_opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c1f5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks, implement model checkpoint and early stopping\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#val - represent validation metrics. therefore getting val_accuracy as metrics.\n",
    "checkpoint = ModelCheckpoint(\"vgg16_best.keras\", monitor='val_categorial_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "#early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "#Tensorboard\n",
    "#create logs to view learning in real time\n",
    "log_path = os.path.join('Logs_MHI_ASL_VGG')\n",
    "tb_callback = TensorBoard(log_dir=log_path)\n",
    "\n",
    "my_callbacks = [\n",
    "    #keras.callbacks.EarlyStopping(patience=2),\n",
    "    keras.callbacks.ModelCheckpoint(\"vgg16_best.keras\", monitor='val_categorial_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto'),\n",
    "    keras.callbacks.TensorBoard(log_dir=log_path),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a909fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3173s\u001b[0m 9s/step - categorical_accuracy: 3.5496e-04 - loss: 7.6668 - val_categorical_accuracy: 0.0000e+00 - val_loss: 7.6033\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhatminh2h/.local/lib/python3.10/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_categorial_accuracy available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3166s\u001b[0m 9s/step - categorical_accuracy: 0.0017 - loss: 7.5982 - val_categorical_accuracy: 0.0000e+00 - val_loss: 7.6085\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 05:18:57.813682: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3185s\u001b[0m 9s/step - categorical_accuracy: 7.2651e-04 - loss: 7.5907 - val_categorical_accuracy: 0.0000e+00 - val_loss: 7.6264\n",
      "Epoch 4/1000\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3181s\u001b[0m 9s/step - categorical_accuracy: 0.0017 - loss: 7.5700 - val_categorical_accuracy: 0.0036 - val_loss: 7.6710\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 07:05:03.019732: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3189s\u001b[0m 9s/step - categorical_accuracy: 0.0010 - loss: 7.5565 - val_categorical_accuracy: 0.0000e+00 - val_loss: 7.6743\n",
      "Epoch 6/1000\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3163s\u001b[0m 9s/step - categorical_accuracy: 8.3488e-04 - loss: 7.5544 - val_categorical_accuracy: 0.0036 - val_loss: 7.7149\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 08:50:55.119266: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3167s\u001b[0m 9s/step - categorical_accuracy: 0.0013 - loss: 7.5453 - val_categorical_accuracy: 0.0000e+00 - val_loss: 7.6763\n",
      "Epoch 8/1000\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3167s\u001b[0m 9s/step - categorical_accuracy: 0.0015 - loss: 7.5519 - val_categorical_accuracy: 0.0000e+00 - val_loss: 7.7096\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 10:36:28.843219: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3176s\u001b[0m 9s/step - categorical_accuracy: 0.0011 - loss: 7.5508 - val_categorical_accuracy: 0.0000e+00 - val_loss: 7.6822\n",
      "Epoch 10/1000\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3173s\u001b[0m 9s/step - categorical_accuracy: 0.0011 - loss: 7.5501 - val_categorical_accuracy: 0.0000e+00 - val_loss: 7.7055\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 12:22:17.721709: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 84/337\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39:34\u001b[0m 9s/step - categorical_accuracy: 0.0034 - loss: 7.5409"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3594/3182592463.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Finally, train the model using fit, callback for modelsavepoint and tensorboard (to visualize ML training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_VGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m                     callbacks.on_train_batch_end(\n\u001b[1;32m    327\u001b[0m                         \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             outputs = self.distribute_strategy.run(\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             )\n\u001b[1;32m    121\u001b[0m             outputs = reduce_per_replica(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1669\u001b[0m       \u001b[0;31m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m       \u001b[0;31m# applied when the caller is also in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1672\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1673\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3259\u001b[0m     \u001b[0m_require_cross_replica_or_default_context_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3261\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mtrainable_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1062\u001b[0m               output_gradients))\n\u001b[1;32m   1063\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise ValueError(\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[0;31m# to use the nn_ops functions, we would have to convert `padding` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m   \u001b[0;31m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m   \u001b[0;31m# in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m   return [\n\u001b[0;32m--> 584\u001b[0;31m       gen_nn_ops.conv2d_backprop_input(\n\u001b[0m\u001b[1;32m    585\u001b[0m           \u001b[0mshape_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1863\u001b[0m         data_format, \"dilations\", dilations)\n\u001b[1;32m   1864\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m       return conv2d_backprop_input_eager_fallback(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Finally, train the model using fit, callback for modelsavepoint and tensorboard (to visualize ML training)\n",
    "model_VGG.fit(X_train, y_train, epochs=1000, validation_data=(X_dev, y_dev), batch_size=32, validation_steps = 10, callbacks=[tb_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa506d1",
   "metadata": {},
   "source": [
    "# Test the Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_cnn = load_model('MobileNetV2_first.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6aef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: continue to train the model (when increased the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c81e3654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab8a2356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sorry'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "563504e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 275ms/step\n",
      "[1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "print(ytrue)\n",
    "len(yhat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e551c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6, 4],\n",
       "        [4, 6]],\n",
       "\n",
       "       [[6, 4],\n",
       "        [4, 6]]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d3b0780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f01bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
