{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Load parquet data into dataset_parquet for training.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.regularizers import l2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import time\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    # root = os.path.join(\"/\", \"kaggle\", \"input\", \"asl-signs\") \n",
    "    root = os.path.join(\"..\",\"data\", \"ASL-ds\")\n",
    "    DATA_LIMIT = 600\n",
    "    BATCH_SIZE = 8\n",
    "    VIDEO_LENGTH = 25\n",
    "    TRAIN_VAL_SPLIT = 0.9\n",
    "    WANDB_RUN = \"mediapipe-asl-dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIPS :  40\n",
      "EYE_LEFT :  20\n",
      "EYE_RIGHT :  20\n",
      "LEFT_HAND :  21\n",
      "RIGHT_HAND :  21\n",
      "LEFT_POSE :  5\n",
      "RIGHT_POSE :  5\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "LIPS_IDXS0 = np.array([\n",
    "        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "    ])\n",
    "\n",
    "EYE_LEFT = np.array([33, 7, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 471, 470, 469, 472])\n",
    "EYE_RIGHT = np.array([362, 398, 384, 385, 386, 387, 388, 466, 263, 249, 390, 373, 374, 380, 381, 382, 476, 475, 474, 477])\n",
    "# Landmark indices in original data\n",
    "LEFT_HAND_IDXS0 = np.arange(468,489)\n",
    "RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
    "LEFT_POSE_IDXS0 = np.array([502, 504, 506, 508, 510])\n",
    "RIGHT_POSE_IDXS0 = np.array([503, 505, 507, 509, 511])\n",
    "\n",
    "print(\"LIPS : \",len(LIPS_IDXS0))\n",
    "print(\"EYE_LEFT : \",len(EYE_LEFT))\n",
    "print(\"EYE_RIGHT : \",len(EYE_RIGHT))\n",
    "print(\"LEFT_HAND : \",len(LEFT_HAND_IDXS0))\n",
    "print(\"RIGHT_HAND : \",len(RIGHT_HAND_IDXS0))\n",
    "print(\"LEFT_POSE : \",len(LEFT_POSE_IDXS0))\n",
    "print(\"RIGHT_POSE : \",len(RIGHT_POSE_IDXS0))\n",
    "\n",
    "all_selection = np.concatenate([LIPS_IDXS0, EYE_LEFT, EYE_RIGHT, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, LEFT_POSE_IDXS0, RIGHT_POSE_IDXS0])\n",
    "print(len(all_selection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code sorts out a parquet files and rearrange the order to pose,face, left-hand, right-hand\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "ids = None\n",
    "\n",
    "order_global = {\"pose\" : 10000, \"face\" : 1000, \"left_hand\" : 100, \"right_hand\" : 10}\n",
    "\n",
    "def visualize_keypoints(frames : np.ndarray, point_size : int):\n",
    "    if len(frames.shape) == 1:\n",
    "        frames = np.array([frames])\n",
    "    \n",
    "    for frame in frames:\n",
    "        frame = frame.reshape(-1, 3)\n",
    "        sizes = point_size * np.ones(frame.shape[0])\n",
    "\n",
    "        fig = go.Figure(data=go.Scatter(x=frame[:,0], y=2.5 - frame[:,1], mode='markers',\n",
    "                                        marker=dict(\n",
    "                                            size=sizes\n",
    "                                            )))\n",
    "\n",
    "    # Customize the layout\n",
    "    fig.update_layout(title='visualization of human keypoints',\n",
    "                        xaxis_title='',\n",
    "                        yaxis_title='',\n",
    "                        width=1000,\n",
    "                        height=1600)\n",
    "\n",
    "    fig.update_xaxes(range=[-0.2, 1.4])  # Set x-axis range from 0 to 6\n",
    "    fig.update_yaxes(range=[0, 2.5])  # Set y-axis range from 10 to 20\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def process_parquet(ds, idxes = None):\n",
    "    ret = []\n",
    "    frames_unique = sorted(np.unique(ds[\"frame\"]))\n",
    "    for i,frame in enumerate(frames_unique):\n",
    "        frame_ds = ds[ds['frame'] == frame]\n",
    "        \n",
    "        order = []\n",
    "        for el in frame_ds[\"row_id\"]:\n",
    "            _frame, part, keypoint = el.split(\"-\")\n",
    "            order.append(order_global[part] - int(keypoint))\n",
    "\n",
    "        order = np.array(order)\n",
    "        frame_ds.iloc[:, 1] = order\n",
    "        frame_ds = frame_ds.sort_values(by=\"row_id\", ascending=False)\n",
    "    \n",
    "        vals = np.array(frame_ds[[\"x\", \"y\", \"z\"]])\n",
    "        if idxes is not None:\n",
    "            vals = vals[idxes]\n",
    "    \n",
    "        vals = vals.flatten()\n",
    "\n",
    "        ret.append(vals)\n",
    "        \n",
    "    return np.array(ret)\n",
    "\n",
    "\n",
    "def process_parquet2(ds, idxes = None):\n",
    "    ret = []    \n",
    "    frame_size = 543\n",
    "    it = len(ds) // frame_size\n",
    "    assert it == len(ds) / frame_size\n",
    "    \n",
    "    for i in range(it):\n",
    "        vals = ds.iloc[ i * frame_size : (i + 1 ) * frame_size ]        \n",
    "        \n",
    "        if idxes is not None:          \n",
    "            vals = ds.iloc[idxes]\n",
    "                        \n",
    "        ret.append(np.array(vals[[\"x\",\"y\", \"z\"]]).flatten())\n",
    "        \n",
    "    return np.array(np.array(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "size": [
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10
          ]
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          0.5313019156455994,
          0.5702122449874878,
          0.5941689014434814,
          0.6143554449081421,
          0.4964868128299713,
          0.4737759828567505,
          0.4550466537475586,
          0.6503288745880127,
          0.43520018458366394,
          0.5833595395088196,
          0.4882272481918335,
          0.8189577460289001,
          0.28548797965049744,
          1.0711381435394287,
          -0.03151913359761238,
          1.1940572261810303,
          0.09543462097644806,
          1.2531251907348633,
          0.08455909043550491,
          1.200533390045166,
          0.19869202375411987,
          1.166185736656189,
          0.1507594734430313,
          0.7406467199325562,
          0.4115261435508728,
          0.7713279128074646,
          0.39396944642066956,
          0.7816365361213684,
          0.41550883650779724,
          0.7945152521133423,
          0.40717074275016785,
          0.736636757850647,
          0.47586262226104736,
          0.5266446471214294,
          0.5229431390762329,
          0.5250797271728516,
          0.5133837461471558,
          0.5223585367202759,
          0.5223549008369446,
          0.5231890082359314,
          0.45120981335639954,
          0.5227876305580139,
          0.5223262906074524,
          0.5218218564987183,
          0.5267362594604492,
          0.5269674062728882,
          0.5273101925849915,
          0.528054416179657,
          0.5282372832298279,
          0.5284289121627808,
          0.5287166833877563,
          0.5305085182189941,
          0.5238029956817627,
          0.5143020749092102,
          0.413287490606308,
          0.4812939465045929,
          0.47021621465682983,
          0.45987409353256226,
          0.44711413979530334,
          0.49077826738357544,
          0.46309489011764526,
          0.47581803798675537,
          0.4515368938446045,
          0.44449567794799805,
          0.43846964836120605,
          0.48824113607406616,
          0.44764450192451477,
          0.4108426570892334,
          0.42759478092193604,
          0.4724549353122711,
          0.511788547039032,
          0.5143126845359802,
          0.49773868918418884,
          0.4892266094684601,
          0.5037195682525635,
          0.49586641788482666,
          0.4797210991382599,
          0.5136921405792236,
          0.5115615725517273,
          0.4278807044029236,
          0.49274611473083496,
          0.48857563734054565,
          0.4879510998725891,
          0.4428643584251404,
          0.5123012065887451,
          0.45008450746536255,
          0.4361300468444824,
          0.4208201467990875,
          0.4989696145057678,
          0.48723602294921875,
          0.47237056493759155,
          0.4270055294036865,
          0.49772995710372925,
          0.5071831941604614,
          0.4815959334373474,
          0.48487991094589233,
          0.4304184317588806,
          0.4889940917491913,
          0.470333456993103,
          0.46746826171875,
          0.4598795771598816,
          0.42657607793807983,
          0.4654504656791687,
          0.42254355549812317,
          0.4186321198940277,
          0.5126669406890869,
          0.5006400346755981,
          0.4923870861530304,
          0.5007532835006714,
          0.4832405149936676,
          0.48730793595314026,
          0.48643413186073303,
          0.5024241805076599,
          0.49849066138267517,
          0.5061776638031006,
          0.5158796310424805,
          0.5141639113426208,
          0.5130847096443176,
          0.5137183666229248,
          0.5149863958358765,
          0.5166100859642029,
          0.499177485704422,
          0.49627846479415894,
          0.49283236265182495,
          0.4902215301990509,
          0.4816882014274597,
          0.41453954577445984,
          0.52447509765625,
          0.4932905435562134,
          0.4902733564376831,
          0.5106481909751892,
          0.49405181407928467,
          0.509020984172821,
          0.48173093795776367,
          0.46547335386276245,
          0.4868057072162628,
          0.43516987562179565,
          0.4410800635814667,
          0.44573378562927246,
          0.4878212809562683,
          0.4937885105609894,
          0.4917434751987457,
          0.4878186583518982,
          0.45177340507507324,
          0.4281029999256134,
          0.49695247411727905,
          0.4349079132080078,
          0.5001257061958313,
          0.49486038088798523,
          0.41770821809768677,
          0.4339556097984314,
          0.44652363657951355,
          0.46698060631752014,
          0.48251810669898987,
          0.4941013753414154,
          0.5131234526634216,
          0.4200296103954315,
          0.42720070481300354,
          0.5182695388793945,
          0.4929654598236084,
          0.41032934188842773,
          0.5022943019866943,
          0.48683369159698486,
          0.44256073236465454,
          0.49455970525741577,
          0.41844114661216736,
          0.4972849488258362,
          0.5032190084457397,
          0.44555458426475525,
          0.44676053524017334,
          0.4125159680843353,
          0.4345881938934326,
          0.4146224856376648,
          0.48566630482673645,
          0.5200764536857605,
          0.4839787483215332,
          0.4208993911743164,
          0.46074026823043823,
          0.46972203254699707,
          0.4846732020378113,
          0.4233916401863098,
          0.5068351626396179,
          0.47249892354011536,
          0.4597735106945038,
          0.5220838785171509,
          0.5332232117652893,
          0.479104220867157,
          0.48804765939712524,
          0.4940533936023712,
          0.4214181900024414,
          0.48700496554374695,
          0.477184921503067,
          0.46790045499801636,
          0.45892518758773804,
          0.45332416892051697,
          0.4101410508155823,
          0.45503610372543335,
          0.5256761312484741,
          0.49030593037605286,
          0.4972906708717346,
          0.5098950266838074,
          0.5232836604118347,
          0.4574049413204193,
          0.4706076383590698,
          0.5060260891914368,
          0.43705856800079346,
          0.49394309520721436,
          0.5061173439025879,
          0.5319567918777466,
          0.4875645637512207,
          0.4168350100517273,
          0.5070421099662781,
          0.5042676329612732,
          0.5016711950302124,
          0.5000054836273193,
          0.49872642755508423,
          0.4896281361579895,
          0.4864266514778137,
          0.4836655855178833,
          0.47571179270744324,
          0.437282919883728,
          0.5068112015724182,
          0.5032625198364258,
          0.4977976679801941,
          0.49224600195884705,
          0.4375778138637543,
          0.5108404755592346,
          0.4934151768684387,
          0.5226566791534424,
          0.5130621194839478,
          0.5229229927062988,
          0.4984799027442932,
          0.5311257839202881,
          0.5306861400604248,
          0.511116623878479,
          0.4692983627319336,
          0.4796231687068939,
          0.4797428548336029,
          0.458072304725647,
          0.4718501567840576,
          0.4513225555419922,
          0.5075511336326599,
          0.4922924041748047,
          0.46025532484054565,
          0.47365832328796387,
          0.46175527572631836,
          0.4273846447467804,
          0.4492507874965668,
          0.42366907000541687,
          0.4656749963760376,
          0.49981170892715454,
          0.49863117933273315,
          0.4922069311141968,
          0.5026494264602661,
          0.49307525157928467,
          0.47367602586746216,
          0.45740389823913574,
          0.44464051723480225,
          0.4369325041770935,
          0.43588173389434814,
          0.4103614091873169,
          0.44368666410446167,
          0.4540308713912964,
          0.46830350160598755,
          0.4822937846183777,
          0.49331116676330566,
          0.5005790591239929,
          0.41255128383636475,
          0.49306413531303406,
          0.5054957270622253,
          0.5061700344085693,
          0.51321941614151,
          0.5069204568862915,
          0.49681758880615234,
          0.5149632096290588,
          0.516692578792572,
          0.5009651184082031,
          0.5058990716934204,
          0.5080057978630066,
          0.45010074973106384,
          0.4407205879688263,
          0.5325565338134766,
          0.6063290238380432,
          0.535323977470398,
          0.6521518230438232,
          0.575113832950592,
          0.5860276818275452,
          0.5966194868087769,
          0.6115288734436035,
          0.5656655430793762,
          0.5893319249153137,
          0.5768023729324341,
          0.6018242835998535,
          0.6102516055107117,
          0.6208887696266174,
          0.5759027600288391,
          0.6105228662490845,
          0.6570323705673218,
          0.6345219016075134,
          0.583012580871582,
          0.5413575768470764,
          0.5399988293647766,
          0.5560919046401978,
          0.5653591156005859,
          0.5510967373847961,
          0.5594257712364197,
          0.5827935338020325,
          0.5326666831970215,
          0.5335708856582642,
          0.6272550225257874,
          0.5599154829978943,
          0.5627003908157349,
          0.5636041164398193,
          0.6163116097450256,
          0.5329514145851135,
          0.5977940559387207,
          0.6149383187294006,
          0.6391087174415588,
          0.5468865633010864,
          0.56634122133255,
          0.5894336700439453,
          0.6488659381866455,
          0.5541115403175354,
          0.5443834662437439,
          0.5752271413803101,
          0.5719960331916809,
          0.6221288442611694,
          0.5636598467826843,
          0.5753182172775269,
          0.5770808458328247,
          0.5891712307929993,
          0.6301431655883789,
          0.582482635974884,
          0.6349510550498962,
          0.6429162621498108,
          0.5410150289535522,
          0.5535823702812195,
          0.562519371509552,
          0.5513210296630859,
          0.573563277721405,
          0.5695966482162476,
          0.570388674736023,
          0.5471183061599731,
          0.5570841431617737,
          0.5491195321083069,
          0.5391318202018738,
          0.5474501848220825,
          0.5448029041290283,
          0.5434491634368896,
          0.5417906641960144,
          0.5399231910705566,
          0.5576227307319641,
          0.5607281923294067,
          0.5642691850662231,
          0.5671435594558716,
          0.5754647850990295,
          0.6609832048416138,
          0.5635099411010742,
          0.5665767192840576,
          0.5409627556800842,
          0.559849202632904,
          0.5425617694854736,
          0.5723558068275452,
          0.5903825759887695,
          0.5660363435745239,
          0.6192269325256348,
          0.6111419200897217,
          0.6020693182945251,
          0.5744935870170593,
          0.5501120090484619,
          0.5538627505302429,
          0.5577986836433411,
          0.6059478521347046,
          0.6333624124526978,
          0.559236466884613,
          0.6225153207778931,
          0.5511041283607483,
          0.5542380809783936,
          0.6460760235786438,
          0.6242308020591736,
          0.608556866645813,
          0.5868257284164429,
          0.5712449550628662,
          0.5591037273406982,
          0.5342539548873901,
          0.6441692113876343,
          0.6316804885864258,
          0.5295398235321045,
          0.5594451427459717,
          0.6625518798828125,
          0.5498201847076416,
          0.567286491394043,
          0.6161841154098511,
          0.5549232959747314,
          0.6574644446372986,
          0.5593795776367188,
          0.5437657237052917,
          0.6233468651771545,
          0.6258775591850281,
          0.6572156548500061,
          0.6354608535766602,
          0.6503506898880005,
          0.5800066590309143,
          0.5290141105651855,
          0.5699861645698547,
          0.6458261609077454,
          0.5955572724342346,
          0.5862605571746826,
          0.5723770260810852,
          0.6422854661941528,
          0.5600628852844238,
          0.5971274375915527,
          0.6113300323486328,
          0.5771744251251221,
          0.5686090588569641,
          0.5626934170722961,
          0.6406787633895874,
          0.5694646835327148,
          0.5787165760993958,
          0.5877087712287903,
          0.5971341729164124,
          0.6033831238746643,
          0.6593077778816223,
          0.6018558740615845,
          0.5650123357772827,
          0.5538641214370728,
          0.5426312685012817,
          0.6106330752372742,
          0.5963731408119202,
          0.5584028959274292,
          0.637445330619812,
          0.562553346157074,
          0.542357861995697,
          0.5804400444030762,
          0.6537579894065857,
          0.5496900677680969,
          0.5526872873306274,
          0.555598795413971,
          0.5579241514205933,
          0.5632912516593933,
          0.566311240196228,
          0.5692200064659119,
          0.5718216896057129,
          0.5837020874023438,
          0.6252661943435669,
          0.5424103736877441,
          0.5495675206184387,
          0.5571773648262024,
          0.5639147758483887,
          0.628476619720459,
          0.537574291229248,
          0.569657564163208,
          0.5335481762886047,
          0.5515766739845276,
          0.5509639382362366,
          0.5941476821899414,
          0.5761262774467468,
          0.5837962031364441,
          0.5998036861419678,
          0.5856357216835022,
          0.6094835996627808,
          0.5552904605865479,
          0.5598630905151367,
          0.6052849292755127,
          0.591273307800293,
          0.6007934808731079,
          0.6396798491477966,
          0.6154804229736328,
          0.6472773551940918,
          0.5941906571388245,
          0.5506607294082642,
          0.5505776405334473,
          0.559031069278717,
          0.544230580329895,
          0.5579817891120911,
          0.5759040117263794,
          0.5924040079116821,
          0.6067155599594116,
          0.6172055006027222,
          0.6241577863693237,
          0.6585739254951477,
          0.6141629219055176,
          0.6019886136054993,
          0.587060809135437,
          0.5730803608894348,
          0.5619845390319824,
          0.5540633201599121,
          0.66228848695755,
          0.5590721368789673,
          0.5421099662780762,
          0.5412834882736206,
          0.5355237722396851,
          0.5417612791061401,
          0.5560322999954224,
          0.5332216620445251,
          0.5326986312866211,
          0.5549154281616211,
          0.5478945374488831,
          0.5429046154022217,
          0.6072248220443726,
          0.6159202456474304,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          0.17974883317947388,
          0.2522865831851959,
          0.324224054813385,
          0.3763918876647949,
          0.42066690325737,
          0.31644463539123535,
          0.36310964822769165,
          0.3580951690673828,
          0.34035998582839966,
          0.26702746748924255,
          0.3159138560295105,
          0.30610376596450806,
          0.2868828773498535,
          0.2125982791185379,
          0.2592703700065613,
          0.25155672430992126,
          0.23598141968250275,
          0.15601195394992828,
          0.20094095170497894,
          0.20347920060157776,
          0.19482247531414032
         ],
         "y": [
          2.155447095632553,
          2.195915102958679,
          2.1936923265457153,
          2.190496176481247,
          2.1946464478969574,
          2.1914640367031097,
          2.188100755214691,
          2.163905829191208,
          2.1602281033992767,
          2.107033133506775,
          2.1033796966075897,
          1.9293657541275024,
          1.9249698519706726,
          1.6400598883628845,
          1.7082305550575256,
          1.3993417024612427,
          1.8765832781791687,
          1.3147796392440796,
          1.922868251800537,
          1.3163615465164185,
          1.9526283144950867,
          1.3391977548599243,
          1.9128456711769104,
          1.3686062097549438,
          1.3696422576904297,
          0.9041949510574341,
          0.8942524194717407,
          0.5171869993209839,
          0.5202747583389282,
          0.45856261253356934,
          0.4654853343963623,
          0.3788771629333496,
          0.3748342990875244,
          2.1239106357097626,
          2.152978390455246,
          2.1425814628601074,
          2.177092969417572,
          2.1613524556159973,
          2.171195387840271,
          2.1937818825244904,
          2.187763273715973,
          2.2117210030555725,
          2.222331166267395,
          2.2574315071105957,
          2.1206085085868835,
          2.1170009076595306,
          2.1146416068077087,
          2.0970614552497864,
          2.0926986932754517,
          2.0870876610279083,
          2.0817187428474426,
          2.07405486702919,
          2.147967666387558,
          2.146734833717346,
          2.21048703789711,
          2.1834613978862762,
          2.182102710008621,
          2.181852698326111,
          2.184450000524521,
          2.1862083673477173,
          2.2046500742435455,
          2.2045872509479523,
          2.2026418447494507,
          2.198956251144409,
          2.1788405179977417,
          2.0644788444042206,
          2.188971996307373,
          2.1766490936279297,
          2.1832107603549957,
          2.1513367295265198,
          2.1249051094055176,
          2.116233676671982,
          2.1196596026420593,
          2.113094240427017,
          2.1136934757232666,
          2.109912931919098,
          2.092988908290863,
          2.1525774598121643,
          2.160432070493698,
          2.2062250077724457,
          2.1725785732269287,
          2.1510229408740997,
          2.1548028588294983,
          2.148932307958603,
          2.169616013765335,
          2.217889428138733,
          2.2135262191295624,
          2.226491630077362,
          2.2140053510665894,
          2.2021909952163696,
          2.102372467517853,
          2.0996504426002502,
          2.146853893995285,
          2.1447742879390717,
          2.099527597427368,
          2.1002471446990967,
          2.21807923913002,
          2.1466273069381714,
          2.2186783850193024,
          2.2250605821609497,
          2.249470293521881,
          2.2216325402259827,
          2.2369655668735504,
          2.2086194157600403,
          2.2083709836006165,
          2.1202360093593597,
          2.1163036823272705,
          2.1113494634628296,
          2.1452490091323853,
          2.0998281240463257,
          2.095471888780594,
          2.100673019886017,
          2.1509559750556946,
          2.10940420627594,
          2.112465739250183,
          2.114174395799637,
          2.0747795701026917,
          2.081722617149353,
          2.0870633721351624,
          2.092725306749344,
          2.0967689752578735,
          2.09704452753067,
          2.0947800874710083,
          2.091800332069397,
          2.0887369513511658,
          2.1216019988059998,
          2.138946980237961,
          2.145388752222061,
          2.098155379295349,
          2.0969277024269104,
          2.1416270434856415,
          2.1414206624031067,
          2.1431624591350555,
          2.166889250278473,
          2.16034272313118,
          2.150409370660782,
          2.239814728498459,
          2.2314996123313904,
          2.223757356405258,
          2.086274355649948,
          2.2245069444179535,
          2.2390332221984863,
          2.2547749280929565,
          2.1824589371681213,
          2.1725085377693176,
          2.1889405846595764,
          2.194791615009308,
          2.1786328852176666,
          2.155379831790924,
          2.164434105157852,
          2.1680800914764404,
          2.166682332754135,
          2.1693881452083588,
          2.1736361384391785,
          2.1783821284770966,
          2.1909809708595276,
          2.148181825876236,
          2.1951407194137573,
          2.1478782892227173,
          2.1657579243183136,
          2.1744921505451202,
          2.1836488246917725,
          2.149137705564499,
          2.188705086708069,
          2.1599332690238953,
          2.120073765516281,
          2.1915460526943207,
          2.165682226419449,
          2.083089977502823,
          2.0718458592891693,
          2.1431168913841248,
          2.093779444694519,
          2.193501114845276,
          2.0544180870056152,
          2.145433485507965,
          2.1587495505809784,
          2.1806665658950806,
          2.1866261959075928,
          2.1866220831871033,
          2.0939910113811493,
          2.1317790746688843,
          2.040209859609604,
          2.0528961420059204,
          2.060936689376831,
          2.240355968475342,
          2.0387361347675323,
          2.1875835061073303,
          2.1893049776554108,
          2.1905486285686493,
          2.1954671442508698,
          2.1941978931427,
          2.194522798061371,
          2.194133698940277,
          2.192757546901703,
          2.191174954175949,
          2.1941724717617035,
          2.1871439814567566,
          2.135572165250778,
          2.1284333169460297,
          2.1486500203609467,
          2.133980691432953,
          2.2021552324295044,
          2.0721509158611298,
          2.063389778137207,
          2.0481684505939484,
          2.0834718346595764,
          2.1929025053977966,
          2.1786604523658752,
          2.04645499587059,
          2.0455797612667084,
          2.125268816947937,
          2.0967181026935577,
          2.0933823585510254,
          2.0888493061065674,
          2.0839836299419403,
          2.079579472541809,
          2.1053199470043182,
          2.105702906847,
          2.1065394580364227,
          2.1127297282218933,
          2.129839926958084,
          2.1854450702667236,
          2.1991139352321625,
          2.196976751089096,
          2.105606973171234,
          2.1079100966453552,
          2.2009724974632263,
          2.0731253623962402,
          2.178978383541107,
          2.1837916672229767,
          2.1862142086029053,
          2.1659765243530273,
          2.056456506252289,
          2.066476345062256,
          2.067607045173645,
          2.0902050137519836,
          2.1413405537605286,
          2.080629050731659,
          2.1401249766349792,
          2.131691813468933,
          2.125216543674469,
          2.0580333471298218,
          2.1603856086730957,
          2.0829200744628906,
          2.0732114613056183,
          2.1015121042728424,
          2.117313712835312,
          2.0992166996002197,
          2.1086334586143494,
          2.1190183460712433,
          2.1723470389842987,
          2.1522835195064545,
          2.148817151784897,
          2.1584087908267975,
          2.206178992986679,
          2.2102328836917877,
          2.210089534521103,
          2.2072399854660034,
          2.2022934556007385,
          2.1863215267658234,
          2.1600146889686584,
          2.1762517988681793,
          2.17516627907753,
          2.1761699318885803,
          2.1788617372512817,
          2.1824392676353455,
          2.1858747005462646,
          2.1565027832984924,
          2.146055281162262,
          2.172420084476471,
          2.1529093980789185,
          2.148509055376053,
          2.1510448157787323,
          2.143357664346695,
          2.148084372282028,
          2.1456826627254486,
          2.1919783651828766,
          2.1909755766391754,
          2.1905264854431152,
          2.1899913251399994,
          2.1945030093193054,
          2.1779386699199677,
          2.1954868137836456,
          2.147824913263321,
          2.2212590277194977,
          2.1875640749931335,
          2.1872296035289764,
          2.18786284327507,
          2.1924499571323395,
          2.189210206270218,
          2.2118238508701324,
          2.209969222545624,
          2.2112028300762177,
          2.208161562681198,
          2.1870443522930145,
          2.067166179418564,
          2.197694778442383,
          2.1871883273124695,
          2.192444622516632,
          2.1560445725917816,
          2.1258467733860016,
          2.1171836853027344,
          2.1215213239192963,
          2.115854263305664,
          2.115348905324936,
          2.1121029257774353,
          2.097187101840973,
          2.153449237346649,
          2.1614056527614594,
          2.2161105573177338,
          2.175629198551178,
          2.1542614102363586,
          2.1580723226070404,
          2.15629306435585,
          2.170550376176834,
          2.2248925268650055,
          2.222498834133148,
          2.2367080748081207,
          2.2138543128967285,
          2.205736994743347,
          2.1073301434516907,
          2.1082873344421387,
          2.1494476795196533,
          2.146473616361618,
          2.103227525949478,
          2.1035974621772766,
          2.2278527319431305,
          2.149852305650711,
          2.2222475707530975,
          2.2290137112140656,
          2.255917251110077,
          2.230865001678467,
          2.2427151799201965,
          2.218924731016159,
          2.21813103556633,
          2.1212722957134247,
          2.118113875389099,
          2.1138647198677063,
          2.147559940814972,
          2.103370100259781,
          2.0990561842918396,
          2.1038568019866943,
          2.1531407833099365,
          2.1112958788871765,
          2.113885849714279,
          2.114962011575699,
          2.075888156890869,
          2.083243250846863,
          2.088490217924118,
          2.0939930379390717,
          2.097859263420105,
          2.0995788276195526,
          2.0977277755737305,
          2.095216244459152,
          2.092521518468857,
          2.1255615651607513,
          2.148950159549713,
          2.100961744785309,
          2.100128650665283,
          2.1429118514060974,
          2.1442075073719025,
          2.144621104001999,
          2.1709124743938446,
          2.165746182203293,
          2.153755336999893,
          2.2487319707870483,
          2.239498555660248,
          2.231402426958084,
          2.089558631181717,
          2.224757879972458,
          2.242129921913147,
          2.258336067199707,
          2.1894348561763763,
          2.180997669696808,
          2.1910287737846375,
          2.2042444944381714,
          2.181006997823715,
          2.1580609381198883,
          2.174169361591339,
          2.175850957632065,
          2.1732066869735718,
          2.1743559539318085,
          2.1774823665618896,
          2.18117219209671,
          2.1920125484466553,
          2.1575616002082825,
          2.204849660396576,
          2.148436963558197,
          2.1686989665031433,
          2.1853481233119965,
          2.1855678856372833,
          2.152537524700165,
          2.1976007223129272,
          2.1626070141792297,
          2.129522979259491,
          2.193599820137024,
          2.1674752831459045,
          2.0895965695381165,
          2.0781630873680115,
          2.1531527638435364,
          2.1015918850898743,
          2.2036993503570557,
          2.0570872724056244,
          2.1458825170993805,
          2.1624678671360016,
          2.1901024878025055,
          2.192676931619644,
          2.191781312227249,
          2.0979317128658295,
          2.140817105770111,
          2.0416336059570312,
          2.0566156208515167,
          2.065842777490616,
          2.1919050216674805,
          2.1926290094852448,
          2.192979633808136,
          2.205706775188446,
          2.1985191106796265,
          2.2008151412010193,
          2.201779395341873,
          2.2013968229293823,
          2.2001221776008606,
          2.205155700445175,
          2.194058656692505,
          2.131593406200409,
          2.1512710750102997,
          2.1353792548179626,
          2.0773074328899384,
          2.0672265887260437,
          2.0496257543563843,
          2.0910903811454773,
          2.195600211620331,
          2.180291622877121,
          2.0481895804405212,
          2.1348492801189423,
          2.0987011194229126,
          2.095695525407791,
          2.091580420732498,
          2.0869666039943695,
          2.0819416642189026,
          2.10807728767395,
          2.10876527428627,
          2.1098711788654327,
          2.1173116266727448,
          2.137657970190048,
          2.187116652727127,
          2.2002457976341248,
          2.1989179849624634,
          2.107964336872101,
          2.115657538175583,
          2.201068878173828,
          2.075637102127075,
          2.1847378611564636,
          2.1682673394680023,
          2.0688402354717255,
          2.094944268465042,
          2.145384967327118,
          2.084340363740921,
          2.146039843559265,
          2.1363700926303864,
          2.131668299436569,
          2.0594308972358704,
          2.1633630096912384,
          2.088144540786743,
          2.077106297016144,
          2.1070845425128937,
          2.1260207891464233,
          2.1057322323322296,
          2.117593437433243,
          2.124256670475006,
          2.1745996177196503,
          2.154732257127762,
          2.1518011689186096,
          2.160286784172058,
          2.2079406678676605,
          2.2147211134433746,
          2.217032641172409,
          2.2157839834690094,
          2.21174156665802,
          2.195087045431137,
          2.1704268157482147,
          2.1837258040905,
          2.1814059019088745,
          2.181253045797348,
          2.1828077733516693,
          2.185241013765335,
          2.187910348176956,
          2.166945368051529,
          2.148986130952835,
          2.174034059047699,
          2.154565691947937,
          2.1495976746082306,
          2.152703285217285,
          2.14596825838089,
          2.1489923000335693,
          2.1465097963809967,
          2.193583458662033,
          2.1923020482063293,
          2.191655158996582,
          2.1989202201366425,
          2.2038174271583557,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          1.863844871520996,
          1.8766652941703796,
          1.9158586859703064,
          1.9461702108383179,
          1.9675619006156921,
          1.9985054731369019,
          2.0135570764541626,
          1.9714759588241577,
          1.9348152875900269,
          2.006772071123123,
          2.01446270942688,
          1.9591842889785767,
          1.9222439527511597,
          2.0056146681308746,
          2.002763718366623,
          1.9463920593261719,
          1.912244439125061,
          1.9956273436546326,
          1.995185375213623,
          1.9505434036254883,
          1.922960877418518
         ]
        }
       ],
       "layout": {
        "height": 1600,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "visualization of human keypoints"
        },
        "width": 1000,
        "xaxis": {
         "range": [
          -0.2,
          1.4
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "range": [
          0,
          2.5
         ],
         "title": {
          "text": ""
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = process_parquet(pd.read_parquet(\"79631423.parquet\"))\n",
    "visualize_keypoints(f[0], point_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "size": [
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10,
           10
          ]
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          0.4815959334373474,
          0.4836655855178833,
          0.4892266094684601,
          0.49773868918418884,
          0.511788547039032,
          0.5266446471214294,
          0.5413575768470764,
          0.5560919046401978,
          0.5653591156005859,
          0.5718216896057129,
          0.5752271413803101,
          0.4846732020378113,
          0.4902215301990509,
          0.5000054836273193,
          0.5130847096443176,
          0.5287166833877563,
          0.5448029041290283,
          0.5579241514205933,
          0.5671435594558716,
          0.5723770260810852,
          0.48643413186073303,
          0.49224600195884705,
          0.49849066138267517,
          0.5061776638031006,
          0.5158796310424805,
          0.5273101925849915,
          0.5391318202018738,
          0.5491195321083069,
          0.5570841431617737,
          0.5639147758483887,
          0.4932905435562134,
          0.499177485704422,
          0.5070421099662781,
          0.5166100859642029,
          0.528054416179657,
          0.5399231910705566,
          0.5496900677680969,
          0.5576227307319641,
          0.5635099411010742,
          0.570388674736023,
          0.44764450192451477,
          0.45120981335639954,
          0.45010074973106384,
          0.45332416892051697,
          0.45892518758773804,
          0.46790045499801636,
          0.477184921503067,
          0.48700496554374695,
          0.49394309520721436,
          0.4972849488258362,
          0.4940533936023712,
          0.48804765939712524,
          0.479104220867157,
          0.46972203254699707,
          0.46074026823043823,
          0.45503610372543335,
          null,
          null,
          null,
          null,
          0.5593795776367188,
          0.562553346157074,
          0.5694646835327148,
          0.5787165760993958,
          0.5877087712287903,
          0.5971341729164124,
          0.6033831238746643,
          0.6072248220443726,
          0.6105228662490845,
          0.6063290238380432,
          0.6018558740615845,
          0.5955572724342346,
          0.5862605571746826,
          0.5771744251251221,
          0.5686090588569641,
          0.5626934170722961,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          0.17974883317947388,
          0.2522865831851959,
          0.324224054813385,
          0.3763918876647949,
          0.42066690325737,
          0.31644463539123535,
          0.36310964822769165,
          0.3580951690673828,
          0.34035998582839966,
          0.26702746748924255,
          0.3159138560295105,
          0.30610376596450806,
          0.2868828773498535,
          0.2125982791185379,
          0.2592703700065613,
          0.25155672430992126,
          0.23598141968250275,
          0.15601195394992828,
          0.20094095170497894,
          0.20347920060157776,
          0.19482247531414032,
          1.0711381435394287,
          1.1940572261810303,
          1.2531251907348633,
          1.200533390045166,
          1.166185736656189,
          -0.03151913359761238,
          0.09543462097644806,
          0.08455909043550491,
          0.19869202375411987,
          0.1507594734430313
         ],
         "y": [
          2.099527597427368,
          2.1065394580364227,
          2.113094240427017,
          2.1196596026420593,
          2.1249051094055176,
          2.1239106357097626,
          2.1258467733860016,
          2.1215213239192963,
          2.115854263305664,
          2.1098711788654327,
          2.103227525949478,
          2.0939910113811493,
          2.0887369513511658,
          2.0839836299419403,
          2.081722617149353,
          2.0817187428474426,
          2.083243250846863,
          2.0869666039943695,
          2.092521518468857,
          2.0979317128658295,
          2.100673019886017,
          2.105606973171234,
          2.10940420627594,
          2.112465739250183,
          2.114174395799637,
          2.1146416068077087,
          2.114962011575699,
          2.113885849714279,
          2.1112958788871765,
          2.107964336872101,
          2.098155379295349,
          2.09704452753067,
          2.0967181026935577,
          2.0967689752578735,
          2.0970614552497864,
          2.097859263420105,
          2.0987011194229126,
          2.0995788276195526,
          2.100961744785309,
          2.1038568019866943,
          2.188971996307373,
          2.187763273715973,
          2.1899913251399994,
          2.191174954175949,
          2.192757546901703,
          2.194133698940277,
          2.194522798061371,
          2.1941978931427,
          2.1929025053977966,
          2.1915460526943207,
          2.1905486285686493,
          2.1893049776554108,
          2.1875835061073303,
          2.1866220831871033,
          2.1866261959075928,
          2.1871439814567566,
          null,
          null,
          null,
          null,
          2.193599820137024,
          2.195600211620331,
          2.1985191106796265,
          2.2008151412010193,
          2.201779395341873,
          2.2013968229293823,
          2.2001221776008606,
          2.1989202201366425,
          2.197694778442383,
          2.1954868137836456,
          2.194058656692505,
          2.192676931619644,
          2.191781312227249,
          2.1919050216674805,
          2.1926290094852448,
          2.192979633808136,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          1.863844871520996,
          1.8766652941703796,
          1.9158586859703064,
          1.9461702108383179,
          1.9675619006156921,
          1.9985054731369019,
          2.0135570764541626,
          1.9714759588241577,
          1.9348152875900269,
          2.006772071123123,
          2.01446270942688,
          1.9591842889785767,
          1.9222439527511597,
          2.0056146681308746,
          2.002763718366623,
          1.9463920593261719,
          1.912244439125061,
          1.9956273436546326,
          1.995185375213623,
          1.9505434036254883,
          1.922960877418518,
          1.6400598883628845,
          1.3993417024612427,
          1.3147796392440796,
          1.3163615465164185,
          1.3391977548599243,
          1.7082305550575256,
          1.8765832781791687,
          1.922868251800537,
          1.9526283144950867,
          1.9128456711769104
         ]
        }
       ],
       "layout": {
        "height": 1600,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "visualization of human keypoints"
        },
        "width": 1000,
        "xaxis": {
         "range": [
          -0.2,
          1.4
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "range": [
          0,
          2.5
         ],
         "title": {
          "text": ""
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f2 = process_parquet2(pd.read_parquet(\"79631423.parquet\"), idxes=all_selection)\n",
    "visualize_keypoints(f2[0], point_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet( os.path.join(\"..\", \"data\",\"ASL-ds\", \"train_landmark_files\", \"16069\", \"695046.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 94477/94477 [00:02<00:00, 40931.96it/s]\n",
      "100%|| 94477/94477 [00:02<00:00, 41566.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardinality of train : 113, cardinality of validation : 13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#custom class to load data from Parquet files for training ML models.\n",
    "class ParquetDataset(keras.utils.Sequence):\n",
    "    def __init__(self, dataset_folder, csv_file : str, batch_size=CONFIG.BATCH_SIZE, \n",
    "                 data_limit :int= CONFIG.DATA_LIMIT, check_if_file_exists = True, \n",
    "                 preprocessing_func=None, frame_length :int = CONFIG.VIDEO_LENGTH,\n",
    "                 split : str = \"train\", train_val_split : float = CONFIG.TRAIN_VAL_SPLIT,\n",
    "                 sort_by_counts : bool = True, **kwargs\n",
    "                ):\n",
    "        super().__init__(**kwargs)\n",
    "        #taking keras sequence for .fit(), .evaluate(), .predict() methods\n",
    "        #load csv - it has the path to parquet file, and another to store label\n",
    "        self.csv_path = csv_file\n",
    "        self.root_folder = dataset_folder\n",
    "        self.batch_size = batch_size\n",
    "        #optional pre-processing function to the parquet files.\n",
    "        self.preprocessing_func = preprocessing_func\n",
    "        \n",
    "        self.csv_data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        self.all_files = []\n",
    "        self.not_exists = []\n",
    "        self.frame_length = frame_length\n",
    "\n",
    "        \n",
    "        for path, label in tqdm(list(zip(self.csv_data[\"path\"], self.csv_data[\"sign\"]))):\n",
    "            prop_path = os.path.join(self.root_folder, path)\n",
    "            \n",
    "            if check_if_file_exists:\n",
    "                if os.path.exists(prop_path):\n",
    "                    self.all_files.append((prop_path, label))\n",
    "                else:\n",
    "                    self.not_exists.append(prop_path)\n",
    "            else:\n",
    "                self.all_files.append((prop_path, label))\n",
    "                \n",
    "                    \n",
    "        self.all_files = np.array(self.all_files)\n",
    "        self.unique_labels = np.unique(self.all_files[:, 1])\n",
    "        self.label_2_id = { key : i for i, key in enumerate(self.unique_labels)}\n",
    "    \n",
    "        # sort the values by popularity\n",
    "        if sort_by_counts:\n",
    "            cnt = Counter(self.all_files[:, 1])\n",
    "            vals = []\n",
    "            \n",
    "            for i,row in enumerate(self.all_files):\n",
    "                vals.append((int(1e6 * cnt[row[1]] + self.label_2_id [row[1]]),i))\n",
    "            \n",
    "            vals = np.array(sorted(vals)[::-1])\n",
    "            self.all_files = self.all_files[vals[:,1]]\n",
    "\n",
    "        \n",
    "        if data_limit < 0:\n",
    "            train_ds, val_ds = train_test_split(self.all_files, train_size=train_val_split, random_state=42)\n",
    "        else:\n",
    "            train_ds, val_ds = train_test_split(self.all_files[:data_limit], train_size=train_val_split, random_state=42)\n",
    "            self.unique_labels = np.unique(self.all_files[:data_limit, 1])\n",
    "            self.label_2_id = { key : i for i, key in enumerate(self.unique_labels)}\n",
    "            \n",
    "        if split.lower() == \"train\":\n",
    "            self.dataset = train_ds\n",
    "            \n",
    "        elif split.lower() == \"val\":\n",
    "            self.dataset = val_ds \n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"please specify split to be either train or val\")\n",
    "            \n",
    "        np.random.shuffle(self.dataset)\n",
    "                   \n",
    "\n",
    "    def __len__(self):\n",
    "        # Assuming each Parquet file should be one batch; adjust if necessary\n",
    "        return math.ceil(len(self.dataset) / self.batch_size)\n",
    "    \n",
    "    def get_single(self, idx):\n",
    "        # Load one file per batch\n",
    "        #take the idx value, 1st label, \n",
    "        path, label = self.dataset[idx]\n",
    "        \n",
    "        df = pd.read_parquet( path)\n",
    "        \n",
    "        # Apply preprocessing if specified\n",
    "        if self.preprocessing_func:\n",
    "            df = self.preprocessing_func(df, self.frame_length)\n",
    "        \n",
    "        one_hot_encoded_label = np.zeros(len(self.unique_labels))\n",
    "        one_hot_encoded_label[self.label_2_id[label]] = 1  \n",
    "        \n",
    "        return df, one_hot_encoded_label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, Y = [], []\n",
    "        \n",
    "        low = idx * self.batch_size\n",
    "        high = min(low + self.batch_size, len(self.dataset))\n",
    "        \n",
    "        for i in range(low, high):\n",
    "            x, y = self.get_single(i)\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "        \n",
    "        return np.array(X), np.array(Y)\n",
    "                \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle files for the next epoch\n",
    "        np.random.shuffle(self.dataset)\n",
    "\n",
    "def my_preprocessing_func(df, frame_length):\n",
    "    \n",
    "    # Define your preprocessing steps here\n",
    "    # Example: normalize numerical features\n",
    "    frames_mediapipe = process_parquet(df)\n",
    "    \n",
    "    current_length, num_features = frames_mediapipe.shape\n",
    "\n",
    "    if current_length >= frame_length:\n",
    "            # TODO: a better than uniform value ? Could place gaussian in the middle\n",
    "            random_start = random.randint(0, current_length - frame_length)\n",
    "            return np.nan_to_num(frames_mediapipe[random_start : (random_start + frame_length)])\n",
    "        \n",
    "    # padd the video to contain zeros \n",
    "    return np.concatenate([np.nan_to_num(frames_mediapipe), np.zeros((frame_length - current_length, num_features))], axis=0)\n",
    "    \n",
    "# Usage example\n",
    "parquet_folder_path = CONFIG.root\n",
    "train_dataset_parquet = ParquetDataset(parquet_folder_path, csv_file = os.path.join(CONFIG.root, \"train.csv\"), \n",
    "                                 batch_size=CONFIG.BATCH_SIZE, data_limit=1000,\n",
    "                                 preprocessing_func=my_preprocessing_func,\n",
    "                                check_if_file_exists = True,\n",
    "                                split=\"train\")\n",
    "\n",
    "val_dataset_parquet = ParquetDataset(parquet_folder_path, csv_file = os.path.join(CONFIG.root, \"train.csv\"), \n",
    "                                 batch_size=CONFIG.BATCH_SIZE, data_limit=1000,\n",
    "                                 preprocessing_func=my_preprocessing_func,\n",
    "                                 check_if_file_exists= True,\n",
    "                                 split=\"val\")\n",
    "\n",
    "print(f\"cardinality of train : {len(train_dataset_parquet)}, cardinality of validation : {len(val_dataset_parquet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 94477/94477 [00:02<00:00, 41181.96it/s]\n",
      "Cacheing: 100%|| 900/900 [00:26<00:00, 34.54it/s]\n",
      "100%|| 94477/94477 [00:02<00:00, 42228.25it/s]\n",
      "Cacheing: 100%|| 100/100 [00:02<00:00, 35.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardinality of train : 900, cardinality of validation : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#custom class to load data from Parquet files for training ML models.\n",
    "class ParquetDatasetCached(keras.utils.Sequence):\n",
    "    def __init__(self, dataset_folder, csv_file : str, batch_size=CONFIG.BATCH_SIZE, \n",
    "                 data_limit :int= CONFIG.DATA_LIMIT, check_if_file_exists = True, \n",
    "                 preprocessing_func=None, frame_length :int = CONFIG.VIDEO_LENGTH,\n",
    "                 split : str = \"train\", train_val_split : float = CONFIG.TRAIN_VAL_SPLIT,\n",
    "                 sort_by_counts : bool = True, **kwargs\n",
    "                ):\n",
    "        super().__init__(**kwargs)\n",
    "        #taking keras sequence for .fit(), .evaluate(), .predict() methods\n",
    "        #load csv - it has the path to parquet file, and another to store label\n",
    "        self.csv_path = csv_file\n",
    "        self.root_folder = dataset_folder\n",
    "        self.batch_size = batch_size\n",
    "        #optional pre-processing function to the parquet files.\n",
    "        self.preprocessing_func = preprocessing_func\n",
    "        \n",
    "        self.csv_data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        self.all_files = []\n",
    "        self.not_exists = []\n",
    "        self.frame_length = frame_length\n",
    "\n",
    "        \n",
    "        for path, label in tqdm(list(zip(self.csv_data[\"path\"], self.csv_data[\"sign\"]))):\n",
    "            prop_path = os.path.join(self.root_folder, path)\n",
    "            \n",
    "            if check_if_file_exists:\n",
    "                if os.path.exists(prop_path):\n",
    "                    self.all_files.append((prop_path, label))\n",
    "                else:\n",
    "                    self.not_exists.append(prop_path)\n",
    "            else:\n",
    "                self.all_files.append((prop_path, label))\n",
    "                \n",
    "                    \n",
    "        self.all_files = np.array(self.all_files)\n",
    "        self.unique_labels = np.unique(self.all_files[:, 1])\n",
    "        self.label_2_id = { key : i for i, key in enumerate(self.unique_labels)}\n",
    "    \n",
    "        # sort the values by popularity\n",
    "        if sort_by_counts:\n",
    "            cnt = Counter(self.all_files[:, 1])\n",
    "            vals = []\n",
    "            \n",
    "            for i,row in enumerate(self.all_files):\n",
    "                vals.append((int(1e6 * cnt[row[1]] + self.label_2_id [row[1]]),i))\n",
    "            \n",
    "            vals = np.array(sorted(vals)[::-1])\n",
    "            self.all_files = self.all_files[vals[:,1]]\n",
    "\n",
    "        \n",
    "        if data_limit < 0:\n",
    "            train_ds, val_ds = train_test_split(self.all_files, train_size=train_val_split, random_state=42)\n",
    "        else:\n",
    "            train_ds, val_ds = train_test_split(self.all_files[:data_limit], train_size=train_val_split, random_state=42)\n",
    "            self.unique_labels = np.unique(self.all_files[:data_limit, 1])\n",
    "            self.label_2_id = { key : i for i, key in enumerate(self.unique_labels)}\n",
    "            \n",
    "        if split.lower() == \"train\":\n",
    "            self.dataset = train_ds\n",
    "            \n",
    "        elif split.lower() == \"val\":\n",
    "            self.dataset = val_ds \n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"please specify split to be either train or val\")\n",
    "            \n",
    "        self.cache_data()\n",
    "                   \n",
    "\n",
    "    def cache_data(self):\n",
    "        self.cached_X, self.cached_Y = [], []\n",
    "        \n",
    "        pb = tqdm(range(len(self.dataset)), desc=\"Cacheing\")\n",
    "\n",
    "        for i in pb:\n",
    "            \n",
    "            path, label = self.dataset[i]\n",
    "            df = pd.read_parquet(path)\n",
    "                        \n",
    "            one_hot_encoded_label = np.zeros(len(self.unique_labels))\n",
    "            one_hot_encoded_label[self.label_2_id[label]] = 1\n",
    "\n",
    "            self.cached_X.append(process_parquet2(df)) \n",
    "            self.cached_Y.append(one_hot_encoded_label)        \n",
    "\n",
    "    def __len__(self):\n",
    "        # Assuming each Parquet file should be one batch; adjust if necessary\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.preprocessing_func(self.cached_X[idx]), self.cached_Y[idx]                \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle files for the next epoch\n",
    "        np.random.shuffle(self.dataset)\n",
    "\n",
    "\n",
    "def preprocess(frames):\n",
    "    current_length, num_features = frames.shape\n",
    "\n",
    "    if current_length >= CONFIG.VIDEO_LENGTH:\n",
    "            # TODO: a better than uniform value ? Could place gaussian in the middle\n",
    "            random_start = random.randint(0, current_length - CONFIG.VIDEO_LENGTH)\n",
    "            return np.nan_to_num(frames[random_start : (random_start + CONFIG.VIDEO_LENGTH)])\n",
    "        \n",
    "    # padd the video to contain zeros \n",
    "    return np.concatenate([np.nan_to_num(frames), np.zeros((CONFIG.VIDEO_LENGTH - current_length, num_features))], axis=0)\n",
    "\n",
    "    \n",
    "# Usage example\n",
    "parquet_folder_path = CONFIG.root\n",
    "train_dataset_parquet = ParquetDatasetCached(parquet_folder_path, csv_file = os.path.join(CONFIG.root, \"train.csv\"), \n",
    "                                 batch_size=CONFIG.BATCH_SIZE, data_limit=1000,\n",
    "                                 preprocessing_func=preprocess,\n",
    "                                check_if_file_exists = True,\n",
    "                                split=\"train\")\n",
    "\n",
    "val_dataset_parquet = ParquetDatasetCached(parquet_folder_path, csv_file = os.path.join(CONFIG.root, \"train.csv\"), \n",
    "                                 batch_size=CONFIG.BATCH_SIZE, data_limit=1000,\n",
    "                                 preprocessing_func=preprocess,\n",
    "                                 check_if_file_exists= True,\n",
    "                                 split=\"val\")\n",
    "\n",
    "print(f\"cardinality of train : {len(train_dataset_parquet)}, cardinality of validation : {len(val_dataset_parquet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape = (25, 1629), Y_shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "X_shape = train_dataset_parquet[0][0].shape\n",
    "Y_shape = train_dataset_parquet[0][1].shape\n",
    "print(f\"X_shape = {X_shape}, Y_shape = {Y_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_train_generator():\n",
    "    # Instantiate your existing dataset loader\n",
    "\n",
    "    for i in range(len(train_dataset_parquet)):\n",
    "        X_batch, Y_batch = train_dataset_parquet[i]\n",
    "        yield X_batch, Y_batch\n",
    "        \n",
    "def dataset_val_generator():\n",
    "    # Instantiate your existing dataset loader\n",
    "\n",
    "    for i in range(len(val_dataset_parquet)):\n",
    "        X_batch, Y_batch = val_dataset_parquet[i]\n",
    "        yield X_batch, Y_batch        \n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: dataset_train_generator(),\n",
    "    output_types=(tf.float32, tf.float32),  # Adjust types based on your actual data\n",
    "    output_shapes=(X_shape, Y_shape)\n",
    ").prefetch(tf.data.AUTOTUNE).batch(CONFIG.BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: dataset_val_generator(),\n",
    "    output_types=(tf.float32, tf.float32),  # Adjust types based on your actual data\n",
    "    output_shapes=(X_shape, Y_shape)\n",
    ").prefetch(tf.data.AUTOTUNE).batch(CONFIG.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:00, 109.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 25, 1629) (8, 10)\n",
      "Iterating through dataset took : 0.1245s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "isnans =False\n",
    "\n",
    "f = True\n",
    "labels_batches = []\n",
    "for el in tqdm(train_dataset):\n",
    "    if f:\n",
    "        print(el[0].shape, el[1].shape)\n",
    "        f = False\n",
    "    labels_batches.append(el[1])\n",
    "        \n",
    "    isnans |= np.any(np.isnan(el[0]))\n",
    "    if isnans:\n",
    "        print(\"FOUND NAN!\")\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Iterating through dataset took : {round( time.time() - start , 4)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "from keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "\n",
    "\n",
    "class CosineAnnealingLearningRateScheduler(Callback):\n",
    "    def __init__(self, max_lr, min_lr, T_max):\n",
    "        super(CosineAnnealingLearningRateScheduler, self).__init__()\n",
    "        self.max_lr = max_lr  # Maximum learning rate (i.e., start learning rate)\n",
    "        self.min_lr = min_lr  # Minimum learning rate\n",
    "        self.T_max = T_max    # Specifies the number of epochs per cycle\n",
    "        self.t = 0            # Current epoch\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.t += 1\n",
    "        cos = np.cos(np.pi * (self.t % self.T_max) / self.T_max)\n",
    "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + cos)\n",
    "\n",
    "        keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "def keras_train(model, filepath : str, max_lr = 1e-4, min_lr = 5e-5, T_max=50, epochs=100, run_name=\"\",\n",
    "                mediapipe_features = \"all\", USE_WANDB=True): \n",
    "    \n",
    "    \n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                                 monitor=\"val_categorical_accuracy\",\n",
    "                                                 verbose=0,\n",
    "                                                 save_best_only=True,\n",
    "                                                 mode=\"max\",\n",
    "                                                 save_freq=\"epoch\")\n",
    "    \n",
    "    cosine_annealer = CosineAnnealingLearningRateScheduler(max_lr=max_lr,\n",
    "                                                           min_lr=min_lr,\n",
    "                                                           T_max=T_max)\n",
    "    \n",
    "    #Adam Optimizer - fixed learning rate.\n",
    "    adam_optimizer = tf.keras.optimizers.Adam(learning_rate=max_lr, clipnorm=1.)\n",
    "\n",
    "    model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    \n",
    "    callbacks  = [checkpoint, cosine_annealer]\n",
    "    \n",
    "    if USE_WANDB:\n",
    "        wandb.init(project=CONFIG.WANDB_RUN,\n",
    "                        name=run_name,\n",
    "                        notes=\"Model summary : \\n\" + str(model),\n",
    "                        config={\"max_lr\" : max_lr, \n",
    "                                \"min_lr\" : 5e-5, \n",
    "                                \"scheduler\" : \"cosineAnnealer\", \n",
    "                                \"epochs\" : epochs, \n",
    "                                \"T_max\" : T_max, \n",
    "                                \"train_size\" : len(train_dataset_parquet.dataset),\n",
    "                                \"val_size\" : len(val_dataset_parquet.dataset),\n",
    "                                \"unique_classes\" : len(train_dataset_parquet.unique_labels), \n",
    "                                \"video_length\" : CONFIG.VIDEO_LENGTH,\n",
    "                                \"features\" : mediapipe_features\n",
    "                                })\n",
    "        callbacks.append(WandbMetricsLogger())\n",
    "\n",
    "\n",
    "    history = model.fit(train_dataset, epochs=epochs, validation_data = val_dataset, callbacks=callbacks)\n",
    "    \n",
    "    if USE_WANDB:      \n",
    "        wandb.finish()\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "     12/Unknown - 5s 57ms/step - loss: 2.3933 - categorical_accuracy: 0.0521INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 14s 863ms/step - loss: 2.3941 - categorical_accuracy: 0.0500 - val_loss: 2.3655 - val_categorical_accuracy: 0.0900\n",
      "Epoch 2/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.3600 - categorical_accuracy: 0.1250INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 9s 707ms/step - loss: 2.3612 - categorical_accuracy: 0.1200 - val_loss: 2.3456 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.3428 - categorical_accuracy: 0.1875INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 9s 783ms/step - loss: 2.3433 - categorical_accuracy: 0.1800 - val_loss: 2.3314 - val_categorical_accuracy: 0.2100\n",
      "Epoch 4/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.3269 - categorical_accuracy: 0.2500INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 9s 746ms/step - loss: 2.3276 - categorical_accuracy: 0.2400 - val_loss: 2.3117 - val_categorical_accuracy: 0.2300\n",
      "Epoch 5/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.3091 - categorical_accuracy: 0.2188INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 9s 744ms/step - loss: 2.3101 - categorical_accuracy: 0.2100 - val_loss: 2.2952 - val_categorical_accuracy: 0.2400\n",
      "Epoch 6/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.2898 - categorical_accuracy: 0.2292INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 9s 726ms/step - loss: 2.2907 - categorical_accuracy: 0.2300 - val_loss: 2.2777 - val_categorical_accuracy: 0.2600\n",
      "Epoch 7/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.2738 - categorical_accuracy: 0.2604INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 9s 730ms/step - loss: 2.2746 - categorical_accuracy: 0.2600 - val_loss: 2.2515 - val_categorical_accuracy: 0.2800\n",
      "Epoch 8/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.2611 - categorical_accuracy: 0.2500INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 8s 692ms/step - loss: 2.2618 - categorical_accuracy: 0.2500 - val_loss: 2.2329 - val_categorical_accuracy: 0.2900\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 2.2373 - categorical_accuracy: 0.2800 - val_loss: 2.2116 - val_categorical_accuracy: 0.2700\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 2.2138 - categorical_accuracy: 0.2800 - val_loss: 2.1901 - val_categorical_accuracy: 0.2900\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 2.1983 - categorical_accuracy: 0.2900 - val_loss: 2.1720 - val_categorical_accuracy: 0.2900\n",
      "Epoch 12/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.1676 - categorical_accuracy: 0.3021INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM1.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 8s 694ms/step - loss: 2.1697 - categorical_accuracy: 0.3100 - val_loss: 2.1518 - val_categorical_accuracy: 0.3000\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.1515 - categorical_accuracy: 0.2700"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;28mlen\u001b[39m(train_dataset_parquet\u001b[38;5;241m.\u001b[39munique_labels), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m---> 12\u001b[0m keras_train(model, filepath\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM1.tf\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     13\u001b[0m             run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM128-Dense128-Dense256-allfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m             USE_WANDB\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[92], line 67\u001b[0m, in \u001b[0;36mkeras_train\u001b[1;34m(model, filepath, max_lr, min_lr, T_max, epochs, run_name, mediapipe_features, USE_WANDB)\u001b[0m\n\u001b[0;32m     50\u001b[0m     wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39mCONFIG\u001b[38;5;241m.\u001b[39mWANDB_RUN,\n\u001b[0;32m     51\u001b[0m                     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m     52\u001b[0m                     notes\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel summary : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(model),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m : mediapipe_features\n\u001b[0;32m     63\u001b[0m                             })\n\u001b[0;32m     64\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(WandbMetricsLogger())\n\u001b[1;32m---> 67\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_dataset, epochs\u001b[38;5;241m=\u001b[39mepochs, validation_data \u001b[38;5;241m=\u001b[39m val_dataset, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_WANDB:      \n\u001b[0;32m     70\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\training.py:1832\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1818\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1819\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1830\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[0;32m   1831\u001b[0m     )\n\u001b[1;32m-> 1832\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m   1833\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1834\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   1835\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[0;32m   1836\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[0;32m   1837\u001b[0m     steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m   1838\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1839\u001b[0m     max_queue_size\u001b[38;5;241m=\u001b[39mmax_queue_size,\n\u001b[0;32m   1840\u001b[0m     workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[0;32m   1841\u001b[0m     use_multiprocessing\u001b[38;5;241m=\u001b[39muse_multiprocessing,\n\u001b[0;32m   1842\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1843\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1844\u001b[0m )\n\u001b[0;32m   1845\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1847\u001b[0m }\n\u001b[0;32m   1848\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\training.py:2272\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2268\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   2269\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2270\u001b[0m             ):\n\u001b[0;32m   2271\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2272\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m test_function_runner\u001b[38;5;241m.\u001b[39mrun_step(\n\u001b[0;32m   2273\u001b[0m                     dataset_or_iterator,\n\u001b[0;32m   2274\u001b[0m                     data_handler,\n\u001b[0;32m   2275\u001b[0m                     step,\n\u001b[0;32m   2276\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[0;32m   2277\u001b[0m                 )\n\u001b[0;32m   2279\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2280\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\training.py:4079\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[1;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[0;32m   4078\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[1;32m-> 4079\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function(dataset_or_iterator)\n\u001b[0;32m   4080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   4081\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:876\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 876\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    877\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    878\u001b[0m )\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    880\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM1.tf\"),\n",
    "            run_name=\"LSTM128-Dense128-Dense256-allfeatures\",\n",
    "            USE_WANDB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM1.tf\"),\n",
    "            run_name=\"LSTM64-Dense128-Dense256-allfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(256, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM256-Dense128-Dense256-allfeatures.tf\"),\n",
    "            run_name=\"LSTM256-Dense128-Dense256-allfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM128-Dense256-allfeatures.tf\"),\n",
    "            run_name=\"LSTM128-Dense256-allfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM128-Dense128-allfeatures.tf\"),\n",
    "            run_name=\"LSTM128-Dense128-allfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, activation='relu', input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0000001), \n",
    "               activity_regularizer=l2(0.0000001)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM128_l2-Dense128-Dense256-allfeatures.tf\"),\n",
    "            run_name=\"LSTM128_l2-Dense128-Dense256-allfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:g1jztv1q) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td></td></tr><tr><td>epoch/epoch</td><td></td></tr><tr><td>epoch/learning_rate</td><td></td></tr><tr><td>epoch/loss</td><td></td></tr><tr><td>epoch/val_categorical_accuracy</td><td></td></tr><tr><td>epoch/val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td>0.36889</td></tr><tr><td>epoch/epoch</td><td>0</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>2.82214</td></tr><tr><td>epoch/val_categorical_accuracy</td><td>0.45</td></tr><tr><td>epoch/val_loss</td><td>2.39018</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM64-Dense128-Dense256-allfeatures_bigger_reg</strong> at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/g1jztv1q' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/g1jztv1q</a><br/> View project at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240408_085721-g1jztv1q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:g1jztv1q). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae32d08edf64e04a8009a32b4a48b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113070862160788, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20240408_085904-b2cvthn0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/b2cvthn0' target=\"_blank\">LSTM64-Dense128-Dense256-allfeatures_bigger_reg</a></strong> to <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/b2cvthn0' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/b2cvthn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 2.8411 - categorical_accuracy: 0.4000INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 60s 499ms/step - loss: 2.8411 - categorical_accuracy: 0.4000 - val_loss: 2.4088 - val_categorical_accuracy: 0.4200\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 2.1274 - categorical_accuracy: 0.4056INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 502ms/step - loss: 2.1274 - categorical_accuracy: 0.4056 - val_loss: 1.8624 - val_categorical_accuracy: 0.4300\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 49s 439ms/step - loss: 1.7043 - categorical_accuracy: 0.4044 - val_loss: 1.5451 - val_categorical_accuracy: 0.4300\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 1.4585 - categorical_accuracy: 0.4056 - val_loss: 1.3563 - val_categorical_accuracy: 0.4400\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 50s 441ms/step - loss: 1.3106 - categorical_accuracy: 0.4056 - val_loss: 1.2412 - val_categorical_accuracy: 0.4300\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.2187 - categorical_accuracy: 0.4167INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 503ms/step - loss: 1.2187 - categorical_accuracy: 0.4167 - val_loss: 1.1653 - val_categorical_accuracy: 0.4200\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.1668 - categorical_accuracy: 0.4211INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 505ms/step - loss: 1.1668 - categorical_accuracy: 0.4211 - val_loss: 1.0656 - val_categorical_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 50s 442ms/step - loss: 1.1402 - categorical_accuracy: 0.4167 - val_loss: 1.0608 - val_categorical_accuracy: 0.5100\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0638 - categorical_accuracy: 0.4833INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 505ms/step - loss: 1.0638 - categorical_accuracy: 0.4833 - val_loss: 0.9921 - val_categorical_accuracy: 0.5600\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0240 - categorical_accuracy: 0.4889INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 500ms/step - loss: 1.0240 - categorical_accuracy: 0.4889 - val_loss: 1.0163 - val_categorical_accuracy: 0.5200\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0002 - categorical_accuracy: 0.5100INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 512ms/step - loss: 1.0002 - categorical_accuracy: 0.5100 - val_loss: 0.9776 - val_categorical_accuracy: 0.5200\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9623 - categorical_accuracy: 0.5144INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 512ms/step - loss: 0.9623 - categorical_accuracy: 0.5144 - val_loss: 0.9214 - val_categorical_accuracy: 0.5500\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9209 - categorical_accuracy: 0.5544INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 505ms/step - loss: 0.9209 - categorical_accuracy: 0.5544 - val_loss: 0.8942 - val_categorical_accuracy: 0.5600\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.9315 - categorical_accuracy: 0.5333 - val_loss: 0.9100 - val_categorical_accuracy: 0.5400\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8799 - categorical_accuracy: 0.5733INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 512ms/step - loss: 0.8799 - categorical_accuracy: 0.5733 - val_loss: 0.8732 - val_categorical_accuracy: 0.5500\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.8731 - categorical_accuracy: 0.5589 - val_loss: 0.8565 - val_categorical_accuracy: 0.5900\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.8757 - categorical_accuracy: 0.5556 - val_loss: 0.8595 - val_categorical_accuracy: 0.5800\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 50s 444ms/step - loss: 0.8616 - categorical_accuracy: 0.5733 - val_loss: 0.8362 - val_categorical_accuracy: 0.6100\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8751 - categorical_accuracy: 0.5800INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 505ms/step - loss: 0.8751 - categorical_accuracy: 0.5800 - val_loss: 0.8408 - val_categorical_accuracy: 0.5700\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8239 - categorical_accuracy: 0.6022INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 56s 502ms/step - loss: 0.8239 - categorical_accuracy: 0.6022 - val_loss: 0.8111 - val_categorical_accuracy: 0.6000\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8207 - categorical_accuracy: 0.6067INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 511ms/step - loss: 0.8207 - categorical_accuracy: 0.6067 - val_loss: 0.8012 - val_categorical_accuracy: 0.6100\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7945 - categorical_accuracy: 0.6511INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 510ms/step - loss: 0.7945 - categorical_accuracy: 0.6511 - val_loss: 0.7536 - val_categorical_accuracy: 0.6500\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.7951 - categorical_accuracy: 0.6400 - val_loss: 0.9351 - val_categorical_accuracy: 0.6400\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 50s 449ms/step - loss: 0.8354 - categorical_accuracy: 0.6267 - val_loss: 1.3834 - val_categorical_accuracy: 0.3300\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7755 - categorical_accuracy: 0.6633INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 56s 499ms/step - loss: 0.7755 - categorical_accuracy: 0.6633 - val_loss: 0.7559 - val_categorical_accuracy: 0.6800\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7431 - categorical_accuracy: 0.7156INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 515ms/step - loss: 0.7431 - categorical_accuracy: 0.7156 - val_loss: 0.8453 - val_categorical_accuracy: 0.5700\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7037 - categorical_accuracy: 0.7278INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 56s 502ms/step - loss: 0.7037 - categorical_accuracy: 0.7278 - val_loss: 0.7106 - val_categorical_accuracy: 0.7100\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6386 - categorical_accuracy: 0.7778INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 502ms/step - loss: 0.6386 - categorical_accuracy: 0.7778 - val_loss: 0.7482 - val_categorical_accuracy: 0.6600\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.6493 - categorical_accuracy: 0.7622 - val_loss: 0.5469 - val_categorical_accuracy: 0.8400\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 50s 441ms/step - loss: 0.6398 - categorical_accuracy: 0.7711 - val_loss: 0.5749 - val_categorical_accuracy: 0.7700\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6062 - categorical_accuracy: 0.7833INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 508ms/step - loss: 0.6062 - categorical_accuracy: 0.7833 - val_loss: 0.7759 - val_categorical_accuracy: 0.6900\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5734 - categorical_accuracy: 0.8022INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 510ms/step - loss: 0.5734 - categorical_accuracy: 0.8022 - val_loss: 0.6057 - val_categorical_accuracy: 0.7800\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5675 - categorical_accuracy: 0.8044INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 506ms/step - loss: 0.5675 - categorical_accuracy: 0.8044 - val_loss: 0.7343 - val_categorical_accuracy: 0.7800\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.5910 - categorical_accuracy: 0.7911 - val_loss: 0.5328 - val_categorical_accuracy: 0.8200\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.6100 - categorical_accuracy: 0.7944 - val_loss: 0.9632 - val_categorical_accuracy: 0.7100\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.6669 - categorical_accuracy: 0.7811 - val_loss: 0.5713 - val_categorical_accuracy: 0.8100\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.5737 - categorical_accuracy: 0.8033 - val_loss: 0.8288 - val_categorical_accuracy: 0.6900\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5330 - categorical_accuracy: 0.8344INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 510ms/step - loss: 0.5330 - categorical_accuracy: 0.8344 - val_loss: 0.8726 - val_categorical_accuracy: 0.6300\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.5579 - categorical_accuracy: 0.8111 - val_loss: 0.7435 - val_categorical_accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.5458 - categorical_accuracy: 0.8233 - val_loss: 0.8340 - val_categorical_accuracy: 0.7000\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.6143 - categorical_accuracy: 0.7856 - val_loss: 0.7396 - val_categorical_accuracy: 0.7700\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.5929 - categorical_accuracy: 0.7967 - val_loss: 0.7475 - val_categorical_accuracy: 0.6900\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.5422 - categorical_accuracy: 0.8333 - val_loss: 0.6000 - val_categorical_accuracy: 0.8200\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4798 - categorical_accuracy: 0.8567INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 507ms/step - loss: 0.4798 - categorical_accuracy: 0.8567 - val_loss: 0.6378 - val_categorical_accuracy: 0.7800\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 49s 438ms/step - loss: 0.5517 - categorical_accuracy: 0.8100 - val_loss: 0.6610 - val_categorical_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 50s 444ms/step - loss: 0.5207 - categorical_accuracy: 0.8422 - val_loss: 0.5422 - val_categorical_accuracy: 0.8600\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.5088 - categorical_accuracy: 0.8489 - val_loss: 0.5806 - val_categorical_accuracy: 0.7900\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.5605 - categorical_accuracy: 0.8167 - val_loss: 0.4904 - val_categorical_accuracy: 0.8400\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.5473 - categorical_accuracy: 0.8278 - val_loss: 0.6565 - val_categorical_accuracy: 0.7600\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.5422 - categorical_accuracy: 0.8378 - val_loss: 0.6482 - val_categorical_accuracy: 0.8100\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 50s 444ms/step - loss: 0.4920 - categorical_accuracy: 0.8533 - val_loss: 0.9195 - val_categorical_accuracy: 0.7200\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.5176 - categorical_accuracy: 0.8456 - val_loss: 0.4050 - val_categorical_accuracy: 0.8900\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.5224 - categorical_accuracy: 0.8367 - val_loss: 0.6238 - val_categorical_accuracy: 0.8300\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 51s 446ms/step - loss: 0.4998 - categorical_accuracy: 0.8511 - val_loss: 0.7593 - val_categorical_accuracy: 0.6900\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4259 - categorical_accuracy: 0.8800INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 505ms/step - loss: 0.4259 - categorical_accuracy: 0.8800 - val_loss: 0.6574 - val_categorical_accuracy: 0.7800\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 51s 446ms/step - loss: 0.5203 - categorical_accuracy: 0.8444 - val_loss: 0.5315 - val_categorical_accuracy: 0.8300\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.5094 - categorical_accuracy: 0.8478 - val_loss: 0.6249 - val_categorical_accuracy: 0.8100\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 51s 447ms/step - loss: 0.5697 - categorical_accuracy: 0.8200 - val_loss: 0.4367 - val_categorical_accuracy: 0.9000\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.4575 - categorical_accuracy: 0.8767 - val_loss: 0.6292 - val_categorical_accuracy: 0.8000\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.4987 - categorical_accuracy: 0.8511 - val_loss: 0.5974 - val_categorical_accuracy: 0.8300\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 50s 448ms/step - loss: 0.5852 - categorical_accuracy: 0.8289 - val_loss: 0.6959 - val_categorical_accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.5027 - categorical_accuracy: 0.8533 - val_loss: 0.5093 - val_categorical_accuracy: 0.8500\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 50s 441ms/step - loss: 0.4957 - categorical_accuracy: 0.8622 - val_loss: 0.4846 - val_categorical_accuracy: 0.8500\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.5055 - categorical_accuracy: 0.8533 - val_loss: 0.5980 - val_categorical_accuracy: 0.8600\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.5464 - categorical_accuracy: 0.8367 - val_loss: 0.5365 - val_categorical_accuracy: 0.8400\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 50s 448ms/step - loss: 0.4602 - categorical_accuracy: 0.8689 - val_loss: 0.4441 - val_categorical_accuracy: 0.8800\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.5463 - categorical_accuracy: 0.8189 - val_loss: 0.5223 - val_categorical_accuracy: 0.8000\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4312 - categorical_accuracy: 0.8878INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 513ms/step - loss: 0.4312 - categorical_accuracy: 0.8878 - val_loss: 0.4676 - val_categorical_accuracy: 0.8600\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.4691 - categorical_accuracy: 0.8589 - val_loss: 0.4604 - val_categorical_accuracy: 0.8700\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.4864 - categorical_accuracy: 0.8567 - val_loss: 0.4465 - val_categorical_accuracy: 0.9000\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.4778 - categorical_accuracy: 0.8678 - val_loss: 0.4316 - val_categorical_accuracy: 0.8800\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.4969 - categorical_accuracy: 0.8444 - val_loss: 0.4481 - val_categorical_accuracy: 0.8800\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 50s 448ms/step - loss: 0.4584 - categorical_accuracy: 0.8644 - val_loss: 0.4431 - val_categorical_accuracy: 0.9100\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4070 - categorical_accuracy: 0.8900INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 505ms/step - loss: 0.4070 - categorical_accuracy: 0.8900 - val_loss: 0.4321 - val_categorical_accuracy: 0.8800\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 50s 442ms/step - loss: 0.4880 - categorical_accuracy: 0.8633 - val_loss: 0.4699 - val_categorical_accuracy: 0.8800\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 50s 439ms/step - loss: 0.4324 - categorical_accuracy: 0.8822 - val_loss: 0.4674 - val_categorical_accuracy: 0.8600\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 50s 439ms/step - loss: 0.4607 - categorical_accuracy: 0.8722 - val_loss: 0.4195 - val_categorical_accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.5813 - categorical_accuracy: 0.8144 - val_loss: 0.7107 - val_categorical_accuracy: 0.8300\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 50s 440ms/step - loss: 0.5578 - categorical_accuracy: 0.8311 - val_loss: 0.4452 - val_categorical_accuracy: 0.8800\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 50s 439ms/step - loss: 0.4656 - categorical_accuracy: 0.8722 - val_loss: 0.4972 - val_categorical_accuracy: 0.8600\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.4155 - categorical_accuracy: 0.8800 - val_loss: 0.7409 - val_categorical_accuracy: 0.8000\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.5258 - categorical_accuracy: 0.8367 - val_loss: 0.4980 - val_categorical_accuracy: 0.8300\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 50s 442ms/step - loss: 0.4853 - categorical_accuracy: 0.8689 - val_loss: 0.5915 - val_categorical_accuracy: 0.8200\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 50s 439ms/step - loss: 0.4376 - categorical_accuracy: 0.8811 - val_loss: 0.4558 - val_categorical_accuracy: 0.8700\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 50s 441ms/step - loss: 0.4365 - categorical_accuracy: 0.8822 - val_loss: 0.5814 - val_categorical_accuracy: 0.8300\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 50s 440ms/step - loss: 0.5081 - categorical_accuracy: 0.8378 - val_loss: 0.7659 - val_categorical_accuracy: 0.7900\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.4477 - categorical_accuracy: 0.8767 - val_loss: 0.4377 - val_categorical_accuracy: 0.8800\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 50s 438ms/step - loss: 0.4153 - categorical_accuracy: 0.8900 - val_loss: 0.3688 - val_categorical_accuracy: 0.9100\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4063 - categorical_accuracy: 0.8922INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM-L64-D128-D256-reg=0.005.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 56s 498ms/step - loss: 0.4063 - categorical_accuracy: 0.8922 - val_loss: 0.4536 - val_categorical_accuracy: 0.8800\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 51s 444ms/step - loss: 0.4751 - categorical_accuracy: 0.8656 - val_loss: 0.5127 - val_categorical_accuracy: 0.8400\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 50s 442ms/step - loss: 0.4397 - categorical_accuracy: 0.8767 - val_loss: 0.4737 - val_categorical_accuracy: 0.8700\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.4376 - categorical_accuracy: 0.8722 - val_loss: 0.4013 - val_categorical_accuracy: 0.8800\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.4417 - categorical_accuracy: 0.8722 - val_loss: 0.4582 - val_categorical_accuracy: 0.8600\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 50s 441ms/step - loss: 0.4192 - categorical_accuracy: 0.8867 - val_loss: 0.4077 - val_categorical_accuracy: 0.9000\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 50s 444ms/step - loss: 0.5048 - categorical_accuracy: 0.8467 - val_loss: 0.6696 - val_categorical_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td></td></tr><tr><td>epoch/epoch</td><td></td></tr><tr><td>epoch/learning_rate</td><td></td></tr><tr><td>epoch/loss</td><td></td></tr><tr><td>epoch/val_categorical_accuracy</td><td></td></tr><tr><td>epoch/val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td>0.84667</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>0.50475</td></tr><tr><td>epoch/val_categorical_accuracy</td><td>0.8</td></tr><tr><td>epoch/val_loss</td><td>0.66957</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM64-Dense128-Dense256-allfeatures_bigger_reg</strong> at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/b2cvthn0' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/b2cvthn0</a><br/> View project at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240408_085904-b2cvthn0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fda6bc02690>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.005), \n",
    "               activity_regularizer=l2(0.005)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM-L64-D128-D256-reg=0.005.tf\"),\n",
    "            run_name=\"LSTM64-Dense128-Dense256-allfeatures_bigger_reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ehqx0ymo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.010 MB uploaded\\r'), FloatProgress(value=0.5380860274477296, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM128-Dense128-Dense256-allfeatures</strong> at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/ehqx0ymo' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/ehqx0ymo</a><br/> View project at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240408_102806-ehqx0ymo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ehqx0ymo). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02c443cf9c24d67afce99e0dd73feaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111298907134268, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20240408_102839-tfbow8kv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/tfbow8kv' target=\"_blank\">LSTM128-Dense128-Dense256-allfeatures</a></strong> to <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/tfbow8kv' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/tfbow8kv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.1593 - categorical_accuracy: 0.4111INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 59s 497ms/step - loss: 1.1593 - categorical_accuracy: 0.4111 - val_loss: 1.1264 - val_categorical_accuracy: 0.4300\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 50s 440ms/step - loss: 1.1159 - categorical_accuracy: 0.4122 - val_loss: 1.0794 - val_categorical_accuracy: 0.4300\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 50s 444ms/step - loss: 1.0872 - categorical_accuracy: 0.4156 - val_loss: 1.0639 - val_categorical_accuracy: 0.4300\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0789 - categorical_accuracy: 0.4222INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 504ms/step - loss: 1.0789 - categorical_accuracy: 0.4222 - val_loss: 1.0364 - val_categorical_accuracy: 0.4500\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0382 - categorical_accuracy: 0.4522INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 504ms/step - loss: 1.0382 - categorical_accuracy: 0.4522 - val_loss: 0.9582 - val_categorical_accuracy: 0.4800\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9295 - categorical_accuracy: 0.5167INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 56s 500ms/step - loss: 0.9295 - categorical_accuracy: 0.5167 - val_loss: 0.8747 - val_categorical_accuracy: 0.5400\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.8825 - categorical_accuracy: 0.5411 - val_loss: 0.8312 - val_categorical_accuracy: 0.5300\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8269 - categorical_accuracy: 0.5622INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 509ms/step - loss: 0.8269 - categorical_accuracy: 0.5622 - val_loss: 0.8254 - val_categorical_accuracy: 0.5500\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8556 - categorical_accuracy: 0.5433INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 507ms/step - loss: 0.8556 - categorical_accuracy: 0.5433 - val_loss: 0.8159 - val_categorical_accuracy: 0.6200\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.8348 - categorical_accuracy: 0.5756 - val_loss: 0.7958 - val_categorical_accuracy: 0.5500\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 50s 442ms/step - loss: 0.8885 - categorical_accuracy: 0.5233 - val_loss: 0.9448 - val_categorical_accuracy: 0.5100\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.8151 - categorical_accuracy: 0.5722 - val_loss: 0.8031 - val_categorical_accuracy: 0.5500\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.7978 - categorical_accuracy: 0.5844 - val_loss: 0.8093 - val_categorical_accuracy: 0.5400\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 50s 444ms/step - loss: 0.7737 - categorical_accuracy: 0.5944 - val_loss: 0.7904 - val_categorical_accuracy: 0.5900\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.7715 - categorical_accuracy: 0.6011 - val_loss: 0.7445 - val_categorical_accuracy: 0.6100\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.7729 - categorical_accuracy: 0.6289 - val_loss: 0.7602 - val_categorical_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7333 - categorical_accuracy: 0.6744INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 506ms/step - loss: 0.7333 - categorical_accuracy: 0.6744 - val_loss: 0.7445 - val_categorical_accuracy: 0.6900\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6788 - categorical_accuracy: 0.7311INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 503ms/step - loss: 0.6788 - categorical_accuracy: 0.7311 - val_loss: 0.6787 - val_categorical_accuracy: 0.7300\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6468 - categorical_accuracy: 0.7200INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 508ms/step - loss: 0.6468 - categorical_accuracy: 0.7200 - val_loss: 0.5513 - val_categorical_accuracy: 0.8400\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.6418 - categorical_accuracy: 0.7500 - val_loss: 0.5769 - val_categorical_accuracy: 0.7900\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.5473 - categorical_accuracy: 0.8067 - val_loss: 0.5113 - val_categorical_accuracy: 0.8200\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.5497 - categorical_accuracy: 0.8022 - val_loss: 0.4657 - val_categorical_accuracy: 0.8200\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5541 - categorical_accuracy: 0.7900INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 509ms/step - loss: 0.5541 - categorical_accuracy: 0.7900 - val_loss: 0.5049 - val_categorical_accuracy: 0.8500\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 50s 444ms/step - loss: 0.5154 - categorical_accuracy: 0.7989 - val_loss: 0.5346 - val_categorical_accuracy: 0.7900\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.5237 - categorical_accuracy: 0.8133 - val_loss: 0.4664 - val_categorical_accuracy: 0.8300\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.5831 - categorical_accuracy: 0.8033 - val_loss: 0.5966 - val_categorical_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.5225 - categorical_accuracy: 0.8033 - val_loss: 0.7948 - val_categorical_accuracy: 0.7300\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.5959 - categorical_accuracy: 0.7822 - val_loss: 0.6207 - val_categorical_accuracy: 0.7900\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4713 - categorical_accuracy: 0.8367INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 512ms/step - loss: 0.4713 - categorical_accuracy: 0.8367 - val_loss: 0.4706 - val_categorical_accuracy: 0.8600\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.4891 - categorical_accuracy: 0.8333 - val_loss: 0.4781 - val_categorical_accuracy: 0.8400\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.5176 - categorical_accuracy: 0.8200 - val_loss: 0.5093 - val_categorical_accuracy: 0.8400\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.4791 - categorical_accuracy: 0.8400 - val_loss: 0.4815 - val_categorical_accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 50s 448ms/step - loss: 0.4326 - categorical_accuracy: 0.8689 - val_loss: 0.5219 - val_categorical_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4221 - categorical_accuracy: 0.8611INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 509ms/step - loss: 0.4221 - categorical_accuracy: 0.8611 - val_loss: 0.4338 - val_categorical_accuracy: 0.8700\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.4176 - categorical_accuracy: 0.8600 - val_loss: 0.5111 - val_categorical_accuracy: 0.8100\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 50s 441ms/step - loss: 0.3978 - categorical_accuracy: 0.8722 - val_loss: 0.4874 - val_categorical_accuracy: 0.8100\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4454 - categorical_accuracy: 0.8511INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 504ms/step - loss: 0.4454 - categorical_accuracy: 0.8511 - val_loss: 0.3816 - val_categorical_accuracy: 0.8900\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 49s 437ms/step - loss: 0.3786 - categorical_accuracy: 0.8889 - val_loss: 0.4801 - val_categorical_accuracy: 0.8500\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.3902 - categorical_accuracy: 0.8922 - val_loss: 0.5937 - val_categorical_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 50s 441ms/step - loss: 0.3852 - categorical_accuracy: 0.8889 - val_loss: 0.4676 - val_categorical_accuracy: 0.8500\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.3807 - categorical_accuracy: 0.8856 - val_loss: 0.4871 - val_categorical_accuracy: 0.8300\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 50s 444ms/step - loss: 0.3750 - categorical_accuracy: 0.8822 - val_loss: 0.4893 - val_categorical_accuracy: 0.8600\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 50s 441ms/step - loss: 0.4044 - categorical_accuracy: 0.8911 - val_loss: 0.6310 - val_categorical_accuracy: 0.7900\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 50s 442ms/step - loss: 0.3771 - categorical_accuracy: 0.8867 - val_loss: 0.4822 - val_categorical_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3903 - categorical_accuracy: 0.8844INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 56s 499ms/step - loss: 0.3903 - categorical_accuracy: 0.8844 - val_loss: 0.3689 - val_categorical_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.3459 - categorical_accuracy: 0.9078 - val_loss: 0.3768 - val_categorical_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3704 - categorical_accuracy: 0.8956 - val_loss: 0.4289 - val_categorical_accuracy: 0.8800\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.3126 - categorical_accuracy: 0.9122 - val_loss: 0.4029 - val_categorical_accuracy: 0.8800\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3530 - categorical_accuracy: 0.8922 - val_loss: 0.4759 - val_categorical_accuracy: 0.8700\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.4171 - categorical_accuracy: 0.8767 - val_loss: 0.6324 - val_categorical_accuracy: 0.7900\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.4903 - categorical_accuracy: 0.8400 - val_loss: 0.4580 - val_categorical_accuracy: 0.8600\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.5004 - categorical_accuracy: 0.8322 - val_loss: 0.7386 - val_categorical_accuracy: 0.7800\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.5495 - categorical_accuracy: 0.8144 - val_loss: 0.5707 - val_categorical_accuracy: 0.8200\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.4326 - categorical_accuracy: 0.8522 - val_loss: 0.4949 - val_categorical_accuracy: 0.8600\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.4168 - categorical_accuracy: 0.8711 - val_loss: 0.3718 - val_categorical_accuracy: 0.8700\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.4029 - categorical_accuracy: 0.8656 - val_loss: 0.3996 - val_categorical_accuracy: 0.8900\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.3701 - categorical_accuracy: 0.8833 - val_loss: 0.4646 - val_categorical_accuracy: 0.8700\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.3946 - categorical_accuracy: 0.8789 - val_loss: 0.7404 - val_categorical_accuracy: 0.7200\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.3892 - categorical_accuracy: 0.8789 - val_loss: 0.4167 - val_categorical_accuracy: 0.8900\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.3286 - categorical_accuracy: 0.8978 - val_loss: 0.4500 - val_categorical_accuracy: 0.8700\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.4057 - categorical_accuracy: 0.8778 - val_loss: 0.5199 - val_categorical_accuracy: 0.8400\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.4515 - categorical_accuracy: 0.8611 - val_loss: 0.4424 - val_categorical_accuracy: 0.8700\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.4480 - categorical_accuracy: 0.8656 - val_loss: 0.4351 - val_categorical_accuracy: 0.8900\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 51s 447ms/step - loss: 0.3490 - categorical_accuracy: 0.8967 - val_loss: 0.5264 - val_categorical_accuracy: 0.8400\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3577 - categorical_accuracy: 0.9011 - val_loss: 0.4346 - val_categorical_accuracy: 0.8300\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.3784 - categorical_accuracy: 0.8800 - val_loss: 0.4018 - val_categorical_accuracy: 0.8700\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.3576 - categorical_accuracy: 0.8956 - val_loss: 0.5138 - val_categorical_accuracy: 0.8200\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.3531 - categorical_accuracy: 0.8933 - val_loss: 0.4497 - val_categorical_accuracy: 0.8500\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 51s 446ms/step - loss: 0.3818 - categorical_accuracy: 0.8944 - val_loss: 0.5373 - val_categorical_accuracy: 0.8200\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 51s 447ms/step - loss: 0.3838 - categorical_accuracy: 0.8922 - val_loss: 0.5568 - val_categorical_accuracy: 0.8300\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 50s 443ms/step - loss: 0.2919 - categorical_accuracy: 0.9233 - val_loss: 0.4551 - val_categorical_accuracy: 0.8700\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3211 - categorical_accuracy: 0.9078 - val_loss: 0.4649 - val_categorical_accuracy: 0.8700\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 50s 446ms/step - loss: 0.3066 - categorical_accuracy: 0.9122 - val_loss: 0.4409 - val_categorical_accuracy: 0.8600\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.3514 - categorical_accuracy: 0.8922 - val_loss: 0.4000 - val_categorical_accuracy: 0.8900\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.3193 - categorical_accuracy: 0.9122 - val_loss: 0.3849 - val_categorical_accuracy: 0.8700\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.3559 - categorical_accuracy: 0.8922 - val_loss: 0.4093 - val_categorical_accuracy: 0.8900\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.2585 - categorical_accuracy: 0.9344 - val_loss: 0.3891 - val_categorical_accuracy: 0.8900\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.2845 - categorical_accuracy: 0.9200INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM128-Dense128-Dense256-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 506ms/step - loss: 0.2845 - categorical_accuracy: 0.9200 - val_loss: 0.3175 - val_categorical_accuracy: 0.9200\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.3147 - categorical_accuracy: 0.9156 - val_loss: 0.3852 - val_categorical_accuracy: 0.8900\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.2673 - categorical_accuracy: 0.9200 - val_loss: 0.3926 - val_categorical_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.2707 - categorical_accuracy: 0.9256 - val_loss: 0.3431 - val_categorical_accuracy: 0.9000\n",
      "Epoch 82/100\n",
      "  6/113 [>.............................] - ETA: 38s - loss: 0.2516 - categorical_accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM128-Dense128-Dense256-allfeatures.tf\"),\n",
    "            run_name=\"LSTM128-Dense128-Dense256-allfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:vxwg2tiq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td></td></tr><tr><td>epoch/epoch</td><td></td></tr><tr><td>epoch/learning_rate</td><td></td></tr><tr><td>epoch/loss</td><td></td></tr><tr><td>epoch/val_categorical_accuracy</td><td></td></tr><tr><td>epoch/val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td>0.41667</td></tr><tr><td>epoch/epoch</td><td>0</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>1.13316</td></tr><tr><td>epoch/val_categorical_accuracy</td><td>0.44</td></tr><tr><td>epoch/val_loss</td><td>1.11618</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM64-Dense64-allfeatures</strong> at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/vxwg2tiq' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/vxwg2tiq</a><br/> View project at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240408_124116-vxwg2tiq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:vxwg2tiq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a843215891450f8950dbbea742785b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112615217765172, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20240408_124402-tyh5w2ae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/tyh5w2ae' target=\"_blank\">LSTM64-Dense64-allfeatures</a></strong> to <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/tyh5w2ae' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/tyh5w2ae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.1343 - categorical_accuracy: 0.4444INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 59s 497ms/step - loss: 1.1343 - categorical_accuracy: 0.4444 - val_loss: 1.1175 - val_categorical_accuracy: 0.4300\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 1.1170 - categorical_accuracy: 0.4256 - val_loss: 1.0923 - val_categorical_accuracy: 0.4300\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 52s 454ms/step - loss: 1.0976 - categorical_accuracy: 0.4200 - val_loss: 1.0688 - val_categorical_accuracy: 0.4300\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 1.0772 - categorical_accuracy: 0.4267 - val_loss: 1.0476 - val_categorical_accuracy: 0.4300\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 1.0660 - categorical_accuracy: 0.4222 - val_loss: 1.0532 - val_categorical_accuracy: 0.4300\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 1.0527 - categorical_accuracy: 0.4122 - val_loss: 1.0162 - val_categorical_accuracy: 0.4300\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0104 - categorical_accuracy: 0.4322INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 518ms/step - loss: 1.0104 - categorical_accuracy: 0.4322 - val_loss: 0.9230 - val_categorical_accuracy: 0.5300\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.9788 - categorical_accuracy: 0.4911 - val_loss: 1.0028 - val_categorical_accuracy: 0.4700\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9554 - categorical_accuracy: 0.5089INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 512ms/step - loss: 0.9554 - categorical_accuracy: 0.5089 - val_loss: 0.9205 - val_categorical_accuracy: 0.5400\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8856 - categorical_accuracy: 0.5389INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 514ms/step - loss: 0.8856 - categorical_accuracy: 0.5389 - val_loss: 0.8232 - val_categorical_accuracy: 0.5600\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.8843 - categorical_accuracy: 0.5400 - val_loss: 0.8389 - val_categorical_accuracy: 0.5600\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.8609 - categorical_accuracy: 0.5311 - val_loss: 0.8181 - val_categorical_accuracy: 0.5600\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.8422 - categorical_accuracy: 0.5622 - val_loss: 0.8075 - val_categorical_accuracy: 0.5500\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.8400 - categorical_accuracy: 0.5556 - val_loss: 0.8344 - val_categorical_accuracy: 0.5600\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.8375 - categorical_accuracy: 0.5533 - val_loss: 0.8198 - val_categorical_accuracy: 0.5400\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.8186 - categorical_accuracy: 0.5600 - val_loss: 0.8137 - val_categorical_accuracy: 0.5500\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.8218 - categorical_accuracy: 0.5478 - val_loss: 0.8052 - val_categorical_accuracy: 0.5300\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.8168 - categorical_accuracy: 0.5567 - val_loss: 0.8125 - val_categorical_accuracy: 0.5600\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7975 - categorical_accuracy: 0.5889INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 514ms/step - loss: 0.7975 - categorical_accuracy: 0.5889 - val_loss: 0.7677 - val_categorical_accuracy: 0.5700\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7678 - categorical_accuracy: 0.5900INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 510ms/step - loss: 0.7678 - categorical_accuracy: 0.5900 - val_loss: 0.7368 - val_categorical_accuracy: 0.6100\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.7924 - categorical_accuracy: 0.5856 - val_loss: 0.8150 - val_categorical_accuracy: 0.5900\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.7752 - categorical_accuracy: 0.6200 - val_loss: 0.8004 - val_categorical_accuracy: 0.5900\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 51s 446ms/step - loss: 0.7590 - categorical_accuracy: 0.6222 - val_loss: 0.7709 - val_categorical_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7470 - categorical_accuracy: 0.6400INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 503ms/step - loss: 0.7470 - categorical_accuracy: 0.6400 - val_loss: 0.7407 - val_categorical_accuracy: 0.6800\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 51s 456ms/step - loss: 0.6949 - categorical_accuracy: 0.6856 - val_loss: 0.6845 - val_categorical_accuracy: 0.6800\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7088 - categorical_accuracy: 0.7156INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 515ms/step - loss: 0.7088 - categorical_accuracy: 0.7156 - val_loss: 0.6359 - val_categorical_accuracy: 0.7800\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.6057 - categorical_accuracy: 0.7789 - val_loss: 0.6122 - val_categorical_accuracy: 0.7800\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.5726 - categorical_accuracy: 0.7922 - val_loss: 0.5490 - val_categorical_accuracy: 0.7800\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.5773 - categorical_accuracy: 0.7700 - val_loss: 0.6536 - val_categorical_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.6203 - categorical_accuracy: 0.7578 - val_loss: 0.5957 - val_categorical_accuracy: 0.7600\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5099 - categorical_accuracy: 0.8278INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 59s 525ms/step - loss: 0.5099 - categorical_accuracy: 0.8278 - val_loss: 0.5750 - val_categorical_accuracy: 0.7900\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.5296 - categorical_accuracy: 0.8056 - val_loss: 0.6380 - val_categorical_accuracy: 0.7300\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.5025 - categorical_accuracy: 0.8167 - val_loss: 0.6393 - val_categorical_accuracy: 0.7700\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.5316 - categorical_accuracy: 0.8089 - val_loss: 0.6577 - val_categorical_accuracy: 0.7400\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5025 - categorical_accuracy: 0.8278INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 503ms/step - loss: 0.5025 - categorical_accuracy: 0.8278 - val_loss: 0.5503 - val_categorical_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 52s 460ms/step - loss: 0.4798 - categorical_accuracy: 0.8322 - val_loss: 0.5658 - val_categorical_accuracy: 0.7900\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4456 - categorical_accuracy: 0.8544INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 510ms/step - loss: 0.4456 - categorical_accuracy: 0.8544 - val_loss: 0.5746 - val_categorical_accuracy: 0.8100\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.4612 - categorical_accuracy: 0.8422 - val_loss: 0.6220 - val_categorical_accuracy: 0.7800\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.4847 - categorical_accuracy: 0.8411 - val_loss: 0.5608 - val_categorical_accuracy: 0.7900\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.4923 - categorical_accuracy: 0.8311 - val_loss: 0.5668 - val_categorical_accuracy: 0.7900\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.4842 - categorical_accuracy: 0.8278 - val_loss: 0.7195 - val_categorical_accuracy: 0.7000\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.4352 - categorical_accuracy: 0.8600 - val_loss: 0.5334 - val_categorical_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4023 - categorical_accuracy: 0.8844INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 59s 523ms/step - loss: 0.4023 - categorical_accuracy: 0.8844 - val_loss: 0.4396 - val_categorical_accuracy: 0.8700\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3983 - categorical_accuracy: 0.8722 - val_loss: 0.6895 - val_categorical_accuracy: 0.7600\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.4343 - categorical_accuracy: 0.8678 - val_loss: 0.4985 - val_categorical_accuracy: 0.8100\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.3535 - categorical_accuracy: 0.8922 - val_loss: 0.7079 - val_categorical_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.4056 - categorical_accuracy: 0.8678 - val_loss: 0.4280 - val_categorical_accuracy: 0.8600\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.3670 - categorical_accuracy: 0.8867 - val_loss: 0.6978 - val_categorical_accuracy: 0.7400\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.4121 - categorical_accuracy: 0.8656 - val_loss: 0.7472 - val_categorical_accuracy: 0.7600\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.3920 - categorical_accuracy: 0.8778 - val_loss: 0.4649 - val_categorical_accuracy: 0.8300\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.3776 - categorical_accuracy: 0.8800 - val_loss: 0.5739 - val_categorical_accuracy: 0.8000\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 51s 456ms/step - loss: 0.3885 - categorical_accuracy: 0.8822 - val_loss: 0.6278 - val_categorical_accuracy: 0.7800\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.3540 - categorical_accuracy: 0.8956 - val_loss: 0.5146 - val_categorical_accuracy: 0.8400\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 52s 463ms/step - loss: 0.3355 - categorical_accuracy: 0.9022 - val_loss: 0.4200 - val_categorical_accuracy: 0.8600\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.3524 - categorical_accuracy: 0.8911 - val_loss: 0.4268 - val_categorical_accuracy: 0.8500\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.3640 - categorical_accuracy: 0.8911 - val_loss: 0.4965 - val_categorical_accuracy: 0.8400\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3157 - categorical_accuracy: 0.9111 - val_loss: 0.4252 - val_categorical_accuracy: 0.8500\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.3352 - categorical_accuracy: 0.9033 - val_loss: 0.7226 - val_categorical_accuracy: 0.7800\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.3047 - categorical_accuracy: 0.9144 - val_loss: 0.4384 - val_categorical_accuracy: 0.8700\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.3595 - categorical_accuracy: 0.8933 - val_loss: 0.4577 - val_categorical_accuracy: 0.8600\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.2885 - categorical_accuracy: 0.9200INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 508ms/step - loss: 0.2885 - categorical_accuracy: 0.9200 - val_loss: 0.4066 - val_categorical_accuracy: 0.8900\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 52s 460ms/step - loss: 0.3012 - categorical_accuracy: 0.9133 - val_loss: 0.4599 - val_categorical_accuracy: 0.8600\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 51s 457ms/step - loss: 0.2946 - categorical_accuracy: 0.9133 - val_loss: 0.5087 - val_categorical_accuracy: 0.8200\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.2807 - categorical_accuracy: 0.9178 - val_loss: 0.4382 - val_categorical_accuracy: 0.8700\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.2937 - categorical_accuracy: 0.9189 - val_loss: 0.4842 - val_categorical_accuracy: 0.8600\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.3033 - categorical_accuracy: 0.9200 - val_loss: 0.4485 - val_categorical_accuracy: 0.8700\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.3023 - categorical_accuracy: 0.9122 - val_loss: 0.4437 - val_categorical_accuracy: 0.8600\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.2777 - categorical_accuracy: 0.9244 - val_loss: 0.4381 - val_categorical_accuracy: 0.8700\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.2983 - categorical_accuracy: 0.9200 - val_loss: 0.3792 - val_categorical_accuracy: 0.8900\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 51s 456ms/step - loss: 0.3051 - categorical_accuracy: 0.9122 - val_loss: 0.4292 - val_categorical_accuracy: 0.8800\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 52s 457ms/step - loss: 0.3089 - categorical_accuracy: 0.9144 - val_loss: 0.4018 - val_categorical_accuracy: 0.8800\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 52s 457ms/step - loss: 0.2753 - categorical_accuracy: 0.9244 - val_loss: 0.4442 - val_categorical_accuracy: 0.8700\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 52s 459ms/step - loss: 0.3125 - categorical_accuracy: 0.9044 - val_loss: 0.5365 - val_categorical_accuracy: 0.8400\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.2727 - categorical_accuracy: 0.9278 - val_loss: 0.4091 - val_categorical_accuracy: 0.8700\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.4557 - categorical_accuracy: 0.8600 - val_loss: 0.4815 - val_categorical_accuracy: 0.8500\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 51s 456ms/step - loss: 0.4240 - categorical_accuracy: 0.8578 - val_loss: 0.4209 - val_categorical_accuracy: 0.8900\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.4365 - categorical_accuracy: 0.8600 - val_loss: 0.6409 - val_categorical_accuracy: 0.8000\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.4681 - categorical_accuracy: 0.8456 - val_loss: 0.7268 - val_categorical_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.4132 - categorical_accuracy: 0.8644 - val_loss: 0.4595 - val_categorical_accuracy: 0.8700\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.4216 - categorical_accuracy: 0.8600 - val_loss: 0.9288 - val_categorical_accuracy: 0.6800\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.4877 - categorical_accuracy: 0.8344 - val_loss: 0.6403 - val_categorical_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.4549 - categorical_accuracy: 0.8511 - val_loss: 0.4718 - val_categorical_accuracy: 0.8200\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 52s 459ms/step - loss: 0.4132 - categorical_accuracy: 0.8622 - val_loss: 0.5724 - val_categorical_accuracy: 0.8000\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 52s 461ms/step - loss: 0.4099 - categorical_accuracy: 0.8733 - val_loss: 0.3596 - val_categorical_accuracy: 0.8900\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.3584 - categorical_accuracy: 0.8867 - val_loss: 0.5718 - val_categorical_accuracy: 0.8200\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 52s 457ms/step - loss: 0.3383 - categorical_accuracy: 0.8967 - val_loss: 0.5884 - val_categorical_accuracy: 0.8100\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 52s 459ms/step - loss: 0.3716 - categorical_accuracy: 0.8844 - val_loss: 0.4360 - val_categorical_accuracy: 0.8800\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.3714 - categorical_accuracy: 0.8889 - val_loss: 0.4109 - val_categorical_accuracy: 0.8600\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.3686 - categorical_accuracy: 0.8833 - val_loss: 0.4547 - val_categorical_accuracy: 0.8600\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 52s 462ms/step - loss: 0.3794 - categorical_accuracy: 0.8800 - val_loss: 0.4483 - val_categorical_accuracy: 0.8600\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 52s 460ms/step - loss: 0.3467 - categorical_accuracy: 0.8967 - val_loss: 0.4917 - val_categorical_accuracy: 0.8300\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4276 - categorical_accuracy: 0.8656INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense64-allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 514ms/step - loss: 0.4276 - categorical_accuracy: 0.8656 - val_loss: 0.3346 - val_categorical_accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 52s 459ms/step - loss: 0.3803 - categorical_accuracy: 0.8844 - val_loss: 0.5051 - val_categorical_accuracy: 0.8300\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 51s 456ms/step - loss: 0.3907 - categorical_accuracy: 0.8700 - val_loss: 0.4872 - val_categorical_accuracy: 0.8200\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 52s 460ms/step - loss: 0.3270 - categorical_accuracy: 0.9056 - val_loss: 0.4560 - val_categorical_accuracy: 0.8700\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3558 - categorical_accuracy: 0.8944 - val_loss: 0.3986 - val_categorical_accuracy: 0.8800\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.3054 - categorical_accuracy: 0.9033 - val_loss: 0.4988 - val_categorical_accuracy: 0.8500\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.3453 - categorical_accuracy: 0.8889 - val_loss: 0.5048 - val_categorical_accuracy: 0.8400\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.3556 - categorical_accuracy: 0.8967 - val_loss: 0.3912 - val_categorical_accuracy: 0.8700\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 52s 457ms/step - loss: 0.3030 - categorical_accuracy: 0.9111 - val_loss: 0.7505 - val_categorical_accuracy: 0.7400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td></td></tr><tr><td>epoch/epoch</td><td></td></tr><tr><td>epoch/learning_rate</td><td></td></tr><tr><td>epoch/loss</td><td></td></tr><tr><td>epoch/val_categorical_accuracy</td><td></td></tr><tr><td>epoch/val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td>0.91111</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>8e-05</td></tr><tr><td>epoch/loss</td><td>0.30305</td></tr><tr><td>epoch/val_categorical_accuracy</td><td>0.74</td></tr><tr><td>epoch/val_loss</td><td>0.75053</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM64-Dense64-allfeatures</strong> at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/tyh5w2ae' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/tyh5w2ae</a><br/> View project at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240408_124402-tyh5w2ae/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fda527cdad0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM64-Dense64-allfeatures.tf\"),\n",
    "            run_name=\"LSTM64-Dense64-allfeatures\", T_max=75, epochs=100, \n",
    "            max_lr = 1e-4, min_lr = 2.5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20240408_141317-jhepc329</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/jhepc329' target=\"_blank\">LSTM64-Dense128-allfeatures</a></strong> to <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/jhepc329' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/jhepc329</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.1320 - categorical_accuracy: 0.3978INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 67s 557ms/step - loss: 1.1320 - categorical_accuracy: 0.3978 - val_loss: 1.1157 - val_categorical_accuracy: 0.4100\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.1137 - categorical_accuracy: 0.4156INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 517ms/step - loss: 1.1137 - categorical_accuracy: 0.4156 - val_loss: 1.0914 - val_categorical_accuracy: 0.4600\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 1.0936 - categorical_accuracy: 0.4167 - val_loss: 1.0644 - val_categorical_accuracy: 0.4300\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0683 - categorical_accuracy: 0.3889INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 56s 501ms/step - loss: 1.0683 - categorical_accuracy: 0.3889 - val_loss: 1.0305 - val_categorical_accuracy: 0.4700\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 52s 457ms/step - loss: 1.0345 - categorical_accuracy: 0.4256 - val_loss: 0.9855 - val_categorical_accuracy: 0.4300\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0035 - categorical_accuracy: 0.4456INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 59s 520ms/step - loss: 1.0035 - categorical_accuracy: 0.4456 - val_loss: 0.9437 - val_categorical_accuracy: 0.4900\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0103 - categorical_accuracy: 0.4544INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 513ms/step - loss: 1.0103 - categorical_accuracy: 0.4544 - val_loss: 0.9660 - val_categorical_accuracy: 0.5200\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.9675 - categorical_accuracy: 0.4767 - val_loss: 1.0216 - val_categorical_accuracy: 0.4900\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9119 - categorical_accuracy: 0.5267INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 59s 517ms/step - loss: 0.9119 - categorical_accuracy: 0.5267 - val_loss: 0.8566 - val_categorical_accuracy: 0.5600\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9029 - categorical_accuracy: 0.5400INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 59s 518ms/step - loss: 0.9029 - categorical_accuracy: 0.5400 - val_loss: 0.8066 - val_categorical_accuracy: 0.5800\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8586 - categorical_accuracy: 0.5511INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 511ms/step - loss: 0.8586 - categorical_accuracy: 0.5511 - val_loss: 0.8088 - val_categorical_accuracy: 0.5900\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 52s 457ms/step - loss: 0.8127 - categorical_accuracy: 0.5533 - val_loss: 0.7929 - val_categorical_accuracy: 0.5800\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.8108 - categorical_accuracy: 0.5578 - val_loss: 0.7927 - val_categorical_accuracy: 0.5700\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.8790 - categorical_accuracy: 0.5344 - val_loss: 0.8307 - val_categorical_accuracy: 0.5500\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.7909 - categorical_accuracy: 0.5622 - val_loss: 0.8010 - val_categorical_accuracy: 0.5500\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.8140 - categorical_accuracy: 0.5711 - val_loss: 0.8049 - val_categorical_accuracy: 0.5600\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.8103 - categorical_accuracy: 0.5778INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 508ms/step - loss: 0.8103 - categorical_accuracy: 0.5778 - val_loss: 0.8149 - val_categorical_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.8039 - categorical_accuracy: 0.5756 - val_loss: 0.7945 - val_categorical_accuracy: 0.5800\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 52s 457ms/step - loss: 0.7993 - categorical_accuracy: 0.5856 - val_loss: 0.7896 - val_categorical_accuracy: 0.5500\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.7795 - categorical_accuracy: 0.5911 - val_loss: 0.8051 - val_categorical_accuracy: 0.5300\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.7706 - categorical_accuracy: 0.6022 - val_loss: 0.7732 - val_categorical_accuracy: 0.5700\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.7396 - categorical_accuracy: 0.6156 - val_loss: 0.8178 - val_categorical_accuracy: 0.5900\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.7452 - categorical_accuracy: 0.6011 - val_loss: 0.7757 - val_categorical_accuracy: 0.5900\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.7296 - categorical_accuracy: 0.6189 - val_loss: 0.7378 - val_categorical_accuracy: 0.6000\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.7152 - categorical_accuracy: 0.6333 - val_loss: 0.7172 - val_categorical_accuracy: 0.5900\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6897 - categorical_accuracy: 0.6811INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 515ms/step - loss: 0.6897 - categorical_accuracy: 0.6811 - val_loss: 0.6801 - val_categorical_accuracy: 0.6400\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6367 - categorical_accuracy: 0.7233INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 512ms/step - loss: 0.6367 - categorical_accuracy: 0.7233 - val_loss: 0.6453 - val_categorical_accuracy: 0.7200\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5524 - categorical_accuracy: 0.7744INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 515ms/step - loss: 0.5524 - categorical_accuracy: 0.7744 - val_loss: 0.5173 - val_categorical_accuracy: 0.8400\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.5915 - categorical_accuracy: 0.7633 - val_loss: 0.6240 - val_categorical_accuracy: 0.7300\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.5347 - categorical_accuracy: 0.7911 - val_loss: 0.4735 - val_categorical_accuracy: 0.8400\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.5165 - categorical_accuracy: 0.7944 - val_loss: 0.4232 - val_categorical_accuracy: 0.8100\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.4915 - categorical_accuracy: 0.8178 - val_loss: 0.4979 - val_categorical_accuracy: 0.8100\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4810 - categorical_accuracy: 0.8333INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 518ms/step - loss: 0.4810 - categorical_accuracy: 0.8333 - val_loss: 0.4634 - val_categorical_accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4596 - categorical_accuracy: 0.8411INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 515ms/step - loss: 0.4596 - categorical_accuracy: 0.8411 - val_loss: 0.4470 - val_categorical_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4790 - categorical_accuracy: 0.8244INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 516ms/step - loss: 0.4790 - categorical_accuracy: 0.8244 - val_loss: 0.3842 - val_categorical_accuracy: 0.8700\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.4455 - categorical_accuracy: 0.8478 - val_loss: 0.4243 - val_categorical_accuracy: 0.8600\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.4786 - categorical_accuracy: 0.8322 - val_loss: 0.4498 - val_categorical_accuracy: 0.8400\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.4863 - categorical_accuracy: 0.8233 - val_loss: 0.4660 - val_categorical_accuracy: 0.8300\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.4091 - categorical_accuracy: 0.8544 - val_loss: 0.4194 - val_categorical_accuracy: 0.8700\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.4525 - categorical_accuracy: 0.8433 - val_loss: 0.5789 - val_categorical_accuracy: 0.8100\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3981 - categorical_accuracy: 0.8767INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 59s 520ms/step - loss: 0.3981 - categorical_accuracy: 0.8767 - val_loss: 0.2976 - val_categorical_accuracy: 0.9100\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.4388 - categorical_accuracy: 0.8467 - val_loss: 0.6030 - val_categorical_accuracy: 0.7800\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.4349 - categorical_accuracy: 0.8567 - val_loss: 0.3512 - val_categorical_accuracy: 0.8700\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3927 - categorical_accuracy: 0.8689 - val_loss: 0.4066 - val_categorical_accuracy: 0.8600\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.3653 - categorical_accuracy: 0.8867 - val_loss: 0.3749 - val_categorical_accuracy: 0.8900\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.3591 - categorical_accuracy: 0.8867 - val_loss: 0.5302 - val_categorical_accuracy: 0.8400\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.4030 - categorical_accuracy: 0.8644 - val_loss: 0.4458 - val_categorical_accuracy: 0.8300\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.3572 - categorical_accuracy: 0.8889 - val_loss: 0.3102 - val_categorical_accuracy: 0.9100\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3615 - categorical_accuracy: 0.8844 - val_loss: 0.3618 - val_categorical_accuracy: 0.8900\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.3644 - categorical_accuracy: 0.8856 - val_loss: 0.3790 - val_categorical_accuracy: 0.8900\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.3868 - categorical_accuracy: 0.8800 - val_loss: 0.3699 - val_categorical_accuracy: 0.8800\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.3769 - categorical_accuracy: 0.8833 - val_loss: 0.3959 - val_categorical_accuracy: 0.8700\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.3448 - categorical_accuracy: 0.8978 - val_loss: 0.4130 - val_categorical_accuracy: 0.8800\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.3351 - categorical_accuracy: 0.9000 - val_loss: 0.5915 - val_categorical_accuracy: 0.7800\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.3425 - categorical_accuracy: 0.8944 - val_loss: 0.3477 - val_categorical_accuracy: 0.9000\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3734 - categorical_accuracy: 0.8778 - val_loss: 0.4047 - val_categorical_accuracy: 0.8800\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3462 - categorical_accuracy: 0.8978 - val_loss: 0.4394 - val_categorical_accuracy: 0.8500\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3559 - categorical_accuracy: 0.8944 - val_loss: 0.4795 - val_categorical_accuracy: 0.8300\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.3530 - categorical_accuracy: 0.8922 - val_loss: 0.3734 - val_categorical_accuracy: 0.8900\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.3217 - categorical_accuracy: 0.9044 - val_loss: 0.3667 - val_categorical_accuracy: 0.8900\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3137 - categorical_accuracy: 0.9100 - val_loss: 0.3653 - val_categorical_accuracy: 0.9100\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3203 - categorical_accuracy: 0.9033 - val_loss: 0.3331 - val_categorical_accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.3133 - categorical_accuracy: 0.9033 - val_loss: 0.3486 - val_categorical_accuracy: 0.9000\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 52s 460ms/step - loss: 0.3524 - categorical_accuracy: 0.9022 - val_loss: 0.3530 - val_categorical_accuracy: 0.8900\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 52s 452ms/step - loss: 0.2923 - categorical_accuracy: 0.9189 - val_loss: 0.3919 - val_categorical_accuracy: 0.8800\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.3018 - categorical_accuracy: 0.9178 - val_loss: 0.5833 - val_categorical_accuracy: 0.8100\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.3623 - categorical_accuracy: 0.8911 - val_loss: 0.3731 - val_categorical_accuracy: 0.8900\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 52s 457ms/step - loss: 0.3082 - categorical_accuracy: 0.9022 - val_loss: 0.4030 - val_categorical_accuracy: 0.8600\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 52s 456ms/step - loss: 0.3097 - categorical_accuracy: 0.9122 - val_loss: 0.3692 - val_categorical_accuracy: 0.8800\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 52s 459ms/step - loss: 0.2826 - categorical_accuracy: 0.9233 - val_loss: 0.4324 - val_categorical_accuracy: 0.8600\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.2819 - categorical_accuracy: 0.9189 - val_loss: 0.5258 - val_categorical_accuracy: 0.8300\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 52s 459ms/step - loss: 0.3141 - categorical_accuracy: 0.9111 - val_loss: 0.4164 - val_categorical_accuracy: 0.8800\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3128 - categorical_accuracy: 0.9156 - val_loss: 0.3882 - val_categorical_accuracy: 0.8800\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 51s 446ms/step - loss: 0.3042 - categorical_accuracy: 0.9144 - val_loss: 0.4380 - val_categorical_accuracy: 0.8700\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.4798 - categorical_accuracy: 0.8467 - val_loss: 0.5084 - val_categorical_accuracy: 0.8300\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 52s 457ms/step - loss: 0.5408 - categorical_accuracy: 0.8244 - val_loss: 0.4815 - val_categorical_accuracy: 0.8300\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 52s 457ms/step - loss: 0.4122 - categorical_accuracy: 0.8633 - val_loss: 0.6058 - val_categorical_accuracy: 0.8200\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.5175 - categorical_accuracy: 0.8189 - val_loss: 0.4488 - val_categorical_accuracy: 0.8500\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.4475 - categorical_accuracy: 0.8511 - val_loss: 0.3743 - val_categorical_accuracy: 0.9000\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.4989 - categorical_accuracy: 0.8378 - val_loss: 0.8412 - val_categorical_accuracy: 0.7000\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 52s 459ms/step - loss: 0.4617 - categorical_accuracy: 0.8389 - val_loss: 0.3929 - val_categorical_accuracy: 0.8900\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 52s 460ms/step - loss: 0.3690 - categorical_accuracy: 0.8878 - val_loss: 0.5399 - val_categorical_accuracy: 0.8200\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 52s 458ms/step - loss: 0.5458 - categorical_accuracy: 0.8256 - val_loss: 0.6096 - val_categorical_accuracy: 0.7900\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3830 - categorical_accuracy: 0.8844 - val_loss: 0.3760 - val_categorical_accuracy: 0.8900\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.4080 - categorical_accuracy: 0.8711 - val_loss: 0.4618 - val_categorical_accuracy: 0.8400\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.4076 - categorical_accuracy: 0.8622 - val_loss: 0.6547 - val_categorical_accuracy: 0.7900\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 51s 455ms/step - loss: 0.3966 - categorical_accuracy: 0.8689 - val_loss: 0.6459 - val_categorical_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3849 - categorical_accuracy: 0.8789 - val_loss: 0.3922 - val_categorical_accuracy: 0.8800\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.3967 - categorical_accuracy: 0.8722 - val_loss: 0.4036 - val_categorical_accuracy: 0.8500\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.4118 - categorical_accuracy: 0.8667 - val_loss: 0.3600 - val_categorical_accuracy: 0.8700\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.4056 - categorical_accuracy: 0.8733 - val_loss: 0.5976 - val_categorical_accuracy: 0.7800\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.4430 - categorical_accuracy: 0.8622 - val_loss: 0.3574 - val_categorical_accuracy: 0.8900\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 52s 455ms/step - loss: 0.3914 - categorical_accuracy: 0.8733 - val_loss: 0.4379 - val_categorical_accuracy: 0.8500\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 52s 461ms/step - loss: 0.3451 - categorical_accuracy: 0.8922 - val_loss: 0.4518 - val_categorical_accuracy: 0.8600\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.3373 - categorical_accuracy: 0.9000 - val_loss: 0.5741 - val_categorical_accuracy: 0.8000\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 51s 457ms/step - loss: 0.3771 - categorical_accuracy: 0.8856 - val_loss: 0.4136 - val_categorical_accuracy: 0.8600\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3577 - categorical_accuracy: 0.8922 - val_loss: 0.4052 - val_categorical_accuracy: 0.8700\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3453 - categorical_accuracy: 0.9000INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense128allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 516ms/step - loss: 0.3453 - categorical_accuracy: 0.9000 - val_loss: 0.2897 - val_categorical_accuracy: 0.9200\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3037 - categorical_accuracy: 0.9133 - val_loss: 0.4313 - val_categorical_accuracy: 0.8800\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3411 - categorical_accuracy: 0.8978 - val_loss: 0.4559 - val_categorical_accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td></td></tr><tr><td>epoch/epoch</td><td></td></tr><tr><td>epoch/learning_rate</td><td></td></tr><tr><td>epoch/loss</td><td></td></tr><tr><td>epoch/val_categorical_accuracy</td><td></td></tr><tr><td>epoch/val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td>0.89778</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>8e-05</td></tr><tr><td>epoch/loss</td><td>0.3411</td></tr><tr><td>epoch/val_categorical_accuracy</td><td>0.86</td></tr><tr><td>epoch/val_loss</td><td>0.45587</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM64-Dense128-allfeatures</strong> at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/jhepc329' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/jhepc329</a><br/> View project at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240408_141317-jhepc329/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fda52b45090>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM64-Dense128allfeatures.tf\"),\n",
    "            run_name=\"LSTM64-Dense128-allfeatures\", T_max=75, epochs=100, \n",
    "            max_lr = 1e-4, min_lr = 2.5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20240408_154309-dtxcqcb5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/dtxcqcb5' target=\"_blank\">LSTM64-Dense257-allfeatures</a></strong> to <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/dtxcqcb5' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/dtxcqcb5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.1294 - categorical_accuracy: 0.4156INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 62s 512ms/step - loss: 1.1294 - categorical_accuracy: 0.4156 - val_loss: 1.1076 - val_categorical_accuracy: 0.4400\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 1.1075 - categorical_accuracy: 0.4222 - val_loss: 1.0894 - val_categorical_accuracy: 0.4300\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 1.0856 - categorical_accuracy: 0.4189 - val_loss: 1.0600 - val_categorical_accuracy: 0.4300\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 1.0583 - categorical_accuracy: 0.4211INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 500ms/step - loss: 1.0583 - categorical_accuracy: 0.4211 - val_loss: 1.0436 - val_categorical_accuracy: 0.4500\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 53s 466ms/step - loss: 1.0402 - categorical_accuracy: 0.4322 - val_loss: 1.0101 - val_categorical_accuracy: 0.4200\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9952 - categorical_accuracy: 0.4556INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 59s 520ms/step - loss: 0.9952 - categorical_accuracy: 0.4556 - val_loss: 0.9143 - val_categorical_accuracy: 0.5800\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.9315 - categorical_accuracy: 0.5089INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 518ms/step - loss: 0.9315 - categorical_accuracy: 0.5089 - val_loss: 0.8479 - val_categorical_accuracy: 0.5900\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.9245 - categorical_accuracy: 0.5300 - val_loss: 0.8585 - val_categorical_accuracy: 0.5500\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.8849 - categorical_accuracy: 0.5322 - val_loss: 0.8620 - val_categorical_accuracy: 0.5700\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.9289 - categorical_accuracy: 0.5156 - val_loss: 0.8300 - val_categorical_accuracy: 0.5600\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.8394 - categorical_accuracy: 0.5600 - val_loss: 0.8156 - val_categorical_accuracy: 0.5700\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.8493 - categorical_accuracy: 0.5567 - val_loss: 0.8283 - val_categorical_accuracy: 0.5800\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 51s 446ms/step - loss: 0.8212 - categorical_accuracy: 0.5533 - val_loss: 0.8123 - val_categorical_accuracy: 0.5100\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.8168 - categorical_accuracy: 0.5822 - val_loss: 0.8011 - val_categorical_accuracy: 0.5700\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.8150 - categorical_accuracy: 0.5711 - val_loss: 0.7711 - val_categorical_accuracy: 0.5600\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 51s 447ms/step - loss: 0.7867 - categorical_accuracy: 0.5933 - val_loss: 0.7957 - val_categorical_accuracy: 0.5300\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 51s 447ms/step - loss: 0.7756 - categorical_accuracy: 0.5911 - val_loss: 0.7544 - val_categorical_accuracy: 0.5900\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7765 - categorical_accuracy: 0.5956INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 508ms/step - loss: 0.7765 - categorical_accuracy: 0.5956 - val_loss: 0.7695 - val_categorical_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.7625 - categorical_accuracy: 0.6044 - val_loss: 0.8354 - val_categorical_accuracy: 0.5600\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.7641 - categorical_accuracy: 0.5956 - val_loss: 0.7856 - val_categorical_accuracy: 0.5800\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.7537 - categorical_accuracy: 0.6067 - val_loss: 0.8254 - val_categorical_accuracy: 0.5800\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.7807 - categorical_accuracy: 0.6044 - val_loss: 0.7774 - val_categorical_accuracy: 0.5600\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.7218 - categorical_accuracy: 0.6544INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 515ms/step - loss: 0.7218 - categorical_accuracy: 0.6544 - val_loss: 0.7005 - val_categorical_accuracy: 0.6600\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6934 - categorical_accuracy: 0.6756INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 512ms/step - loss: 0.6934 - categorical_accuracy: 0.6756 - val_loss: 0.7214 - val_categorical_accuracy: 0.6900\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6997 - categorical_accuracy: 0.7067INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 515ms/step - loss: 0.6997 - categorical_accuracy: 0.7067 - val_loss: 0.6414 - val_categorical_accuracy: 0.7300\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6192 - categorical_accuracy: 0.7644INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 508ms/step - loss: 0.6192 - categorical_accuracy: 0.7644 - val_loss: 0.6036 - val_categorical_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.5595 - categorical_accuracy: 0.7889 - val_loss: 0.6018 - val_categorical_accuracy: 0.7900\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.5250 - categorical_accuracy: 0.8167 - val_loss: 0.6052 - val_categorical_accuracy: 0.7800\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.5321 - categorical_accuracy: 0.7844 - val_loss: 0.5875 - val_categorical_accuracy: 0.7800\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5018 - categorical_accuracy: 0.8189INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 58s 511ms/step - loss: 0.5018 - categorical_accuracy: 0.8189 - val_loss: 0.4842 - val_categorical_accuracy: 0.8100\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 50s 445ms/step - loss: 0.5003 - categorical_accuracy: 0.8244 - val_loss: 0.7470 - val_categorical_accuracy: 0.7200\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5084 - categorical_accuracy: 0.8100INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 56s 494ms/step - loss: 0.5084 - categorical_accuracy: 0.8100 - val_loss: 0.4414 - val_categorical_accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.4533 - categorical_accuracy: 0.8344 - val_loss: 0.4862 - val_categorical_accuracy: 0.8400\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.4792 - categorical_accuracy: 0.8311 - val_loss: 0.5741 - val_categorical_accuracy: 0.7900\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 50s 441ms/step - loss: 0.4670 - categorical_accuracy: 0.8356 - val_loss: 0.5930 - val_categorical_accuracy: 0.7900\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.4843 - categorical_accuracy: 0.8300 - val_loss: 0.5214 - val_categorical_accuracy: 0.8300\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4420 - categorical_accuracy: 0.8489INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 56s 494ms/step - loss: 0.4420 - categorical_accuracy: 0.8489 - val_loss: 0.4315 - val_categorical_accuracy: 0.8700\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.4192 - categorical_accuracy: 0.8567 - val_loss: 0.4976 - val_categorical_accuracy: 0.8400\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 51s 456ms/step - loss: 0.4574 - categorical_accuracy: 0.8400 - val_loss: 0.4369 - val_categorical_accuracy: 0.8600\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.4144 - categorical_accuracy: 0.8656 - val_loss: 0.5767 - val_categorical_accuracy: 0.7900\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 51s 456ms/step - loss: 0.4299 - categorical_accuracy: 0.8578 - val_loss: 0.5178 - val_categorical_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.4259 - categorical_accuracy: 0.8633 - val_loss: 0.6478 - val_categorical_accuracy: 0.7800\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.4309 - categorical_accuracy: 0.8544 - val_loss: 0.5246 - val_categorical_accuracy: 0.8400\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.4161 - categorical_accuracy: 0.8633 - val_loss: 0.5034 - val_categorical_accuracy: 0.8600\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3872 - categorical_accuracy: 0.8789INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 507ms/step - loss: 0.3872 - categorical_accuracy: 0.8789 - val_loss: 0.4209 - val_categorical_accuracy: 0.8900\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3671 - categorical_accuracy: 0.8922 - val_loss: 0.5633 - val_categorical_accuracy: 0.7900\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.3706 - categorical_accuracy: 0.8822 - val_loss: 0.6383 - val_categorical_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.3800 - categorical_accuracy: 0.8856 - val_loss: 0.4459 - val_categorical_accuracy: 0.8700\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.3679 - categorical_accuracy: 0.8911 - val_loss: 0.5862 - val_categorical_accuracy: 0.8500\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.3488 - categorical_accuracy: 0.8989 - val_loss: 0.4686 - val_categorical_accuracy: 0.8700\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.3243 - categorical_accuracy: 0.9089 - val_loss: 0.4609 - val_categorical_accuracy: 0.8500\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3512 - categorical_accuracy: 0.8944 - val_loss: 0.5035 - val_categorical_accuracy: 0.8200\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.3587 - categorical_accuracy: 0.8933 - val_loss: 0.4697 - val_categorical_accuracy: 0.8700\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3023 - categorical_accuracy: 0.9178 - val_loss: 0.6036 - val_categorical_accuracy: 0.8400\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.3401 - categorical_accuracy: 0.9056 - val_loss: 0.4467 - val_categorical_accuracy: 0.8700\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.3360 - categorical_accuracy: 0.9000 - val_loss: 0.5005 - val_categorical_accuracy: 0.8200\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.3344 - categorical_accuracy: 0.8989 - val_loss: 0.4966 - val_categorical_accuracy: 0.8300\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3392 - categorical_accuracy: 0.9033 - val_loss: 0.4649 - val_categorical_accuracy: 0.8600\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 51s 451ms/step - loss: 0.3297 - categorical_accuracy: 0.9033 - val_loss: 0.5340 - val_categorical_accuracy: 0.8500\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.3123 - categorical_accuracy: 0.9078 - val_loss: 0.4660 - val_categorical_accuracy: 0.8500\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.2969 - categorical_accuracy: 0.9167 - val_loss: 0.4637 - val_categorical_accuracy: 0.8800\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 50s 447ms/step - loss: 0.3339 - categorical_accuracy: 0.9022 - val_loss: 0.5756 - val_categorical_accuracy: 0.8000\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 50s 448ms/step - loss: 0.2775 - categorical_accuracy: 0.9267 - val_loss: 0.4496 - val_categorical_accuracy: 0.8500\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.2522 - categorical_accuracy: 0.9322 - val_loss: 0.4852 - val_categorical_accuracy: 0.8500\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.2856 - categorical_accuracy: 0.9233 - val_loss: 0.4737 - val_categorical_accuracy: 0.8700\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.3039 - categorical_accuracy: 0.9111 - val_loss: 0.6630 - val_categorical_accuracy: 0.8300\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.2949 - categorical_accuracy: 0.9167 - val_loss: 0.4312 - val_categorical_accuracy: 0.8700\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 51s 447ms/step - loss: 0.3138 - categorical_accuracy: 0.9156 - val_loss: 0.5354 - val_categorical_accuracy: 0.8400\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.2769 - categorical_accuracy: 0.9189 - val_loss: 0.5554 - val_categorical_accuracy: 0.8400\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.2758 - categorical_accuracy: 0.9256 - val_loss: 0.4695 - val_categorical_accuracy: 0.8600\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 50s 448ms/step - loss: 0.2844 - categorical_accuracy: 0.9222 - val_loss: 0.4849 - val_categorical_accuracy: 0.8600\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.2574 - categorical_accuracy: 0.9322 - val_loss: 0.4980 - val_categorical_accuracy: 0.8400\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.2820 - categorical_accuracy: 0.9200 - val_loss: 0.4960 - val_categorical_accuracy: 0.8400\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.2596 - categorical_accuracy: 0.9278 - val_loss: 0.4992 - val_categorical_accuracy: 0.8500\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.5701 - categorical_accuracy: 0.8200 - val_loss: 0.4703 - val_categorical_accuracy: 0.8100\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4652 - categorical_accuracy: 0.8444INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM64-Dense256allfeatures.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 507ms/step - loss: 0.4652 - categorical_accuracy: 0.8444 - val_loss: 0.3677 - val_categorical_accuracy: 0.9100\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.4806 - categorical_accuracy: 0.8356 - val_loss: 0.4930 - val_categorical_accuracy: 0.8700\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.3906 - categorical_accuracy: 0.8889 - val_loss: 0.4066 - val_categorical_accuracy: 0.8600\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.4055 - categorical_accuracy: 0.8744 - val_loss: 0.8157 - val_categorical_accuracy: 0.7000\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.4152 - categorical_accuracy: 0.8711 - val_loss: 0.4717 - val_categorical_accuracy: 0.8200\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.3796 - categorical_accuracy: 0.8944 - val_loss: 0.5826 - val_categorical_accuracy: 0.8300\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.4741 - categorical_accuracy: 0.8289 - val_loss: 0.4194 - val_categorical_accuracy: 0.8500\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 51s 452ms/step - loss: 0.4464 - categorical_accuracy: 0.8422 - val_loss: 0.5595 - val_categorical_accuracy: 0.8300\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.4245 - categorical_accuracy: 0.8600 - val_loss: 0.4758 - val_categorical_accuracy: 0.8200\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 51s 447ms/step - loss: 0.4011 - categorical_accuracy: 0.8667 - val_loss: 0.5513 - val_categorical_accuracy: 0.8500\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3663 - categorical_accuracy: 0.8900 - val_loss: 0.4687 - val_categorical_accuracy: 0.8500\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 51s 446ms/step - loss: 0.4279 - categorical_accuracy: 0.8689 - val_loss: 0.6647 - val_categorical_accuracy: 0.8100\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.3741 - categorical_accuracy: 0.8833 - val_loss: 0.5761 - val_categorical_accuracy: 0.8500\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 51s 446ms/step - loss: 0.3585 - categorical_accuracy: 0.8900 - val_loss: 0.9366 - val_categorical_accuracy: 0.6600\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3772 - categorical_accuracy: 0.8844 - val_loss: 0.4098 - val_categorical_accuracy: 0.8700\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.3593 - categorical_accuracy: 0.8933 - val_loss: 0.5831 - val_categorical_accuracy: 0.7700\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 51s 454ms/step - loss: 0.4430 - categorical_accuracy: 0.8567 - val_loss: 0.5215 - val_categorical_accuracy: 0.7900\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 51s 448ms/step - loss: 0.4518 - categorical_accuracy: 0.8578 - val_loss: 0.4675 - val_categorical_accuracy: 0.8400\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3978 - categorical_accuracy: 0.8744 - val_loss: 0.5808 - val_categorical_accuracy: 0.8300\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.4023 - categorical_accuracy: 0.8756 - val_loss: 0.6677 - val_categorical_accuracy: 0.7900\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 51s 447ms/step - loss: 0.3559 - categorical_accuracy: 0.8789 - val_loss: 0.3913 - val_categorical_accuracy: 0.8900\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 51s 450ms/step - loss: 0.3396 - categorical_accuracy: 0.8956 - val_loss: 0.4530 - val_categorical_accuracy: 0.8700\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 51s 449ms/step - loss: 0.4212 - categorical_accuracy: 0.8733 - val_loss: 0.4849 - val_categorical_accuracy: 0.8300\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 51s 453ms/step - loss: 0.3324 - categorical_accuracy: 0.8944 - val_loss: 0.5087 - val_categorical_accuracy: 0.8200\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 50s 444ms/step - loss: 0.3433 - categorical_accuracy: 0.8956 - val_loss: 0.3723 - val_categorical_accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td></td></tr><tr><td>epoch/epoch</td><td></td></tr><tr><td>epoch/learning_rate</td><td></td></tr><tr><td>epoch/loss</td><td></td></tr><tr><td>epoch/val_categorical_accuracy</td><td></td></tr><tr><td>epoch/val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/categorical_accuracy</td><td>0.89556</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>8e-05</td></tr><tr><td>epoch/loss</td><td>0.34329</td></tr><tr><td>epoch/val_categorical_accuracy</td><td>0.88</td></tr><tr><td>epoch/val_loss</td><td>0.3723</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM64-Dense257-allfeatures</strong> at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/dtxcqcb5' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/dtxcqcb5</a><br/> View project at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240408_154309-dtxcqcb5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fda49b2fa50>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM64-Dense256allfeatures.tf\"),\n",
    "            run_name=\"LSTM64-Dense257-allfeatures\", T_max=75, epochs=100, \n",
    "            max_lr = 1e-4, min_lr = 2.5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNITS: 512\n"
     ]
    }
   ],
   "source": [
    "# Epsilon value for layer normalisation\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "\n",
    "# Dense layer units for landmarks\n",
    "LIPS_UNITS = 384\n",
    "HANDS_UNITS = 384\n",
    "POSE_UNITS = 384\n",
    "# final embedding and transformer embedding size\n",
    "UNITS = 512\n",
    "\n",
    "# Transformer\n",
    "NUM_BLOCKS = 2\n",
    "MLP_RATIO = 2\n",
    "\n",
    "# Dropout\n",
    "EMBEDDING_DROPOUT = 0.00\n",
    "MLP_DROPOUT_RATIO = 0.30\n",
    "CLASSIFIER_DROPOUT_RATIO = 0.10\n",
    "\n",
    "# Initiailizers\n",
    "INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n",
    "INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n",
    "INIT_ZEROS = tf.keras.initializers.constant(0.0)\n",
    "# Activations\n",
    "GELU = tf.keras.activations.gelu\n",
    "\n",
    "print(f'UNITS: {UNITS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow port of Transformer, done by : https://www.kaggle.com/code/markwijkhuizen/gislr-tf-data-processing-transformer-training\n",
    "\n",
    "def scaled_dot_product(q,k,v, softmax, attention_mask):\n",
    "    #calculates Q . K(transpose)\n",
    "    qkt = tf.matmul(q,k,transpose_b=True)\n",
    "    #caculates scaling factor\n",
    "    dk = tf.math.sqrt(tf.cast(q.shape[-1],dtype=tf.float32))\n",
    "    scaled_qkt = qkt/dk\n",
    "    softmax = softmax(scaled_qkt, mask=attention_mask)\n",
    "    \n",
    "    z = tf.matmul(softmax,v)\n",
    "    #shape: (m,Tx,depth), same shape as q,k,v\n",
    "    return z\n",
    "\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,num_of_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_of_heads = num_of_heads\n",
    "        self.depth = d_model//num_of_heads\n",
    "        self.wq = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wk = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wv = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wo = tf.keras.layers.Dense(d_model)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "\n",
    "    def call(self,x, attention_mask):\n",
    "        \n",
    "        multi_attn = []\n",
    "        for i in range(self.num_of_heads):\n",
    "            Q = self.wq[i](x)\n",
    "            K = self.wk[i](x)\n",
    "            V = self.wv[i](x)\n",
    "            multi_attn.append(scaled_dot_product(Q,K,V, self.softmax, attention_mask))\n",
    "            \n",
    "        multi_head = tf.concat(multi_attn,axis=-1)\n",
    "        multi_head_attention = self.wo(multi_head)\n",
    "        return multi_head_attention\n",
    "\n",
    "# Full Transformer\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_blocks):\n",
    "        super(Transformer, self).__init__(name='transformer')\n",
    "        self.num_blocks = num_blocks\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.ln_1s = []\n",
    "        self.mhas = []\n",
    "        self.ln_2s = []\n",
    "        self.mlps = []\n",
    "        # Make Transformer Blocks\n",
    "        for i in range(self.num_blocks):\n",
    "            # Multi Head Attention\n",
    "            self.mhas.append(MultiHeadAttention(UNITS, 8))\n",
    "            # Multi Layer Perception\n",
    "            self.mlps.append(tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(UNITS * MLP_RATIO, activation=GELU, kernel_initializer=INIT_GLOROT_UNIFORM),\n",
    "                tf.keras.layers.Dropout(MLP_DROPOUT_RATIO),\n",
    "                tf.keras.layers.Dense(UNITS, kernel_initializer=INIT_HE_UNIFORM),\n",
    "            ]))\n",
    "        \n",
    "    def call(self, x, attention_mask):\n",
    "        # Iterate input over transformer blocks\n",
    "        for mha, mlp in zip(self.mhas, self.mlps):\n",
    "            x = x + mha(x, attention_mask)\n",
    "            x = x + mlp(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Embedding\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    # Inputs\n",
    "    frames = tf.keras.layers.Input([INPUT_SIZE, N_COLS, N_DIMS], dtype=tf.float32, name='frames')\n",
    "    non_empty_frame_idxs = tf.keras.layers.Input([INPUT_SIZE], dtype=tf.float32, name='non_empty_frame_idxs')\n",
    "    # Padding Mask\n",
    "    mask0 = tf.cast(tf.math.not_equal(non_empty_frame_idxs, -1), tf.float32)\n",
    "    mask0 = tf.expand_dims(mask0, axis=2)\n",
    "    # Random Frame Masking\n",
    "    mask = tf.where(\n",
    "        (tf.random.uniform(tf.shape(mask0)) > 0.25) & tf.math.not_equal(mask0, 0.0),\n",
    "        1.0,\n",
    "        0.0,\n",
    "    )\n",
    "    # Correct Samples Which are all masked now...\n",
    "    mask = tf.where(\n",
    "        tf.math.equal(tf.reduce_sum(mask, axis=[1,2], keepdims=True), 0.0),\n",
    "        mask0,\n",
    "        mask,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "        left_hand: 468:489\n",
    "        pose: 489:522\n",
    "        right_hand: 522:543\n",
    "    \"\"\"\n",
    "    x = frames\n",
    "    x = tf.slice(x, [0,0,0,0], [-1,INPUT_SIZE, N_COLS, 2])\n",
    "    # LIPS\n",
    "    lips = tf.slice(x, [0,0,LIPS_START,0], [-1,INPUT_SIZE, 40, 2])\n",
    "    lips = tf.where(\n",
    "            tf.math.equal(lips, 0.0),\n",
    "            0.0,\n",
    "            (lips - LIPS_MEAN) / LIPS_STD,\n",
    "        )\n",
    "    # LEFT HAND\n",
    "    left_hand = tf.slice(x, [0,0,40,0], [-1,INPUT_SIZE, 21, 2])\n",
    "    left_hand = tf.where(\n",
    "            tf.math.equal(left_hand, 0.0),\n",
    "            0.0,\n",
    "            (left_hand - LEFT_HANDS_MEAN) / LEFT_HANDS_STD,\n",
    "        )\n",
    "    # POSE\n",
    "    pose = tf.slice(x, [0,0,61,0], [-1,INPUT_SIZE, 5, 2])\n",
    "    pose = tf.where(\n",
    "            tf.math.equal(pose, 0.0),\n",
    "            0.0,\n",
    "            (pose - POSE_MEAN) / POSE_STD,\n",
    "        )\n",
    "    \n",
    "    # Flatten\n",
    "    lips = tf.reshape(lips, [-1, INPUT_SIZE, 40*2])\n",
    "    left_hand = tf.reshape(left_hand, [-1, INPUT_SIZE, 21*2])\n",
    "    pose = tf.reshape(pose, [-1, INPUT_SIZE, 5*2])\n",
    "        \n",
    "    # Embedding\n",
    "    x = Embedding()(lips, left_hand, pose, non_empty_frame_idxs)\n",
    "    \n",
    "    # Encoder Transformer Blocks\n",
    "    x = Transformer(NUM_BLOCKS)(x, mask)\n",
    "    \n",
    "    # Pooling\n",
    "    x = tf.reduce_sum(x * mask, axis=1) / tf.reduce_sum(mask, axis=1)\n",
    "    # Classifier Dropout\n",
    "    x = tf.keras.layers.Dropout(CLASSIFIER_DROPOUT_RATIO)(x)\n",
    "    # Classification Layer\n",
    "    x = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.keras.activations.softmax, kernel_initializer=INIT_GLOROT_UNIFORM)(x)\n",
    "    \n",
    "    outputs = x\n",
    "    \n",
    "    # Create Tensorflow Model\n",
    "    model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)\n",
    "    \n",
    "    # Sparse Categorical Cross Entropy With Label Smoothing\n",
    "    loss = scce_with_ls\n",
    "    \n",
    "    # Adam Optimizer with weight decay\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5, clipnorm=1.0)\n",
    "    \n",
    "    # TopK Metrics\n",
    "    metrics = [\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10, name='top_10_acc'),\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 5087314,
     "sourceId": 46105,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
