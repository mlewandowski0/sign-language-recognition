{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e590034b-fd11-4b74-ad5d-b9ae3dc95bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.14.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
      "Requirement already satisfied: larq in /usr/local/lib/python3.11/dist-packages (0.13.3)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.16.6)\n",
      "Collecting albumentations\n",
      "  Obtaining dependency information for albumentations from https://files.pythonhosted.org/packages/40/01/4202bd81ab337dca5693d7d1cb25c8e9041d97762aee738a24382ff9af2f/albumentations-1.4.3-py3-none-any.whl.metadata\n",
      "  Downloading albumentations-1.4.3-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: terminaltables>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from larq) (3.1.10)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (1.45.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from wandb) (1.4.4)\n",
      "Collecting scikit-image>=0.21.0 (from albumentations)\n",
      "  Obtaining dependency information for scikit-image>=0.21.0 from https://files.pythonhosted.org/packages/0e/6e/cae83e24d1c62aacb8facb9e3325d3b9454f3374d42ead5e6caae4753048/scikit_image-0.23.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scikit_image-0.23.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow)\n",
      "  Obtaining dependency information for typing-extensions>=3.6.6 from https://files.pythonhosted.org/packages/01/f3/936e209267d6ef7510322191003885de524fc48d1b43269810cd589ceaf5/typing_extensions-4.11.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting opencv-python-headless>=4.9.0 (from albumentations)\n",
      "  Obtaining dependency information for opencv-python-headless>=4.9.0 from https://files.pythonhosted.org/packages/71/19/3c65483a80a1d062d46ae20faf5404712d25cb1dfdcaf371efbd67c38544/opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Collecting networkx>=2.8 (from scikit-image>=0.21.0->albumentations)\n",
      "  Obtaining dependency information for networkx>=2.8 from https://files.pythonhosted.org/packages/38/e9/5f72929373e1a0e8d142a130f3f97e6ff920070f87f91c4e13e40e0fba5a/networkx-3.3-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting imageio>=2.33 (from scikit-image>=0.21.0->albumentations)\n",
      "  Obtaining dependency information for imageio>=2.33 from https://files.pythonhosted.org/packages/02/25/66533a8390e3763cf8254dee143dbf8a830391ea60d2762512ba7f9ddfbe/imageio-2.34.0-py3-none-any.whl.metadata\n",
      "  Downloading imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image>=0.21.0->albumentations)\n",
      "  Obtaining dependency information for tifffile>=2022.8.12 from https://files.pythonhosted.org/packages/cd/0b/33610b4d0d1bb83a6bfd20ed838f52e02a44e9b439116cd4f3d424e81a80/tifffile-2024.2.12-py3-none-any.whl.metadata\n",
      "  Downloading tifffile-2024.2.12-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image>=0.21.0->albumentations)\n",
      "  Obtaining dependency information for lazy-loader>=0.4 from https://files.pythonhosted.org/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl.metadata\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.23.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.0)\n",
      "Downloading albumentations-1.4.3-py3-none-any.whl (137 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.23.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Downloading imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m160.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-extensions, tifffile, opencv-python-headless, networkx, lazy-loader, imageio, scikit-image, albumentations\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "Successfully installed albumentations-1.4.3 imageio-2.34.0 lazy-loader-0.4 networkx-3.3 opencv-python-headless-4.9.0.80 scikit-image-0.23.1 tifffile-2024.2.12 typing-extensions-4.11.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy tensorflow scikit-learn matplotlib larq wandb albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167211ac-0c75-4671-80ba-89a16ec53e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 23:03:10.288223: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-14 23:03:10.288319: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-14 23:03:10.288367: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-14 23:03:10.298668: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#get all the required dependencies of the project\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "from typing import Tuple\n",
    "from collections import Counter\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import json\n",
    "import tensorflow.keras as keras \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6769893-fdab-4bc5-b80b-2fc3915b8bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_diff(prev_frame, current_frame, next_frame):\n",
    "    if prev_frame is None or current_frame is None or next_frame is None:\n",
    "        return None\n",
    "    \n",
    "    #standarized frame.\n",
    "    prev_frame = cv2.resize(prev_frame, (640, 480))\n",
    "    current_frame = cv2.resize(current_frame, (640, 480))\n",
    "    next_frame = cv2.resize(next_frame, (640, 480))\n",
    "    \n",
    "    #getting the absolute difference between current frame and next frame.\n",
    "    diff1 = cv2.absdiff(next_frame, current_frame)\n",
    "    \n",
    "    #absolute diff between previous and current frame.\n",
    "    diff2 = cv2.absdiff(current_frame, prev_frame)\n",
    "    \n",
    "    #bitwise AND operation to obtain common region of motion\n",
    "    motion_diff = cv2.bitwise_and(diff1, diff2)\n",
    "    \n",
    "    return motion_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86fa712e-39d7-4bb1-90e1-cefcb4108c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected actions: ['about' 'accident' 'africa' 'again' 'all' 'always' 'animal' 'apple'\n",
      " 'approve' 'argue' 'arrive' 'baby' 'back' 'backpack' 'bad' 'bake'\n",
      " 'balance' 'ball' 'banana' 'bar' 'basketball' 'bath' 'bathroom' 'beard'\n",
      " 'because' 'bed' 'before' 'behind' 'bird' 'birthday' 'black' 'blanket'\n",
      " 'blue' 'book' 'bowling' 'boy' 'bring' 'brother' 'brown' 'business' 'but'\n",
      " 'buy' 'call' 'can' 'candy' 'careful' 'cat' 'catch' 'center' 'cereal'\n",
      " 'chair' 'champion' 'change' 'chat' 'cheat' 'check' 'cheese' 'children'\n",
      " 'christmas' 'city' 'class' 'clock' 'close' 'clothes' 'coffee' 'cold'\n",
      " 'college' 'color' 'computer' 'convince' 'cook' 'cool' 'copy' 'corn'\n",
      " 'cough']\n"
     ]
    }
   ],
   "source": [
    "#code that loops through folders to get actions\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Path to the dataset folder containing subfolders for each action\n",
    "dataset_folder = \"asl_dataset_word/archive (1)/extracted_videos_asl\"  # Update this to your dataset directory\n",
    "\n",
    "# Path for exported data (not used for video processing here, but kept for structure)\n",
    "DATA_PATH = os.path.join('FD_FLAT_ASL_DATA') \n",
    "\n",
    "# Ensure DATA_PATH exists\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "# List to hold the names of actions based on folder names in the dataset_folder\n",
    "actions = []\n",
    "\n",
    "# Populate actions list with the names of directories in DATA_PATH\n",
    "for entry in os.listdir(DATA_PATH):\n",
    "    if os.path.isdir(os.path.join(DATA_PATH, entry)):\n",
    "        actions.append(entry)\n",
    "\n",
    "# Convert the list of actions to a numpy array (optional, depending on further use)\n",
    "actions = np.array(actions)\n",
    "\n",
    "# Print detected actions\n",
    "print(f\"Detected actions: {actions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b79bd8-1992-4816-83a2-cb70ff80b2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d8732-f2a5-41fa-8201-17d6eafd58bd",
   "metadata": {},
   "source": [
    "## Preprocess data - create labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155911a5-eb64-46f5-9bdd-2afba3473989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test is a function to split dataset into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Converts class vectors to binary class matrix for categorial crossentropy\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e079b3-b63c-41df-9d64-df81ce0ccb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Label Map\n",
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51f6aae3-1b80-487e-a305-5fc46a74f19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about': 0,\n",
       " 'accident': 1,\n",
       " 'africa': 2,\n",
       " 'again': 3,\n",
       " 'all': 4,\n",
       " 'always': 5,\n",
       " 'animal': 6,\n",
       " 'apple': 7,\n",
       " 'approve': 8,\n",
       " 'argue': 9,\n",
       " 'arrive': 10,\n",
       " 'baby': 11,\n",
       " 'back': 12,\n",
       " 'backpack': 13,\n",
       " 'bad': 14,\n",
       " 'bake': 15,\n",
       " 'balance': 16,\n",
       " 'ball': 17,\n",
       " 'banana': 18,\n",
       " 'bar': 19,\n",
       " 'basketball': 20,\n",
       " 'bath': 21,\n",
       " 'bathroom': 22,\n",
       " 'beard': 23,\n",
       " 'because': 24,\n",
       " 'bed': 25,\n",
       " 'before': 26,\n",
       " 'behind': 27,\n",
       " 'bird': 28,\n",
       " 'birthday': 29,\n",
       " 'black': 30,\n",
       " 'blanket': 31,\n",
       " 'blue': 32,\n",
       " 'book': 33,\n",
       " 'bowling': 34,\n",
       " 'boy': 35,\n",
       " 'bring': 36,\n",
       " 'brother': 37,\n",
       " 'brown': 38,\n",
       " 'business': 39,\n",
       " 'but': 40,\n",
       " 'buy': 41,\n",
       " 'call': 42,\n",
       " 'can': 43,\n",
       " 'candy': 44,\n",
       " 'careful': 45,\n",
       " 'cat': 46,\n",
       " 'catch': 47,\n",
       " 'center': 48,\n",
       " 'cereal': 49,\n",
       " 'chair': 50,\n",
       " 'champion': 51,\n",
       " 'change': 52,\n",
       " 'chat': 53,\n",
       " 'cheat': 54,\n",
       " 'check': 55,\n",
       " 'cheese': 56,\n",
       " 'children': 57,\n",
       " 'christmas': 58,\n",
       " 'city': 59,\n",
       " 'class': 60,\n",
       " 'clock': 61,\n",
       " 'close': 62,\n",
       " 'clothes': 63,\n",
       " 'coffee': 64,\n",
       " 'cold': 65,\n",
       " 'college': 66,\n",
       " 'color': 67,\n",
       " 'computer': 68,\n",
       " 'convince': 69,\n",
       " 'cook': 70,\n",
       " 'cool': 71,\n",
       " 'copy': 72,\n",
       " 'corn': 73,\n",
       " 'cough': 74}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "123e7188-9d79-406b-8241-72f45f538c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences processed: 0\n"
     ]
    }
   ],
   "source": [
    "#Padding for uniform data - USE THIS!\n",
    "DATA_PATH = \"FD_FLAT_ASL_DATA\"\n",
    "sequences, labels = [], []\n",
    "sequence_counter = 0  # Initialize a counter for the number of sequences processed\n",
    "\n",
    "# Assuming a predefined maximum sequence length (adjust as needed)\n",
    "max_sequence_length = 150  # Change this to your maximum length requirement\n",
    "\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    for file_name in os.listdir(action_path):\n",
    "        if file_name.endswith('.npy'):\n",
    "\n",
    "            fd_path = os.path.join(action_path, file_name)\n",
    "            fd_data = np.load(fd_path)\n",
    "            \n",
    "            # Check if the loaded sequence length is shorter than max_sequence_length and pad if necessary\n",
    "            if fd_data.shape[0] < max_sequence_length:\n",
    "                # Calculate the padding amount needed\n",
    "                padding_length = max_sequence_length - fd_data.shape[0]\n",
    "                # Pad with zeros - assuming fd_data is a 2D array; adjust padding shape as necessary\n",
    "                padding = np.zeros((padding_length, *fd_data.shape[1:]))\n",
    "                fd_data = np.vstack((fd_data, padding))\n",
    "            \n",
    "            sequences.append(fd_data)\n",
    "            labels.append(label_map[action])  # Map the label\n",
    "\n",
    "print(f\"Total sequences processed: {sequence_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "905b0203-6477-4376-81f5-88e7fe1436c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676, 150, 100, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_data.shape\n",
    "\n",
    "#note each fd_data time has different length - apply normalization and zero-padding to get rid of the problem. Then\n",
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bbf271f-facf-4a8c-a214-7450dc04a62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0b9cb66-7707-43ae-af48-d2e0e361420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676, 150, 100, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(sequences)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca8672b9-51b8-4c21-bbb1-eb0b38635a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#label_encoder = LabelEncoder()\n",
    "#integer_encoded = label_encoder.fit_transform(labels)\n",
    "y = to_categorical(labels).astype(int)\n",
    "#y = to_categorical(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ab25dd2-be46-4bc1-9120-a6a8af4f356a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0fb6a36-8385-4fe2-b6b8-37859c07d3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80d2482b-5b0a-4ff1-a0c8-b1244d134d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, split into train, test, and dev (validate) dataset\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)\n",
    "\n",
    "# First, split into temp training and test sets\n",
    "X_temp, X_dev, y_temp, y_dev = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "# Then, split the temp training set into final training and dev (validation) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c37c1506-e2fa-4fb3-9612-54ed2f1c415b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((609, 150, 100, 100), (33, 150, 100, 100), (34, 150, 100, 100))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at the distribution of test and dev dataset\n",
    "X_train.shape, X_test.shape, X_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac62dd5-8b86-4b25-9a6f-adb667b2669e",
   "metadata": {},
   "source": [
    "## Build and Train CNN!\n",
    "Simple architecture using LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d5830fc-aad3-4dbc-9178-7febee8f794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D , Flatten, BatchNormalization, Reshape\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "#from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "#import larq as lq larq uses tensorflow 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80d98751-6dfd-4ec9-bc92-87f97113e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 150, 100, 32)      80032     \n",
      "                                                                 \n",
      " batch_normalization_29 (Ba  (None, 150, 100, 32)      128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 150, 100, 48)      38448     \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 150, 100, 48)      192       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 75, 50, 48)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 75, 50, 32)        38432     \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  (None, 75, 50, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 75, 50, 48)        38448     \n",
      "                                                                 \n",
      " batch_normalization_32 (Ba  (None, 75, 50, 48)        192       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 37, 25, 48)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 37, 25, 32)        38432     \n",
      "                                                                 \n",
      " batch_normalization_33 (Ba  (None, 37, 25, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 37, 25, 48)        38448     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 150, 296)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                92416     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 75)                4875      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370299 (1.41 MB)\n",
      "Trainable params: 369915 (1.41 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Port LeNet CNN Architecture from MHI version of the project\n",
    "FD_FLAT_SHAPE = (150,100,100) \n",
    "#150,10000\n",
    "model_leNet = Sequential()\n",
    "#Block 1\n",
    "model_leNet.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=FD_FLAT_SHAPE))\n",
    "model_leNet.add(BatchNormalization())\n",
    "model_leNet.add(Conv2D(filters=48, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model_leNet.add(BatchNormalization())\n",
    "model_leNet.add(MaxPooling2D(pool_size=(2,2), strides = (2,2)))\n",
    "\n",
    "#Block 2\n",
    "model_leNet.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model_leNet.add(BatchNormalization())\n",
    "model_leNet.add(Conv2D(filters=48, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model_leNet.add(BatchNormalization())\n",
    "model_leNet.add(MaxPooling2D(pool_size=(2,2), strides = (2,2)))\n",
    "\n",
    "#Block 3\n",
    "model_leNet.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model_leNet.add(BatchNormalization())\n",
    "model_leNet.add(Conv2D(filters=48, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "\n",
    "# Flatten the output and reshape for LSTM\n",
    "model_leNet.add(Reshape((150, -1)))  # Reshape to (batch_size, 150, features_per_timestep)\n",
    "# Add LSTM layer\n",
    "# No return_sequences if you want the output from the last timestep only\n",
    "model_leNet.add(LSTM(units=64, activation='relu', return_sequences=False))\n",
    "model_leNet.add(Flatten())\n",
    "model_leNet.add(Dense(units=actions.shape[0], activation='softmax'))\n",
    "\n",
    "\"\"\"\n",
    "model_leNet.add(BatchNormalization())\n",
    "model_leNet.add(MaxPooling2D(pool_size=(2,2), strides = (2,2)))\n",
    "\n",
    "#Block 4\n",
    "model_leNet.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model_leNet.add(BatchNormalization())\n",
    "model_leNet.add(Conv2D(filters=48, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model_leNet.add(BatchNormalization())\n",
    "model_leNet.add(MaxPooling2D(pool_size=(2,2), strides = (2,2)))\n",
    "\n",
    "model_leNet.add(Flatten())\n",
    "model_leNet.add(Dense(128, activation='relu'))\n",
    "model_leNet.add(Dense(units=actions.shape[0], activation='softmax'))\n",
    "#model_leNet.add(Dense(len(train_ds.unique_labels), activation='softmax'))\n",
    "\"\"\"\n",
    "\n",
    "model_leNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14e49341-9d8f-4217-af7f-310736231f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixed learning rate: adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003) #0.001 can be changed.\n",
    "\n",
    "#learning rate decay for Adam\n",
    "initial_learning_rate = 0.0003  # Starting learning rate\n",
    "decay_steps = 100000           # After how many steps to apply decay\n",
    "decay_rate = 0.96              # Decay rate\n",
    "staircase = True               # Apply decay in a staircase fashion\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps,\n",
    "    decay_rate,\n",
    "    staircase=staircase\n",
    ")\n",
    "\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6b3214e-9b7a-461a-9fec-d228ebe90b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "77/77 [==============================] - 17s 152ms/step - loss: 4.3252 - categorical_accuracy: 0.0082 - val_loss: 4.9545 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "77/77 [==============================] - 12s 157ms/step - loss: 23.8317 - categorical_accuracy: 0.0115 - val_loss: 73.1107 - val_categorical_accuracy: 0.0294\n",
      "Epoch 3/1000\n",
      "77/77 [==============================] - 12s 159ms/step - loss: 21.1596 - categorical_accuracy: 0.0181 - val_loss: 26.8657 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "77/77 [==============================] - 12s 157ms/step - loss: 18.9710 - categorical_accuracy: 0.0164 - val_loss: 18.0031 - val_categorical_accuracy: 0.0294\n",
      "Epoch 5/1000\n",
      "77/77 [==============================] - ETA: 0s - loss: 17.2136 - categorical_accuracy: 0.0230"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model_leNet\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39madam_opt, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Train the model - MobileNetV3Small as pretrained model. Tensorboard callback.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel_leNet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#save the model (for future load and training purposes)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:1832\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1818\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1819\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1830\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1831\u001b[0m     )\n\u001b[0;32m-> 1832\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1834\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1835\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1837\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1841\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1847\u001b[0m }\n\u001b[1;32m   1848\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:2261\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_tune_steps_per_execution:\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_tuner\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m-> 2261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[1;32m   2262\u001b[0m     _,\n\u001b[1;32m   2263\u001b[0m     dataset_or_iterator,\n\u001b[1;32m   2264\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/data_adapter.py:1341\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1341\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset)\n\u001b[1;32m   1342\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[1;32m   1343\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/dataset_ops.py:496\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    495\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py:705\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    701\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 705\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py:727\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mget_flat_tensor_shapes(\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec)\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(ds_variant):\n\u001b[1;32m    726\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 727\u001b[0m       \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manonymous_iterator_v3\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m          \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m          \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    730\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# Add full type information to the graph so host memory types inside\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# variants stay on CPU, e.g, ragged string tensors.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;66;03m# type inference (esp. cross-function type inference) instead of\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;66;03m# setting the full type information manually.\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     fulltype \u001b[38;5;241m=\u001b[39m type_utils\u001b[38;5;241m.\u001b[39miterator_full_type_from_spec(\n\u001b[1;32m    739\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_dataset_ops.py:203\u001b[0m, in \u001b[0;36manonymous_iterator_v3\u001b[0;34m(output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    202\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnonymousIteratorV3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#code previously\n",
    "model_leNet.compile(optimizer=adam_opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#Train the model - MobileNetV3Small as pretrained model. Tensorboard callback.\n",
    "model_leNet.fit(X_train, y_train, epochs=1000, validation_data = (X_dev, y_dev), batch_size = 8)\n",
    "#gradient clipping for adam and L2 regularization for LSTM. -> look at the code prev.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64661427-624d-4d94-8542-a3817711d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model_leNet.save('FD_first_leNet.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
