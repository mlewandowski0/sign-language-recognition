{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.14.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.9.0.80)\n",
      "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.11)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.4.1.post1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.1)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (15.0.2)\n",
      "Collecting wandb\n",
      "  Obtaining dependency information for wandb from https://files.pythonhosted.org/packages/8b/8d/bb05a4ecdeac6b2256d98ac10bae8723af5d7a8c1a4c2384b3ae0f80370e/wandb-0.16.6-py3-none-any.whl.metadata\n",
      "  Downloading wandb-0.16.6-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.26)\n",
      "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.26)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mediapipe) (2.2.2)\n",
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
      "Collecting Click!=8.0.0,>=7.1 (from wandb)\n",
      "  Obtaining dependency information for Click!=8.0.0,>=7.1 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for GitPython!=3.1.29,>=1.0.0 from https://files.pythonhosted.org/packages/e9/bd/cc3a402a6439c15c3d4294333e13042b915bbeab54edc457c723931fed3f/GitPython-3.1.43-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for sentry-sdk>=1.0.0 from https://files.pythonhosted.org/packages/b1/f8/2038661bc32579d0c11191fc1093e49db590bfb6e63d501d7995fb798d62/sentry_sdk-1.44.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading sentry_sdk-1.44.1-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Obtaining dependency information for docker-pycreds>=0.4.0 from https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Obtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/fd/df/44b267cb8f073a4ae77e120f0705ab3a07165ad90cecd4881b34c7e1e37b/setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Obtaining dependency information for appdirs>=1.4.3 from https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.23.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (3.13.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe) (12.4.127)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.0)\n",
      "Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.44.1-py2.py3-none-any.whl (266 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, Click, gitdb, GitPython, wandb\n",
      "Successfully installed Click-8.1.7 GitPython-3.1.43 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.44.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow opencv-python mediapipe scikit-learn matplotlib pandas pyarrow wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Load parquet data into dataset_parquet for training.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.regularizers import l2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import time\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    # root = os.path.join(\"/\", \"kaggle\", \"input\", \"asl-signs\") \n",
    "    root = os.path.join(\".\")\n",
    "    DATA_LIMIT = 100\n",
    "    BATCH_SIZE = 8\n",
    "    VIDEO_LENGTH = 60\n",
    "    TRAIN_VAL_SPLIT = 0.9\n",
    "    WANDB_RUN = \"mediapipe-asl-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asl-signs.zip',\n",
       " 'lstm-approach.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'sign_to_prediction_index_map.json',\n",
       " 'train.csv',\n",
       " 'train_landmark_files']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(CONFIG.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code sorts out a parquet files and rearrange the order to pose,face, left-hand, right-hand\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ids = None\n",
    "\n",
    "order_global = {\"pose\" : 10000, \"face\" : 1000, \"left_hand\" : 100, \"right_hand\" : 10}\n",
    "\n",
    "def process_parquet(ds):\n",
    "    ret = []\n",
    "    frames_unique = sorted(np.unique(ds[\"frame\"]))\n",
    "    for i,frame in enumerate(frames_unique):\n",
    "        frame_ds = ds[ds['frame'] == frame]\n",
    "        \n",
    "        order = []\n",
    "        for el in frame_ds[\"row_id\"]:\n",
    "            _frame, part, keypoint = el.split(\"-\")\n",
    "            order.append(order_global[part] - int(keypoint))\n",
    "\n",
    "        order = np.array(order)\n",
    "        frame_ds.iloc[:, 1] = order\n",
    "        frame_ds = frame_ds.sort_values(by=\"row_id\", ascending=False)\n",
    "    \n",
    "        vals = np.array(frame_ds[[\"x\", \"y\", \"z\"]]).flatten()\n",
    "\n",
    "        ret.append(vals)\n",
    "    return np.array(ret)\n",
    "        \n",
    "#process_parquet(\"79631423.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94477/94477 [00:00<00:00, 252266.18it/s]\n",
      "100%|██████████| 94477/94477 [00:00<00:00, 254670.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardinality of train : 113, cardinality of validation : 13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#custom class to load data from Parquet files for training ML models.\n",
    "class ParquetDataset(keras.utils.Sequence):\n",
    "    def __init__(self, dataset_folder, csv_file : str, batch_size=CONFIG.BATCH_SIZE, \n",
    "                 data_limit :int= CONFIG.DATA_LIMIT, check_if_file_exists = True, \n",
    "                 preprocessing_func=None, frame_length :int = CONFIG.VIDEO_LENGTH,\n",
    "                 split : str = \"train\", train_val_split : float = CONFIG.TRAIN_VAL_SPLIT,\n",
    "                 sort_by_counts : bool = True, **kwargs\n",
    "                ):\n",
    "        super().__init__(**kwargs)\n",
    "        #taking keras sequence for .fit(), .evaluate(), .predict() methods\n",
    "        #load csv - it has the path to parquet file, and another to store label\n",
    "        self.csv_path = csv_file\n",
    "        self.root_folder = dataset_folder\n",
    "        self.batch_size = batch_size\n",
    "        #optional pre-processing function to the parquet files.\n",
    "        self.preprocessing_func = preprocessing_func\n",
    "        \n",
    "        self.csv_data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        self.all_files = []\n",
    "        self.not_exists = []\n",
    "        self.frame_length = frame_length\n",
    "\n",
    "        \n",
    "        for path, label in tqdm(list(zip(self.csv_data[\"path\"], self.csv_data[\"sign\"]))):\n",
    "            prop_path = os.path.join(self.root_folder, path)\n",
    "            \n",
    "            if check_if_file_exists:\n",
    "                if os.path.exists(prop_path):\n",
    "                    self.all_files.append((prop_path, label))\n",
    "                else:\n",
    "                    self.not_exists.append(prop_path)\n",
    "            else:\n",
    "                self.all_files.append((prop_path, label))\n",
    "                \n",
    "                    \n",
    "        self.all_files = np.array(self.all_files)\n",
    "        self.unique_labels = np.unique(self.all_files[:, 1])\n",
    "        self.label_2_id = { key : i for i, key in enumerate(self.unique_labels)}\n",
    "    \n",
    "        # sort the values by popularity\n",
    "        if sort_by_counts:\n",
    "            cnt = Counter(self.all_files[:, 1])\n",
    "            vals = []\n",
    "            \n",
    "            for i,row in enumerate(self.all_files):\n",
    "                vals.append((int(1e6 * cnt[row[1]] + self.label_2_id [row[1]]),i))\n",
    "            \n",
    "            vals = np.array(sorted(vals)[::-1])\n",
    "            self.all_files = self.all_files[vals[:,1]]\n",
    "\n",
    "        \n",
    "        if data_limit < 0:\n",
    "            train_ds, val_ds = train_test_split(self.all_files, train_size=train_val_split, random_state=42)\n",
    "        else:\n",
    "            train_ds, val_ds = train_test_split(self.all_files[:data_limit], train_size=train_val_split, random_state=42)\n",
    "            self.unique_labels = np.unique(self.all_files[:data_limit, 1])\n",
    "            self.label_2_id = { key : i for i, key in enumerate(self.unique_labels)}\n",
    "            \n",
    "        if split.lower() == \"train\":\n",
    "            self.dataset = train_ds\n",
    "            \n",
    "        elif split.lower() == \"val\":\n",
    "            self.dataset = val_ds \n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"please specify split to be either train or val\")\n",
    "            \n",
    "        np.random.shuffle(self.dataset)\n",
    "                   \n",
    "\n",
    "    def __len__(self):\n",
    "        # Assuming each Parquet file should be one batch; adjust if necessary\n",
    "        return math.ceil(len(self.dataset) / self.batch_size)\n",
    "    \n",
    "    def get_single(self, idx):\n",
    "        # Load one file per batch\n",
    "        #take the idx value, 1st label, \n",
    "        path, label = self.dataset[idx]\n",
    "        \n",
    "        df = pd.read_parquet( path)\n",
    "        \n",
    "        # Apply preprocessing if specified\n",
    "        if self.preprocessing_func:\n",
    "            df = self.preprocessing_func(df, self.frame_length)\n",
    "        \n",
    "        one_hot_encoded_label = np.zeros(len(self.unique_labels))\n",
    "        one_hot_encoded_label[self.label_2_id[label]] = 1  \n",
    "        \n",
    "        return df, one_hot_encoded_label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, Y = [], []\n",
    "        \n",
    "        low = idx * self.batch_size\n",
    "        high = min(low + self.batch_size, len(self.dataset))\n",
    "        \n",
    "        for i in range(low, high):\n",
    "            x, y = self.get_single(i)\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "        \n",
    "        return np.array(X), np.array(Y)\n",
    "                \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle files for the next epoch\n",
    "        np.random.shuffle(self.dataset)\n",
    "\n",
    "def my_preprocessing_func(df, frame_length):\n",
    "    \n",
    "    # Define your preprocessing steps here\n",
    "    # Example: normalize numerical features\n",
    "    frames_mediapipe = process_parquet(df)\n",
    "    \n",
    "    current_length, num_features = frames_mediapipe.shape\n",
    "\n",
    "    if current_length >= frame_length:\n",
    "            # TODO: a better than uniform value ? Could place gaussian in the middle\n",
    "            random_start = random.randint(0, current_length - frame_length)\n",
    "            return np.nan_to_num(frames_mediapipe[random_start : (random_start + frame_length)])\n",
    "        \n",
    "    # padd the video to contain zeros \n",
    "    return np.concatenate([np.nan_to_num(frames_mediapipe), np.zeros((frame_length - current_length, num_features))], axis=0)\n",
    "    \n",
    "# Usage example\n",
    "parquet_folder_path = CONFIG.root\n",
    "train_dataset_parquet = ParquetDataset(parquet_folder_path, csv_file = os.path.join(CONFIG.root, \"train.csv\"), \n",
    "                                 batch_size=CONFIG.BATCH_SIZE, data_limit=1000,\n",
    "                                 preprocessing_func=my_preprocessing_func,\n",
    "                                check_if_file_exists = True,\n",
    "                                split=\"train\")\n",
    "\n",
    "val_dataset_parquet = ParquetDataset(parquet_folder_path, csv_file = os.path.join(CONFIG.root, \"train.csv\"), \n",
    "                                 batch_size=CONFIG.BATCH_SIZE, data_limit=1000,\n",
    "                                 preprocessing_func=my_preprocessing_func,\n",
    "                                 check_if_file_exists= True,\n",
    "                                 split=\"val\")\n",
    "\n",
    "print(f\"cardinality of train : {len(train_dataset_parquet)}, cardinality of validation : {len(val_dataset_parquet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_dataset_parquet.dataset[:, 1], bins=len(train_dataset_parquet.unique_labels))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(val_dataset_parquet.dataset[:, 1], bins=len(val_dataset_parquet.unique_labels))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/113 [00:00<00:46,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 60, 1629) (8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:40<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating through dataset took : 40.6401s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "isnans =False\n",
    "\n",
    "f = True\n",
    "labels_batches = []\n",
    "for el in tqdm(train_dataset_parquet):\n",
    "    if f:\n",
    "        print(el[0].shape, el[1].shape)\n",
    "        f = False\n",
    "    labels_batches.append(el[1])\n",
    "        \n",
    "    isnans |= np.any(np.isnan(el[0]))\n",
    "    if isnans:\n",
    "        print(\"FOUND NAN!\")\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Iterating through dataset took : {round( time.time() - start , 4)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "from keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "\n",
    "\n",
    "class CosineAnnealingLearningRateScheduler(Callback):\n",
    "    def __init__(self, max_lr, min_lr, T_max):\n",
    "        super(CosineAnnealingLearningRateScheduler, self).__init__()\n",
    "        self.max_lr = max_lr  # Maximum learning rate (i.e., start learning rate)\n",
    "        self.min_lr = min_lr  # Minimum learning rate\n",
    "        self.T_max = T_max    # Specifies the number of epochs per cycle\n",
    "        self.t = 0            # Current epoch\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.t += 1\n",
    "        cos = np.cos(np.pi * (self.t % self.T_max) / self.T_max)\n",
    "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + cos)\n",
    "\n",
    "        keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "def keras_train(model, filepath : str, max_lr = 1e-4, min_lr = 5e-5, T_max=50, epochs=100, run_name=\"\", mediapipe_features = \"all\",): \n",
    "    \n",
    "    \n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                                 monitor=\"categorical_accuracy\",\n",
    "                                                 verbose=0,\n",
    "                                                 save_best_only=True,\n",
    "                                                 mode=\"max\",\n",
    "                                                 save_freq=\"epoch\")\n",
    "    \n",
    "    cosine_annealer = CosineAnnealingLearningRateScheduler(max_lr=max_lr,\n",
    "                                                           min_lr=min_lr,\n",
    "                                                           T_max=T_max)\n",
    "    \n",
    "    #Adam Optimizer - fixed learning rate.\n",
    "    adam_optimizer = tf.keras.optimizers.Adam(learning_rate=max_lr, clipnorm=1.)\n",
    "    lr_metric = get_lr_metric(adam_optimizer)\n",
    "\n",
    "    model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    \n",
    "    wandb.init(project=CONFIG.WANDB_RUN,\n",
    "                     name=run_name,\n",
    "                     notes=\"Model summary : \\n\" + str(model),\n",
    "                     config={\"max_lr\" : max_lr, \n",
    "                             \"min_lr\" : 5e-5, \n",
    "                             \"scheduler\" : \"cosineAnnealer\", \n",
    "                             \"epochs\" : epochs, \n",
    "                             \"T_max\" : T_max, \n",
    "                             \"train_size\" : len(train_dataset_parquet.dataset),\n",
    "                             \"val_size\" : len(val_dataset_parquet.dataset),\n",
    "                             \"unique_classes\" : len(train_dataset_parquet.unique_labels), \n",
    "                             \"video_length\" : CONFIG.VIDEO_LENGTH,\n",
    "                             \"features\" : mediapipe_features\n",
    "                             })\n",
    "    history = model.fit(train_dataset_parquet, epochs=epochs, validation_data = val_dataset_parquet, \n",
    "                        batch_size = 8, callbacks=[WandbMetricsLogger()])\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xt6menui) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.010 MB uploaded\\r'), FloatProgress(value=0.5386814200092208, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM128-Dense128-Dense256-allfeatures</strong> at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/xt6menui' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/xt6menui</a><br/> View project at: <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240408_001326-xt6menui/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:xt6menui). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60635e698f649bd918534f83e36cd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113241604632802, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20240408_001704-mma9yanu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/mma9yanu' target=\"_blank\">LSTM128-Dense128-Dense256-allfeatures</a></strong> to <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/mma9yanu' target=\"_blank\">https://wandb.ai/mlewand7/mediapipe-asl-dataset/runs/mma9yanu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - 50s 420ms/step - loss: 1.1593 - categorical_accuracy: 0.4256 - val_loss: 1.1256 - val_categorical_accuracy: 0.4400\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 47s 419ms/step - loss: 1.1167 - categorical_accuracy: 0.4033 - val_loss: 1.0833 - val_categorical_accuracy: 0.4100\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 47s 418ms/step - loss: 1.0962 - categorical_accuracy: 0.3978 - val_loss: 1.0736 - val_categorical_accuracy: 0.4300\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 47s 418ms/step - loss: 1.0673 - categorical_accuracy: 0.4167 - val_loss: 1.0816 - val_categorical_accuracy: 0.4300\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 48s 429ms/step - loss: 1.0626 - categorical_accuracy: 0.4289 - val_loss: 1.0159 - val_categorical_accuracy: 0.5600\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 47s 421ms/step - loss: 1.0114 - categorical_accuracy: 0.4800 - val_loss: 0.9312 - val_categorical_accuracy: 0.5400\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 48s 425ms/step - loss: 0.9373 - categorical_accuracy: 0.4933 - val_loss: 0.8931 - val_categorical_accuracy: 0.5100\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 48s 426ms/step - loss: 0.9902 - categorical_accuracy: 0.4778 - val_loss: 0.8592 - val_categorical_accuracy: 0.5300\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 47s 419ms/step - loss: 0.8961 - categorical_accuracy: 0.5333 - val_loss: 0.8399 - val_categorical_accuracy: 0.5700\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 48s 423ms/step - loss: 0.8905 - categorical_accuracy: 0.5378 - val_loss: 0.8394 - val_categorical_accuracy: 0.5400\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 48s 422ms/step - loss: 0.8506 - categorical_accuracy: 0.5622 - val_loss: 0.8261 - val_categorical_accuracy: 0.5600\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 48s 422ms/step - loss: 0.8818 - categorical_accuracy: 0.5222 - val_loss: 0.8491 - val_categorical_accuracy: 0.5300\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 48s 427ms/step - loss: 0.8148 - categorical_accuracy: 0.5689 - val_loss: 0.7962 - val_categorical_accuracy: 0.5900\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 47s 419ms/step - loss: 0.7931 - categorical_accuracy: 0.5833 - val_loss: 0.7738 - val_categorical_accuracy: 0.5500\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 48s 424ms/step - loss: 0.8367 - categorical_accuracy: 0.5689 - val_loss: 0.7863 - val_categorical_accuracy: 0.5400\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 48s 422ms/step - loss: 0.8055 - categorical_accuracy: 0.5878 - val_loss: 0.7690 - val_categorical_accuracy: 0.6600\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 48s 422ms/step - loss: 0.7794 - categorical_accuracy: 0.5944 - val_loss: 0.8129 - val_categorical_accuracy: 0.5900\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 48s 422ms/step - loss: 0.8122 - categorical_accuracy: 0.6067 - val_loss: 0.7385 - val_categorical_accuracy: 0.6200\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 48s 424ms/step - loss: 0.7484 - categorical_accuracy: 0.6544 - val_loss: 0.6947 - val_categorical_accuracy: 0.7200\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 48s 431ms/step - loss: 0.6762 - categorical_accuracy: 0.7278 - val_loss: 0.6666 - val_categorical_accuracy: 0.7300\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 48s 425ms/step - loss: 0.6974 - categorical_accuracy: 0.7189 - val_loss: 0.7052 - val_categorical_accuracy: 0.7200\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 48s 425ms/step - loss: 0.6419 - categorical_accuracy: 0.7478 - val_loss: 0.5823 - val_categorical_accuracy: 0.7900\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 48s 425ms/step - loss: 0.6484 - categorical_accuracy: 0.7378 - val_loss: 0.5613 - val_categorical_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 48s 425ms/step - loss: 0.5821 - categorical_accuracy: 0.7722 - val_loss: 0.5581 - val_categorical_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 48s 424ms/step - loss: 0.5418 - categorical_accuracy: 0.8011 - val_loss: 0.6032 - val_categorical_accuracy: 0.7900\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 48s 426ms/step - loss: 0.5472 - categorical_accuracy: 0.8067 - val_loss: 0.5418 - val_categorical_accuracy: 0.7900\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 48s 419ms/step - loss: 0.5336 - categorical_accuracy: 0.7989 - val_loss: 0.6143 - val_categorical_accuracy: 0.7700\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 48s 425ms/step - loss: 0.5005 - categorical_accuracy: 0.8256 - val_loss: 0.5685 - val_categorical_accuracy: 0.7900\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 49s 431ms/step - loss: 0.4811 - categorical_accuracy: 0.8400 - val_loss: 0.4959 - val_categorical_accuracy: 0.8500\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 48s 422ms/step - loss: 0.5266 - categorical_accuracy: 0.8200 - val_loss: 0.4777 - val_categorical_accuracy: 0.8400\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 48s 428ms/step - loss: 0.5450 - categorical_accuracy: 0.8022 - val_loss: 0.4906 - val_categorical_accuracy: 0.8500\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 48s 418ms/step - loss: 0.4958 - categorical_accuracy: 0.8311 - val_loss: 0.4617 - val_categorical_accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 47s 418ms/step - loss: 0.5106 - categorical_accuracy: 0.8133 - val_loss: 0.6085 - val_categorical_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 47s 413ms/step - loss: 0.4859 - categorical_accuracy: 0.8367 - val_loss: 0.4656 - val_categorical_accuracy: 0.8300\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 47s 420ms/step - loss: 0.4826 - categorical_accuracy: 0.8311 - val_loss: 0.6898 - val_categorical_accuracy: 0.7400\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 48s 421ms/step - loss: 0.5441 - categorical_accuracy: 0.8089 - val_loss: 0.8643 - val_categorical_accuracy: 0.6800\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 47s 413ms/step - loss: 0.4600 - categorical_accuracy: 0.8511 - val_loss: 0.4421 - val_categorical_accuracy: 0.8700\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 47s 417ms/step - loss: 0.4399 - categorical_accuracy: 0.8667 - val_loss: 0.4483 - val_categorical_accuracy: 0.8700\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 47s 417ms/step - loss: 0.5153 - categorical_accuracy: 0.8256 - val_loss: 0.4638 - val_categorical_accuracy: 0.8600\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 47s 411ms/step - loss: 0.5243 - categorical_accuracy: 0.8122 - val_loss: 0.6970 - val_categorical_accuracy: 0.7400\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 47s 416ms/step - loss: 0.5487 - categorical_accuracy: 0.8144 - val_loss: 0.4104 - val_categorical_accuracy: 0.8600\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 48s 428ms/step - loss: 0.4268 - categorical_accuracy: 0.8578 - val_loss: 0.4271 - val_categorical_accuracy: 0.8600\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 48s 427ms/step - loss: 0.4736 - categorical_accuracy: 0.8467 - val_loss: 0.6445 - val_categorical_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 48s 419ms/step - loss: 0.5092 - categorical_accuracy: 0.8422 - val_loss: 0.5641 - val_categorical_accuracy: 0.7900\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 48s 425ms/step - loss: 0.5190 - categorical_accuracy: 0.8311 - val_loss: 0.6782 - val_categorical_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 48s 425ms/step - loss: 0.4052 - categorical_accuracy: 0.8800 - val_loss: 0.4169 - val_categorical_accuracy: 0.8800\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 48s 428ms/step - loss: 0.3865 - categorical_accuracy: 0.8856 - val_loss: 0.4572 - val_categorical_accuracy: 0.8700\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 48s 425ms/step - loss: 0.5065 - categorical_accuracy: 0.8478 - val_loss: 0.4465 - val_categorical_accuracy: 0.8400\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 47s 418ms/step - loss: 0.4052 - categorical_accuracy: 0.8800 - val_loss: 0.8905 - val_categorical_accuracy: 0.6700\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 47s 416ms/step - loss: 0.4923 - categorical_accuracy: 0.8456 - val_loss: 0.4294 - val_categorical_accuracy: 0.8500\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 47s 416ms/step - loss: 0.3835 - categorical_accuracy: 0.8911 - val_loss: 0.5039 - val_categorical_accuracy: 0.8400\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 47s 419ms/step - loss: 0.3715 - categorical_accuracy: 0.9011 - val_loss: 0.3427 - val_categorical_accuracy: 0.9000\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 47s 414ms/step - loss: 0.4253 - categorical_accuracy: 0.8689 - val_loss: 0.4801 - val_categorical_accuracy: 0.8500\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 48s 425ms/step - loss: 0.3497 - categorical_accuracy: 0.8967 - val_loss: 0.4864 - val_categorical_accuracy: 0.8500\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 47s 420ms/step - loss: 0.3871 - categorical_accuracy: 0.8856 - val_loss: 0.5752 - val_categorical_accuracy: 0.8400\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 50s 439ms/step - loss: 0.4073 - categorical_accuracy: 0.8789 - val_loss: 0.5532 - val_categorical_accuracy: 0.8400\n",
      "Epoch 57/100\n",
      "  1/113 [..............................] - ETA: 30s - loss: 0.8505 - categorical_accuracy: 0.7500"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0001), \n",
    "               activity_regularizer=l2(0.0001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "keras_train(model, filepath=os.path.join(\"models\", \"LSTM1.keras\"),\n",
    "            run_name=\"LSTM128-Dense128-Dense256-allfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#x,y,z -> y,z as the input shape\n",
    "model.add(LSTM(128, return_sequences=False, activation='relu', input_shape=(CONFIG.VIDEO_LENGTH, 1629),\n",
    "               kernel_regularizer=l2(0.0000001), \n",
    "               activity_regularizer=l2(0.0000001)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(train_dataset_parquet.unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "0keras_train(model, filepath=os.path.join(\"models\", \"LSTM2.keras\"),\n",
    "            run_name=\"LSTM128_l2-Dense128-Dense256-allfeatures\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 5087314,
     "sourceId": 46105,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
